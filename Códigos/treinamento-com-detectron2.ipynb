{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":18613,"sourceType":"datasetVersion","datasetId":5839}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# COMEÇO DETECTRON2","metadata":{}},{"cell_type":"code","source":"# install dependencies: \n!python -m pip install pyyaml==5.1\nimport torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())\n!gcc --version\n# opencv is pre-installed on colab","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:12:05.316369Z","iopub.execute_input":"2024-05-30T22:12:05.316680Z","iopub.status.idle":"2024-05-30T22:12:13.444136Z","shell.execute_reply.started":"2024-05-30T22:12:05.316655Z","shell.execute_reply":"2024-05-30T22:12:13.442794Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pyyaml==5.1\n  Downloading PyYAML-5.1.tar.gz (274 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.2/274.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25lerror\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m \u001b[31m[48 lines of output]\u001b[0m\n  \u001b[31m   \u001b[0m /opt/conda/lib/python3.10/site-packages/setuptools/config/setupcfg.py:293: _DeprecatedConfig: Deprecated config in `setup.cfg`\n  \u001b[31m   \u001b[0m !!\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m         ********************************************************************************\n  \u001b[31m   \u001b[0m         The license_file parameter is deprecated, use license_files instead.\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m         This deprecation is overdue, please update your project and remove deprecated\n  \u001b[31m   \u001b[0m         calls to avoid build errors in the future.\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m         See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n  \u001b[31m   \u001b[0m         ********************************************************************************\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m !!\n  \u001b[31m   \u001b[0m   parsed = self.parsers.get(option_name, lambda x: x)(value)\n  \u001b[31m   \u001b[0m Traceback (most recent call last):\n  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-3uq1qt37/pyyaml_6ccc33dd2e794a63b3147d7b666ebef0/setup.py\", line 291, in <module>\n  \u001b[31m   \u001b[0m     setup(\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 185, in setup\n  \u001b[31m   \u001b[0m     return run_commands(dist)\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n  \u001b[31m   \u001b[0m     dist.run_commands()\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n  \u001b[31m   \u001b[0m     self.run_command(cmd)\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/dist.py\", line 1233, in run_command\n  \u001b[31m   \u001b[0m     super().run_command(command)\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n  \u001b[31m   \u001b[0m     cmd_obj.run()\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/command/egg_info.py\", line 319, in run\n  \u001b[31m   \u001b[0m     self.find_sources()\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/command/egg_info.py\", line 327, in find_sources\n  \u001b[31m   \u001b[0m     mm.run()\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/command/egg_info.py\", line 549, in run\n  \u001b[31m   \u001b[0m     self.add_defaults()\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/command/egg_info.py\", line 587, in add_defaults\n  \u001b[31m   \u001b[0m     sdist.add_defaults(self)\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/command/sdist.py\", line 113, in add_defaults\n  \u001b[31m   \u001b[0m     super().add_defaults()\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/command/sdist.py\", line 251, in add_defaults\n  \u001b[31m   \u001b[0m     self._add_defaults_ext()\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/command/sdist.py\", line 336, in _add_defaults_ext\n  \u001b[31m   \u001b[0m     self.filelist.extend(build_ext.get_source_files())\n  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-3uq1qt37/pyyaml_6ccc33dd2e794a63b3147d7b666ebef0/setup.py\", line 199, in get_source_files\n  \u001b[31m   \u001b[0m     self.cython_sources(ext.sources, ext)\n  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py\", line 107, in __getattr__\n  \u001b[31m   \u001b[0m     raise AttributeError(attr)\n  \u001b[31m   \u001b[0m AttributeError: cython_sources\n  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n\n\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n\u001b[1;36mhint\u001b[0m: See above for details.\n\u001b[?25h2.0.0 True\ngcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\nCopyright (C) 2021 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys, os, distutils.core\n# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n!git clone 'https://github.com/facebookresearch/detectron2'\ndist = distutils.core.run_setup(\"./detectron2/setup.py\")\n!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\nsys.path.insert(0, os.path.abspath('./detectron2'))","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:12:13.446422Z","iopub.execute_input":"2024-05-30T22:12:13.447117Z","iopub.status.idle":"2024-05-30T22:12:36.625219Z","shell.execute_reply.started":"2024-05-30T22:12:13.447087Z","shell.execute_reply":"2024-05-30T22:12:36.624073Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'detectron2'...\nremote: Enumerating objects: 15713, done.\u001b[K\nremote: Counting objects: 100% (436/436), done.\u001b[K\nremote: Compressing objects: 100% (326/326), done.\u001b[K\nremote: Total 15713 (delta 196), reused 296 (delta 104), pack-reused 15277\u001b[K\nReceiving objects: 100% (15713/15713), 6.51 MiB | 22.37 MiB/s, done.\nResolving deltas: 100% (11312/11312), done.\nRequirement already satisfied: Pillow>=7.1 in /opt/conda/lib/python3.10/site-packages (9.5.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.4)\nCollecting pycocotools>=2.0.2\n  Obtaining dependency information for pycocotools>=2.0.2 from https://files.pythonhosted.org/packages/ba/64/0451cf41a00fd5ac4501de4ea0e395b7d909e09d665e56890b5d3809ae26/pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: termcolor>=1.1 in /opt/conda/lib/python3.10/site-packages (2.3.0)\nCollecting yacs>=0.1.8\n  Obtaining dependency information for yacs>=0.1.8 from https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl.metadata\n  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (0.9.0)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (2.2.1)\nRequirement already satisfied: tqdm>4.29.0 in /opt/conda/lib/python3.10/site-packages (4.66.1)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (2.13.0)\nCollecting fvcore<0.1.6,>=0.1.5\n  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting iopath<0.1.10,>=0.1.7\n  Obtaining dependency information for iopath<0.1.10,>=0.1.7 from https://files.pythonhosted.org/packages/af/20/65dd9bd25a1eb7fa35b5ae38d289126af065f8a0c1f6a90564f4bff0f89d/iopath-0.1.9-py3-none-any.whl.metadata\n  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\nCollecting omegaconf<2.4,>=2.1\n  Obtaining dependency information for omegaconf<2.4,>=2.1 from https://files.pythonhosted.org/packages/e3/94/1843518e420fa3ed6919835845df698c7e27e183cb997394e4a670973a65/omegaconf-2.3.0-py3-none-any.whl.metadata\n  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\nCollecting hydra-core>=1.1\n  Obtaining dependency information for hydra-core>=1.1 from https://files.pythonhosted.org/packages/c6/50/e0edd38dcd63fb26a8547f13d28f7a008bc4a3fd4eb4ff030673f22ad41a/hydra_core-1.3.2-py3-none-any.whl.metadata\n  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\nCollecting black\n  Obtaining dependency information for black from https://files.pythonhosted.org/packages/e0/7d/7f8df0fdbbbefc4362d3eca6b69b7a8a4249a8a88dabc00a207d31fddcd7/black-24.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading black-24.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (77 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (21.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.1.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.42.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.24.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.8.2)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from yacs>=0.1.8) (6.0.1)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.51.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.22.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.4.4)\nRequirement already satisfied: protobuf>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.31.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (68.1.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.7.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.0.1)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.41.2)\nCollecting portalocker (from iopath<0.1.10,>=0.1.7)\n  Obtaining dependency information for portalocker from https://files.pythonhosted.org/packages/17/9e/87671efcca80ba6203811540ed1f9c0462c1609d2281d7b7f53cef05da3d/portalocker-2.8.2-py3-none-any.whl.metadata\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nCollecting antlr4-python3-runtime==4.9.* (from omegaconf<2.4,>=2.1)\n  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from black) (8.1.7)\nRequirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from black) (1.0.0)\nCollecting packaging\n  Obtaining dependency information for packaging from https://files.pythonhosted.org/packages/49/df/1fceb2f8900f8639e278b056416d49134fb8d84c5942ffaa01ad34782422/packaging-24.0-py3-none-any.whl.metadata\n  Downloading packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\nCollecting pathspec>=0.9.0 (from black)\n  Obtaining dependency information for pathspec>=0.9.0 from https://files.pythonhosted.org/packages/cc/20/ff623b09d963f88bfde16306a54e12ee5ea43e9b597108672ff3a408aad6/pathspec-0.12.1-py3-none-any.whl.metadata\n  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.10/site-packages (from black) (4.1.0)\nRequirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from black) (2.0.1)\nRequirement already satisfied: typing-extensions>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from black) (4.5.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\nRequirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.26.15)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2023.11.17)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\nDownloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\nDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\nDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading black-24.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading packaging-24.0-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\nDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nBuilding wheels for collected packages: fvcore, antlr4-python3-runtime\n  Building wheel for fvcore (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61400 sha256=2758ee15f5ed4a8dfa33509238158096ff85af1066a28669181dbf43323d3cdc\n  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=b6444233d59ef6eae2fe300e23050f5bffe4aaf103f912f219f54e90f092b68f\n  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\nSuccessfully built fvcore antlr4-python3-runtime\nInstalling collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, packaging, omegaconf, iopath, hydra-core, black, pycocotools, fvcore\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.0 which is incompatible.\njupyterlab 4.0.10 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.4 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.1 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflowjs 4.15.0 requires packaging~=23.1, but you have packaging 24.0 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 black-24.4.2 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 omegaconf-2.3.0 packaging-24.0 pathspec-0.12.1 portalocker-2.8.2 pycocotools-2.0.7 yacs-0.1.8\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch, detectron2\n!nvcc --version\nTORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\nCUDA_VERSION = torch.__version__.split(\"+\")[-1]\nprint(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\nprint(\"detectron2:\", detectron2.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:12:36.626610Z","iopub.execute_input":"2024-05-30T22:12:36.626880Z","iopub.status.idle":"2024-05-30T22:12:37.806772Z","shell.execute_reply.started":"2024-05-30T22:12:36.626856Z","shell.execute_reply":"2024-05-30T22:12:37.805510Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2022 NVIDIA Corporation\nBuilt on Wed_Sep_21_10:33:58_PDT_2022\nCuda compilation tools, release 11.8, V11.8.89\nBuild cuda_11.8.r11.8/compiler.31833905_0\ntorch:  2.0 ; cuda:  2.0.0\ndetectron2: 0.6\n","output_type":"stream"}]},{"cell_type":"code","source":"# Some basic setup:\n# Setup detectron2 logger\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n# import some common libraries\nimport pandas as pd\nimport numpy as np\nimport os, json, cv2, random\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom glob import glob\n\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog\nfrom detectron2.structures import BoxMode","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:12:37.809542Z","iopub.execute_input":"2024-05-30T22:12:37.809856Z","iopub.status.idle":"2024-05-30T22:12:38.757043Z","shell.execute_reply.started":"2024-05-30T22:12:37.809830Z","shell.execute_reply":"2024-05-30T22:12:38.756187Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os, json, cv2, random\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom glob import glob","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:12:38.758147Z","iopub.execute_input":"2024-05-30T22:12:38.758590Z","iopub.status.idle":"2024-05-30T22:12:38.764590Z","shell.execute_reply.started":"2024-05-30T22:12:38.758563Z","shell.execute_reply":"2024-05-30T22:12:38.763561Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"all_xray_df = pd.read_csv('/kaggle/input/data/Data_Entry_2017.csv')\nall_image_paths = {os.path.basename(x): x for x in \n                   glob(os.path.join('/kaggle/input/data', 'images*', '*', '*.png'))}\nprint('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\nall_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\nall_xray_df['Patient Age'] = all_xray_df['Patient Age'].map(lambda x: int(x))\nall_xray_df.sample(3)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:12:38.766030Z","iopub.execute_input":"2024-05-30T22:12:38.766310Z","iopub.status.idle":"2024-05-30T22:12:43.657702Z","shell.execute_reply.started":"2024-05-30T22:12:38.766286Z","shell.execute_reply":"2024-05-30T22:12:43.656740Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Scans found: 112120 , Total Headers 112120\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"             Image Index Finding Labels  Follow-up #  Patient ID  Patient Age  \\\n105942  00028518_011.png     No Finding           11       28518           48   \n60345   00014898_000.png     No Finding            0       14898           46   \n67283   00016607_044.png   Infiltration           44       16607           63   \n\n       Patient Gender View Position  OriginalImage[Width  Height]  \\\n105942              F            AP                 3056     2544   \n60345               M            PA                 2936     2948   \n67283               M            PA                 2992     2991   \n\n        OriginalImagePixelSpacing[x     y]  Unnamed: 11  \\\n105942                        0.139  0.139          NaN   \n60345                         0.143  0.143          NaN   \n67283                         0.143  0.143          NaN   \n\n                                                     path  \n105942  /kaggle/input/data/images_012/images/00028518_...  \n60345   /kaggle/input/data/images_007/images/00014898_...  \n67283   /kaggle/input/data/images_008/images/00016607_...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image Index</th>\n      <th>Finding Labels</th>\n      <th>Follow-up #</th>\n      <th>Patient ID</th>\n      <th>Patient Age</th>\n      <th>Patient Gender</th>\n      <th>View Position</th>\n      <th>OriginalImage[Width</th>\n      <th>Height]</th>\n      <th>OriginalImagePixelSpacing[x</th>\n      <th>y]</th>\n      <th>Unnamed: 11</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>105942</th>\n      <td>00028518_011.png</td>\n      <td>No Finding</td>\n      <td>11</td>\n      <td>28518</td>\n      <td>48</td>\n      <td>F</td>\n      <td>AP</td>\n      <td>3056</td>\n      <td>2544</td>\n      <td>0.139</td>\n      <td>0.139</td>\n      <td>NaN</td>\n      <td>/kaggle/input/data/images_012/images/00028518_...</td>\n    </tr>\n    <tr>\n      <th>60345</th>\n      <td>00014898_000.png</td>\n      <td>No Finding</td>\n      <td>0</td>\n      <td>14898</td>\n      <td>46</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2936</td>\n      <td>2948</td>\n      <td>0.143</td>\n      <td>0.143</td>\n      <td>NaN</td>\n      <td>/kaggle/input/data/images_007/images/00014898_...</td>\n    </tr>\n    <tr>\n      <th>67283</th>\n      <td>00016607_044.png</td>\n      <td>Infiltration</td>\n      <td>44</td>\n      <td>16607</td>\n      <td>63</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2992</td>\n      <td>2991</td>\n      <td>0.143</td>\n      <td>0.143</td>\n      <td>NaN</td>\n      <td>/kaggle/input/data/images_008/images/00016607_...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Antes de tudo precisamos reescrever a BBOX no formato json","metadata":{}},{"cell_type":"code","source":"bbox_csv = pd.read_csv('/kaggle/input/data/BBox_List_2017.csv')\ncategorys = bbox_csv['Finding Label'].unique()\ncategory_ids = {k: v for v, k in enumerate(categorys)}\ncategory_ids","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:12:43.659141Z","iopub.execute_input":"2024-05-30T22:12:43.659563Z","iopub.status.idle":"2024-05-30T22:12:43.677049Z","shell.execute_reply.started":"2024-05-30T22:12:43.659527Z","shell.execute_reply":"2024-05-30T22:12:43.675988Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'Atelectasis': 0,\n 'Cardiomegaly': 1,\n 'Effusion': 2,\n 'Infiltrate': 3,\n 'Mass': 4,\n 'Nodule': 5,\n 'Pneumonia': 6,\n 'Pneumothorax': 7}"},"metadata":{}}]},{"cell_type":"code","source":"bbox_csv_copy = bbox_csv.copy(deep=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:12:43.678276Z","iopub.execute_input":"2024-05-30T22:12:43.678573Z","iopub.status.idle":"2024-05-30T22:12:43.693212Z","shell.execute_reply.started":"2024-05-30T22:12:43.678549Z","shell.execute_reply":"2024-05-30T22:12:43.692304Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"bbox_csv = bbox_csv[~bbox_csv['Finding Label'].isin(['Nodule', 'Mass', 'Pneumothorax'])]\nbbox_csv['Finding Label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:12:43.694368Z","iopub.execute_input":"2024-05-30T22:12:43.694684Z","iopub.status.idle":"2024-05-30T22:12:43.715807Z","shell.execute_reply.started":"2024-05-30T22:12:43.694660Z","shell.execute_reply":"2024-05-30T22:12:43.714700Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Finding Label\nAtelectasis     180\nEffusion        153\nCardiomegaly    146\nInfiltrate      123\nPneumonia       120\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"categorys = bbox_csv['Finding Label'].unique()\ncategory_ids = {k: v for v, k in enumerate(categorys)}\ncategory_ids","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:12:43.720592Z","iopub.execute_input":"2024-05-30T22:12:43.721017Z","iopub.status.idle":"2024-05-30T22:12:43.734088Z","shell.execute_reply.started":"2024-05-30T22:12:43.720988Z","shell.execute_reply":"2024-05-30T22:12:43.731742Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'Atelectasis': 0,\n 'Cardiomegaly': 1,\n 'Effusion': 2,\n 'Infiltrate': 3,\n 'Pneumonia': 4}"},"metadata":{}}]},{"cell_type":"code","source":"list_exc = []\ncats_exc = {k: bbox_csv['Finding Label'].value_counts()[k] - bbox_csv['Finding Label'].value_counts().min() for k in categorys}\n\nfor cat in categorys:\n    count = 0\n    df_catx = bbox_csv[bbox_csv['Finding Label'] == cat]\n    for i, r in df_catx.iterrows():\n        if len(bbox_csv[bbox_csv['Image Index'] == r['Image Index']]['Image Index'].to_list()) == 1 and count < cats_exc[cat]:\n            list_exc.append(r['Image Index'])\n            count += 1\n\ndf_new = bbox_csv[~bbox_csv['Image Index'].isin(list_exc)]\ndf_new","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:12:43.735809Z","iopub.execute_input":"2024-05-30T22:12:43.736562Z","iopub.status.idle":"2024-05-30T22:12:44.197113Z","shell.execute_reply.started":"2024-05-30T22:12:43.736522Z","shell.execute_reply":"2024-05-30T22:12:44.196144Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"          Image Index Finding Label     Bbox [x           y           w  \\\n60   00007676_002.png   Atelectasis  360.677966  439.629386   82.440678   \n61   00005089_002.png   Atelectasis  648.135593  574.137861  263.593220   \n62   00020857_008.png   Atelectasis  190.372881  571.968369  562.983051   \n63   00012291_008.png   Atelectasis  232.677966  631.629386  226.711864   \n64   00018762_002.png   Atelectasis  603.661017  616.786447  257.084746   \n..                ...           ...         ...         ...         ...   \n979  00029464_015.png   Atelectasis  198.940451  352.900747  615.537778   \n980  00025769_001.png   Atelectasis  701.838229  572.491858  103.537778   \n981  00016837_002.png   Atelectasis  140.913785  658.962969  271.928889   \n982  00020124_003.png   Atelectasis  175.047118  580.456302  244.622222   \n983  00026920_000.png   Atelectasis  343.438229  446.198524  120.604444   \n\n             h]  Unnamed: 6  Unnamed: 7  Unnamed: 8  \n60   136.677966         NaN         NaN         NaN  \n61   188.745763         NaN         NaN         NaN  \n62   202.847458         NaN         NaN         NaN  \n63    74.847458         NaN         NaN         NaN  \n64    81.355932         NaN         NaN         NaN  \n..          ...         ...         ...         ...  \n979  323.128889         NaN         NaN         NaN  \n980   63.715556         NaN         NaN         NaN  \n981   94.435556         NaN         NaN         NaN  \n982  103.537778         NaN         NaN         NaN  \n983   53.475556         NaN         NaN         NaN  \n\n[600 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image Index</th>\n      <th>Finding Label</th>\n      <th>Bbox [x</th>\n      <th>y</th>\n      <th>w</th>\n      <th>h]</th>\n      <th>Unnamed: 6</th>\n      <th>Unnamed: 7</th>\n      <th>Unnamed: 8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>60</th>\n      <td>00007676_002.png</td>\n      <td>Atelectasis</td>\n      <td>360.677966</td>\n      <td>439.629386</td>\n      <td>82.440678</td>\n      <td>136.677966</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>00005089_002.png</td>\n      <td>Atelectasis</td>\n      <td>648.135593</td>\n      <td>574.137861</td>\n      <td>263.593220</td>\n      <td>188.745763</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>00020857_008.png</td>\n      <td>Atelectasis</td>\n      <td>190.372881</td>\n      <td>571.968369</td>\n      <td>562.983051</td>\n      <td>202.847458</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>00012291_008.png</td>\n      <td>Atelectasis</td>\n      <td>232.677966</td>\n      <td>631.629386</td>\n      <td>226.711864</td>\n      <td>74.847458</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>00018762_002.png</td>\n      <td>Atelectasis</td>\n      <td>603.661017</td>\n      <td>616.786447</td>\n      <td>257.084746</td>\n      <td>81.355932</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>979</th>\n      <td>00029464_015.png</td>\n      <td>Atelectasis</td>\n      <td>198.940451</td>\n      <td>352.900747</td>\n      <td>615.537778</td>\n      <td>323.128889</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>980</th>\n      <td>00025769_001.png</td>\n      <td>Atelectasis</td>\n      <td>701.838229</td>\n      <td>572.491858</td>\n      <td>103.537778</td>\n      <td>63.715556</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>981</th>\n      <td>00016837_002.png</td>\n      <td>Atelectasis</td>\n      <td>140.913785</td>\n      <td>658.962969</td>\n      <td>271.928889</td>\n      <td>94.435556</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>982</th>\n      <td>00020124_003.png</td>\n      <td>Atelectasis</td>\n      <td>175.047118</td>\n      <td>580.456302</td>\n      <td>244.622222</td>\n      <td>103.537778</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>983</th>\n      <td>00026920_000.png</td>\n      <td>Atelectasis</td>\n      <td>343.438229</td>\n      <td>446.198524</td>\n      <td>120.604444</td>\n      <td>53.475556</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>600 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"bbox_csv = df_new.copy()\n#bbox_csv = bbox_csv_copy.copy(deep=True)\nbbox_csv[bbox_csv['Image Index'] == '00008814_010.png']","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:12:44.198631Z","iopub.execute_input":"2024-05-30T22:12:44.199300Z","iopub.status.idle":"2024-05-30T22:12:44.214138Z","shell.execute_reply.started":"2024-05-30T22:12:44.199260Z","shell.execute_reply":"2024-05-30T22:12:44.213093Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"          Image Index Finding Label     Bbox [x           y           w  \\\n308  00008814_010.png      Effusion  195.128889  412.197934  665.600000   \n461  00008814_010.png    Infiltrate  205.368889  392.855712  643.982222   \n965  00008814_010.png   Atelectasis  195.527118  407.646823  669.013333   \n\n             h]  Unnamed: 6  Unnamed: 7  Unnamed: 8  \n308  105.813333         NaN         NaN         NaN  \n461   86.471111         NaN         NaN         NaN  \n965   64.853333         NaN         NaN         NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image Index</th>\n      <th>Finding Label</th>\n      <th>Bbox [x</th>\n      <th>y</th>\n      <th>w</th>\n      <th>h]</th>\n      <th>Unnamed: 6</th>\n      <th>Unnamed: 7</th>\n      <th>Unnamed: 8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>308</th>\n      <td>00008814_010.png</td>\n      <td>Effusion</td>\n      <td>195.128889</td>\n      <td>412.197934</td>\n      <td>665.600000</td>\n      <td>105.813333</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>461</th>\n      <td>00008814_010.png</td>\n      <td>Infiltrate</td>\n      <td>205.368889</td>\n      <td>392.855712</td>\n      <td>643.982222</td>\n      <td>86.471111</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>965</th>\n      <td>00008814_010.png</td>\n      <td>Atelectasis</td>\n      <td>195.527118</td>\n      <td>407.646823</td>\n      <td>669.013333</td>\n      <td>64.853333</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"bbox_csv.to_csv('imagens.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:12:44.215265Z","iopub.execute_input":"2024-05-30T22:12:44.215563Z","iopub.status.idle":"2024-05-30T22:12:44.232580Z","shell.execute_reply.started":"2024-05-30T22:12:44.215538Z","shell.execute_reply":"2024-05-30T22:12:44.231791Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"dataentry = pd.read_csv('/kaggle/input/data/Data_Entry_2017.csv')\ndataentry","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:12:44.233708Z","iopub.execute_input":"2024-05-30T22:12:44.233992Z","iopub.status.idle":"2024-05-30T22:12:44.464151Z","shell.execute_reply.started":"2024-05-30T22:12:44.233966Z","shell.execute_reply":"2024-05-30T22:12:44.463123Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"             Image Index          Finding Labels  Follow-up #  Patient ID  \\\n0       00000001_000.png            Cardiomegaly            0           1   \n1       00000001_001.png  Cardiomegaly|Emphysema            1           1   \n2       00000001_002.png   Cardiomegaly|Effusion            2           1   \n3       00000002_000.png              No Finding            0           2   \n4       00000003_000.png                  Hernia            0           3   \n...                  ...                     ...          ...         ...   \n112115  00030801_001.png          Mass|Pneumonia            1       30801   \n112116  00030802_000.png              No Finding            0       30802   \n112117  00030803_000.png              No Finding            0       30803   \n112118  00030804_000.png              No Finding            0       30804   \n112119  00030805_000.png              No Finding            0       30805   \n\n        Patient Age Patient Gender View Position  OriginalImage[Width  \\\n0                58              M            PA                 2682   \n1                58              M            PA                 2894   \n2                58              M            PA                 2500   \n3                81              M            PA                 2500   \n4                81              F            PA                 2582   \n...             ...            ...           ...                  ...   \n112115           39              M            PA                 2048   \n112116           29              M            PA                 2048   \n112117           42              F            PA                 2048   \n112118           30              F            PA                 2048   \n112119           27              M            PA                 2048   \n\n        Height]  OriginalImagePixelSpacing[x     y]  Unnamed: 11  \n0          2749                        0.143  0.143          NaN  \n1          2729                        0.143  0.143          NaN  \n2          2048                        0.168  0.168          NaN  \n3          2048                        0.171  0.171          NaN  \n4          2991                        0.143  0.143          NaN  \n...         ...                          ...    ...          ...  \n112115     2500                        0.168  0.168          NaN  \n112116     2500                        0.168  0.168          NaN  \n112117     2500                        0.168  0.168          NaN  \n112118     2500                        0.168  0.168          NaN  \n112119     2500                        0.171  0.171          NaN  \n\n[112120 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image Index</th>\n      <th>Finding Labels</th>\n      <th>Follow-up #</th>\n      <th>Patient ID</th>\n      <th>Patient Age</th>\n      <th>Patient Gender</th>\n      <th>View Position</th>\n      <th>OriginalImage[Width</th>\n      <th>Height]</th>\n      <th>OriginalImagePixelSpacing[x</th>\n      <th>y]</th>\n      <th>Unnamed: 11</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000001_000.png</td>\n      <td>Cardiomegaly</td>\n      <td>0</td>\n      <td>1</td>\n      <td>58</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2682</td>\n      <td>2749</td>\n      <td>0.143</td>\n      <td>0.143</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000001_001.png</td>\n      <td>Cardiomegaly|Emphysema</td>\n      <td>1</td>\n      <td>1</td>\n      <td>58</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2894</td>\n      <td>2729</td>\n      <td>0.143</td>\n      <td>0.143</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000001_002.png</td>\n      <td>Cardiomegaly|Effusion</td>\n      <td>2</td>\n      <td>1</td>\n      <td>58</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2500</td>\n      <td>2048</td>\n      <td>0.168</td>\n      <td>0.168</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000002_000.png</td>\n      <td>No Finding</td>\n      <td>0</td>\n      <td>2</td>\n      <td>81</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2500</td>\n      <td>2048</td>\n      <td>0.171</td>\n      <td>0.171</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000003_000.png</td>\n      <td>Hernia</td>\n      <td>0</td>\n      <td>3</td>\n      <td>81</td>\n      <td>F</td>\n      <td>PA</td>\n      <td>2582</td>\n      <td>2991</td>\n      <td>0.143</td>\n      <td>0.143</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>112115</th>\n      <td>00030801_001.png</td>\n      <td>Mass|Pneumonia</td>\n      <td>1</td>\n      <td>30801</td>\n      <td>39</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2048</td>\n      <td>2500</td>\n      <td>0.168</td>\n      <td>0.168</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>112116</th>\n      <td>00030802_000.png</td>\n      <td>No Finding</td>\n      <td>0</td>\n      <td>30802</td>\n      <td>29</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2048</td>\n      <td>2500</td>\n      <td>0.168</td>\n      <td>0.168</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>112117</th>\n      <td>00030803_000.png</td>\n      <td>No Finding</td>\n      <td>0</td>\n      <td>30803</td>\n      <td>42</td>\n      <td>F</td>\n      <td>PA</td>\n      <td>2048</td>\n      <td>2500</td>\n      <td>0.168</td>\n      <td>0.168</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>112118</th>\n      <td>00030804_000.png</td>\n      <td>No Finding</td>\n      <td>0</td>\n      <td>30804</td>\n      <td>30</td>\n      <td>F</td>\n      <td>PA</td>\n      <td>2048</td>\n      <td>2500</td>\n      <td>0.168</td>\n      <td>0.168</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>112119</th>\n      <td>00030805_000.png</td>\n      <td>No Finding</td>\n      <td>0</td>\n      <td>30805</td>\n      <td>27</td>\n      <td>M</td>\n      <td>PA</td>\n      <td>2048</td>\n      <td>2500</td>\n      <td>0.171</td>\n      <td>0.171</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>112120 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_val_list_txt = pd.read_csv('/kaggle/input/data/train_val_list.txt', sep=' ', header=None)\ntrain_val_list_txt","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:12:44.465654Z","iopub.execute_input":"2024-05-30T22:12:44.466443Z","iopub.status.idle":"2024-05-30T22:12:44.537807Z","shell.execute_reply.started":"2024-05-30T22:12:44.466406Z","shell.execute_reply":"2024-05-30T22:12:44.536850Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                      0\n0      00000001_000.png\n1      00000001_001.png\n2      00000001_002.png\n3      00000002_000.png\n4      00000004_000.png\n...                 ...\n86519  00030789_000.png\n86520  00030793_000.png\n86521  00030795_000.png\n86522  00030801_000.png\n86523  00030801_001.png\n\n[86524 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000001_000.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000001_001.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000001_002.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000002_000.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000004_000.png</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>86519</th>\n      <td>00030789_000.png</td>\n    </tr>\n    <tr>\n      <th>86520</th>\n      <td>00030793_000.png</td>\n    </tr>\n    <tr>\n      <th>86521</th>\n      <td>00030795_000.png</td>\n    </tr>\n    <tr>\n      <th>86522</th>\n      <td>00030801_000.png</td>\n    </tr>\n    <tr>\n      <th>86523</th>\n      <td>00030801_001.png</td>\n    </tr>\n  </tbody>\n</table>\n<p>86524 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"categorys = bbox_csv['Finding Label'].unique()\ncategory_ids = {k: v for v, k in enumerate(categorys)}\ncategory_ids","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:12:44.538988Z","iopub.execute_input":"2024-05-30T22:12:44.539281Z","iopub.status.idle":"2024-05-30T22:12:44.546881Z","shell.execute_reply.started":"2024-05-30T22:12:44.539255Z","shell.execute_reply":"2024-05-30T22:12:44.545943Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"{'Atelectasis': 0,\n 'Cardiomegaly': 1,\n 'Effusion': 2,\n 'Infiltrate': 3,\n 'Pneumonia': 4}"},"metadata":{}}]},{"cell_type":"code","source":"bbox_csv['image_id'] = bbox_csv.apply(lambda x: x['Image Index'].split('.')[0], axis = 1)\nbbox_csv['category_id'] = bbox_csv.apply(lambda x: category_ids[x['Finding Label']], axis = 1)\nbbox_csv['height'] = None\nbbox_csv['width'] = None\n\nfor i in bbox_csv['Image Index']:\n    if i in dataentry['Image Index'].values:\n        bbox_csv.loc[bbox_csv['Image Index'] == i, ['height']] = dataentry.loc[dataentry['Image Index'] == i, ['Height]']].values[0][0]\n        bbox_csv.loc[bbox_csv['Image Index'] == i, ['width']] = dataentry.loc[dataentry['Image Index'] == i, ['OriginalImage[Width']].values[0][0]\n\nbbox_csv","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:12:44.548074Z","iopub.execute_input":"2024-05-30T22:12:44.548376Z","iopub.status.idle":"2024-05-30T22:13:13.053901Z","shell.execute_reply.started":"2024-05-30T22:12:44.548354Z","shell.execute_reply":"2024-05-30T22:13:13.052912Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"          Image Index Finding Label     Bbox [x           y           w  \\\n60   00007676_002.png   Atelectasis  360.677966  439.629386   82.440678   \n61   00005089_002.png   Atelectasis  648.135593  574.137861  263.593220   \n62   00020857_008.png   Atelectasis  190.372881  571.968369  562.983051   \n63   00012291_008.png   Atelectasis  232.677966  631.629386  226.711864   \n64   00018762_002.png   Atelectasis  603.661017  616.786447  257.084746   \n..                ...           ...         ...         ...         ...   \n979  00029464_015.png   Atelectasis  198.940451  352.900747  615.537778   \n980  00025769_001.png   Atelectasis  701.838229  572.491858  103.537778   \n981  00016837_002.png   Atelectasis  140.913785  658.962969  271.928889   \n982  00020124_003.png   Atelectasis  175.047118  580.456302  244.622222   \n983  00026920_000.png   Atelectasis  343.438229  446.198524  120.604444   \n\n             h]  Unnamed: 6  Unnamed: 7  Unnamed: 8      image_id  \\\n60   136.677966         NaN         NaN         NaN  00007676_002   \n61   188.745763         NaN         NaN         NaN  00005089_002   \n62   202.847458         NaN         NaN         NaN  00020857_008   \n63    74.847458         NaN         NaN         NaN  00012291_008   \n64    81.355932         NaN         NaN         NaN  00018762_002   \n..          ...         ...         ...         ...           ...   \n979  323.128889         NaN         NaN         NaN  00029464_015   \n980   63.715556         NaN         NaN         NaN  00025769_001   \n981   94.435556         NaN         NaN         NaN  00016837_002   \n982  103.537778         NaN         NaN         NaN  00020124_003   \n983   53.475556         NaN         NaN         NaN  00026920_000   \n\n     category_id height width  \n60             0   2048  2500  \n61             0   2048  2500  \n62             0   2544  3056  \n63             0   2991  2990  \n64             0   2991  2506  \n..           ...    ...   ...  \n979            0   2021  2021  \n980            0   2544  3056  \n981            0   2446  2592  \n982            0   2991  2754  \n983            0   2544  3056  \n\n[600 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image Index</th>\n      <th>Finding Label</th>\n      <th>Bbox [x</th>\n      <th>y</th>\n      <th>w</th>\n      <th>h]</th>\n      <th>Unnamed: 6</th>\n      <th>Unnamed: 7</th>\n      <th>Unnamed: 8</th>\n      <th>image_id</th>\n      <th>category_id</th>\n      <th>height</th>\n      <th>width</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>60</th>\n      <td>00007676_002.png</td>\n      <td>Atelectasis</td>\n      <td>360.677966</td>\n      <td>439.629386</td>\n      <td>82.440678</td>\n      <td>136.677966</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>00007676_002</td>\n      <td>0</td>\n      <td>2048</td>\n      <td>2500</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>00005089_002.png</td>\n      <td>Atelectasis</td>\n      <td>648.135593</td>\n      <td>574.137861</td>\n      <td>263.593220</td>\n      <td>188.745763</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>00005089_002</td>\n      <td>0</td>\n      <td>2048</td>\n      <td>2500</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>00020857_008.png</td>\n      <td>Atelectasis</td>\n      <td>190.372881</td>\n      <td>571.968369</td>\n      <td>562.983051</td>\n      <td>202.847458</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>00020857_008</td>\n      <td>0</td>\n      <td>2544</td>\n      <td>3056</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>00012291_008.png</td>\n      <td>Atelectasis</td>\n      <td>232.677966</td>\n      <td>631.629386</td>\n      <td>226.711864</td>\n      <td>74.847458</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>00012291_008</td>\n      <td>0</td>\n      <td>2991</td>\n      <td>2990</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>00018762_002.png</td>\n      <td>Atelectasis</td>\n      <td>603.661017</td>\n      <td>616.786447</td>\n      <td>257.084746</td>\n      <td>81.355932</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>00018762_002</td>\n      <td>0</td>\n      <td>2991</td>\n      <td>2506</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>979</th>\n      <td>00029464_015.png</td>\n      <td>Atelectasis</td>\n      <td>198.940451</td>\n      <td>352.900747</td>\n      <td>615.537778</td>\n      <td>323.128889</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>00029464_015</td>\n      <td>0</td>\n      <td>2021</td>\n      <td>2021</td>\n    </tr>\n    <tr>\n      <th>980</th>\n      <td>00025769_001.png</td>\n      <td>Atelectasis</td>\n      <td>701.838229</td>\n      <td>572.491858</td>\n      <td>103.537778</td>\n      <td>63.715556</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>00025769_001</td>\n      <td>0</td>\n      <td>2544</td>\n      <td>3056</td>\n    </tr>\n    <tr>\n      <th>981</th>\n      <td>00016837_002.png</td>\n      <td>Atelectasis</td>\n      <td>140.913785</td>\n      <td>658.962969</td>\n      <td>271.928889</td>\n      <td>94.435556</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>00016837_002</td>\n      <td>0</td>\n      <td>2446</td>\n      <td>2592</td>\n    </tr>\n    <tr>\n      <th>982</th>\n      <td>00020124_003.png</td>\n      <td>Atelectasis</td>\n      <td>175.047118</td>\n      <td>580.456302</td>\n      <td>244.622222</td>\n      <td>103.537778</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>00020124_003</td>\n      <td>0</td>\n      <td>2991</td>\n      <td>2754</td>\n    </tr>\n    <tr>\n      <th>983</th>\n      <td>00026920_000.png</td>\n      <td>Atelectasis</td>\n      <td>343.438229</td>\n      <td>446.198524</td>\n      <td>120.604444</td>\n      <td>53.475556</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>00026920_000</td>\n      <td>0</td>\n      <td>2544</td>\n      <td>3056</td>\n    </tr>\n  </tbody>\n</table>\n<p>600 rows × 13 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def to_annotation(rowbbox):\n    if rowbbox['category_id'] == 8: # PARA OS CASOS QUE NÃO POSSUEM DETECÇÕES\n        dict_return = {\n            'file_name': str(rowbbox['Image Index']),\n            'image_id': str(rowbbox['image_id']),\n            'height': rowbbox['height'],\n            'width': rowbbox['width'],\n            'annotations': []\n        }\n        return dict_return\n    \n    dict_return = {\n        'file_name': str(rowbbox['Image Index']),\n        'image_id': str(rowbbox['image_id']),\n        'height': rowbbox['height'],\n        'width': rowbbox['width'],\n        'annotations': [\n            {\n                'bbox': [rowbbox['Bbox [x'], rowbbox['y'], rowbbox['w'], rowbbox['h]']],\n                'bbox_mode': 1,\n                'category_id': rowbbox['category_id']\n            }\n        ]\n    }\n    return dict_return","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:13:13.055004Z","iopub.execute_input":"2024-05-30T22:13:13.055295Z","iopub.status.idle":"2024-05-30T22:13:13.062710Z","shell.execute_reply.started":"2024-05-30T22:13:13.055270Z","shell.execute_reply":"2024-05-30T22:13:13.061585Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"list_json = []\nfor index, row in bbox_csv.iterrows():\n    presente = False\n    indice = 0\n    for i in range(len(list_json)):\n        if str(row['Image Index']) == list_json[i]['file_name']:\n            presente = True\n            indice = i\n            break\n    \n    if presente:\n        list_json[i]['annotations'].append(\n            {\n                'bbox': [row['Bbox [x'], row['y'], row['w'], row['h]']],\n                'bbox_mode': BoxMode.XYWH_ABS,\n                'category_id': row['category_id']\n            }\n        )\n    else:\n        list_json.append(to_annotation(row))\n\nlen(list_json)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:13:13.064012Z","iopub.execute_input":"2024-05-30T22:13:13.064678Z","iopub.status.idle":"2024-05-30T22:13:13.935385Z","shell.execute_reply.started":"2024-05-30T22:13:13.064644Z","shell.execute_reply":"2024-05-30T22:13:13.934509Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"529"},"metadata":{}}]},{"cell_type":"code","source":"df_ttt = pd.DataFrame(list_json)\ndf_ttt.to_json('temp.json', orient='records')","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:13:13.936722Z","iopub.execute_input":"2024-05-30T22:13:13.937109Z","iopub.status.idle":"2024-05-30T22:13:13.953294Z","shell.execute_reply.started":"2024-05-30T22:13:13.937073Z","shell.execute_reply":"2024-05-30T22:13:13.952231Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"for i in range(len(list_json)):\n    for key, value in all_image_paths.items():\n        if list_json[i]['file_name'] in key:\n            list_json[i]['file_name'] = value\nlist_json[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:13:13.954416Z","iopub.execute_input":"2024-05-30T22:13:13.954829Z","iopub.status.idle":"2024-05-30T22:13:31.499478Z","shell.execute_reply.started":"2024-05-30T22:13:13.954803Z","shell.execute_reply":"2024-05-30T22:13:31.498455Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'file_name': '/kaggle/input/data/images_004/images/00007676_002.png',\n 'image_id': '00007676_002',\n 'height': 2048,\n 'width': 2500,\n 'annotations': [{'bbox': [360.677966101695,\n    439.629386255297,\n    82.4406779661017,\n    136.677966101695],\n   'bbox_mode': 1,\n   'category_id': 0}]}"},"metadata":{}}]},{"cell_type":"code","source":"# To ensure bbox always remap to original image size\nfor i in range(len(list_json)):\n    image = cv2.imread(list_json[i]['file_name'])\n    list_json[i][\"width\"] = image.shape[1]\n    list_json[i][\"height\"] = image.shape[0]\n\nl = None\nfor i in list_json:\n    if i['image_id'] == '00008814_010':\n        l = i\nl","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:13:31.500888Z","iopub.execute_input":"2024-05-30T22:13:31.501272Z","iopub.status.idle":"2024-05-30T22:13:42.261422Z","shell.execute_reply.started":"2024-05-30T22:13:31.501239Z","shell.execute_reply":"2024-05-30T22:13:42.260465Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"{'file_name': '/kaggle/input/data/images_004/images/00008814_010.png',\n 'image_id': '00008814_010',\n 'height': 1024,\n 'width': 1024,\n 'annotations': [{'bbox': [195.128888888889,\n    412.197934027778,\n    665.6,\n    105.813333333333],\n   'bbox_mode': 1,\n   'category_id': 2},\n  {'bbox': [205.368888888889,\n    392.855711805556,\n    643.982222222222,\n    86.4711111111111],\n   'bbox_mode': <BoxMode.XYWH_ABS: 1>,\n   'category_id': 3},\n  {'bbox': [195.527118055556,\n    407.646822916667,\n    669.013333333333,\n    64.8533333333333],\n   'bbox_mode': <BoxMode.XYWH_ABS: 1>,\n   'category_id': 0}]}"},"metadata":{}}]},{"cell_type":"code","source":"listststs = {}\ntrain_data = {}\nval_data = {}\ntest_data = {}\n\nfor i in category_ids.values():\n    listststs[i] = []\n    for j in list_json:\n        try:\n            if j['annotations'][0]['category_id'] == i:\n                listststs[i].append(j)\n        except:\n            if i == 8:\n                listststs[i].append(j)\n\nfor i, x in listststs.items():\n    train_data[i] = x[:int((len(x)+1)*.80)] #80% to training set\n    val_data[i] = x[int((len(x)+1)*.80):int((len(x)+1)*.90)] #10% to val set\n    test_data[i] = x[int((len(x)+1)*.90):] #10% to val set\n\nyyy = []\nxxx = []\nzzz = []\n\nfor i, x in train_data.items():\n    for y in x:\n        yyy.append(y)\n\nfor i, x in val_data.items():\n    for y in x:\n        xxx.append(y)\n        \nfor i, x in test_data.items():\n    for y in x:\n        zzz.append(y)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:13:42.262570Z","iopub.execute_input":"2024-05-30T22:13:42.262860Z","iopub.status.idle":"2024-05-30T22:13:42.273275Z","shell.execute_reply.started":"2024-05-30T22:13:42.262836Z","shell.execute_reply":"2024-05-30T22:13:42.272378Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"len(xxx), len(yyy), len(zzz)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:13:42.274433Z","iopub.execute_input":"2024-05-30T22:13:42.274752Z","iopub.status.idle":"2024-05-30T22:13:42.285527Z","shell.execute_reply.started":"2024-05-30T22:13:42.274719Z","shell.execute_reply":"2024-05-30T22:13:42.284680Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"(53, 424, 52)"},"metadata":{}}]},{"cell_type":"code","source":"import json\nwith open('/kaggle/working/treino.json', 'w', encoding='utf-8') as f:\n    json.dump(yyy, f, ensure_ascii=False, indent=4)\nwith open('/kaggle/working/val.json', 'w', encoding='utf-8') as f:\n    json.dump(xxx, f, ensure_ascii=False, indent=4)\nwith open('/kaggle/working/test.json', 'w', encoding='utf-8') as f:\n    json.dump(zzz, f, ensure_ascii=False, indent=4)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:13:42.286570Z","iopub.execute_input":"2024-05-30T22:13:42.286798Z","iopub.status.idle":"2024-05-30T22:13:42.318225Z","shell.execute_reply.started":"2024-05-30T22:13:42.286778Z","shell.execute_reply":"2024-05-30T22:13:42.317578Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"xray_metadata = {}\n\ndef registrar(d):\n    if d == 'train':\n        return yyy\n    if d == 'val':\n        return xxx\n    return zzz\n\nfor d in [\"train\", \"val\", \"test\"]:\n    DatasetCatalog.register(\"xray_\" + d, lambda d=d: registrar(d))\n    MetadataCatalog.get(\"xray_\" + d).set(thing_classes=list(categorys))\nxray_metadata['train'] = MetadataCatalog.get(\"xray_train\")\nxray_metadata['val'] = MetadataCatalog.get(\"xray_val\")\nxray_metadata['test'] = MetadataCatalog.get(\"xray_test\")","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:13:42.319257Z","iopub.execute_input":"2024-05-30T22:13:42.319585Z","iopub.status.idle":"2024-05-30T22:13:42.325986Z","shell.execute_reply.started":"2024-05-30T22:13:42.319553Z","shell.execute_reply":"2024-05-30T22:13:42.325093Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"for d in random.sample(yyy, 3):\n    img = cv2.imread(d[\"file_name\"])\n    visualizer = Visualizer(img[:, :, ::-1], metadata=xray_metadata['train'], scale=0.5)\n    out = visualizer.draw_dataset_dict(d)\n    plt.imshow(cv2.cvtColor(out.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB)) # converting BGR to RGB for using matplotlib\n    plt.title(d['file_name'])\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:13:42.327085Z","iopub.execute_input":"2024-05-30T22:13:42.327359Z","iopub.status.idle":"2024-05-30T22:13:43.114704Z","shell.execute_reply.started":"2024-05-30T22:13:42.327336Z","shell.execute_reply":"2024-05-30T22:13:43.113795Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"# RetinaNET","metadata":{}},{"cell_type":"code","source":"from detectron2.engine.hooks import HookBase\nfrom detectron2.evaluation import inference_context\nfrom detectron2.utils.logger import log_every_n_seconds\nfrom detectron2.data import DatasetMapper, build_detection_test_loader\nimport detectron2.utils.comm as comm\nimport torch\nimport time\nimport datetime\nimport logging\n\nclass LossEvalHook(HookBase):\n    def __init__(self, eval_period, model, data_loader):\n        self._model = model\n        self._period = eval_period\n        self._data_loader = data_loader\n    \n    def _do_loss_eval(self):\n        # Copying inference_on_dataset from evaluator.py\n        total = len(self._data_loader)\n        num_warmup = min(5, total - 1)\n            \n        start_time = time.perf_counter()\n        total_compute_time = 0\n        losses = []\n        for idx, inputs in enumerate(self._data_loader):            \n            if idx == num_warmup:\n                start_time = time.perf_counter()\n                total_compute_time = 0\n            start_compute_time = time.perf_counter()\n            if torch.cuda.is_available():\n                torch.cuda.synchronize()\n            total_compute_time += time.perf_counter() - start_compute_time\n            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n            seconds_per_img = total_compute_time / iters_after_start\n            if idx >= num_warmup * 2 or seconds_per_img > 5:\n                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n                log_every_n_seconds(\n                    logging.INFO,\n                    \"Loss on Validation  done {}/{}. {:.4f} s / img. ETA={}\".format(\n                        idx + 1, total, seconds_per_img, str(eta)\n                    ),\n                    n=5,\n                )\n            loss_batch = self._get_loss(inputs)\n            losses.append(loss_batch)\n        mean_loss = np.mean(losses)\n        self.trainer.storage.put_scalar('validation_loss', mean_loss)\n        comm.synchronize()\n\n        return losses\n            \n    def _get_loss(self, data):\n        # How loss is calculated on train_loop \n        metrics_dict = self._model(data)\n        metrics_dict = {\n            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n            for k, v in metrics_dict.items()\n        }\n        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n        return total_losses_reduced\n        \n        \n    def after_step(self):\n        next_iter = self.trainer.iter + 1\n        is_final = next_iter == self.trainer.max_iter\n        if is_final or (self._period > 0 and next_iter % self._period == 0):\n            self._do_loss_eval()\n        self.trainer.storage.put_scalars(timetest=12)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:13:43.121244Z","iopub.execute_input":"2024-05-30T22:13:43.121582Z","iopub.status.idle":"2024-05-30T22:13:43.136448Z","shell.execute_reply.started":"2024-05-30T22:13:43.121555Z","shell.execute_reply":"2024-05-30T22:13:43.135331Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"from detectron2.engine import HookBase\nfrom detectron2.data import build_detection_train_loader\nimport detectron2.utils.comm as comm\nfrom detectron2.data import DatasetMapper, build_detection_test_loader\nfrom detectron2.engine import DefaultTrainer\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\n\n\ncfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = (\"xray_train\",)\ncfg.DATASETS.VAL = (\"xray_val\",)\ncfg.DATASETS.TEST = (\"xray_val\",)\ncfg.TEST.EVAL_PERIOD = 50\n#cfg.DATALOADER.NUM_WORKERS = 2\n#cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False  # PARA INCLUIR OS EXEMPLOS NEGATIVOS\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\ncfg.SOLVER.IMS_PER_BATCH = 8  # This is the real \"batch size\" commonly known to deep learning people\n#cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\ncfg.SOLVER.MAX_ITER = 1000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\ncfg.SOLVER.STEPS = []        # do not decay learning rate\n#cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = len(categorys)  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n\nclass MyTrainer(DefaultTrainer):\n    @classmethod\n    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n        if output_folder is None:\n            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n                     \n    def build_hooks(self):\n        hooks = super().build_hooks()\n        hooks.insert(-1,LossEvalHook(\n            cfg.TEST.EVAL_PERIOD,\n            self.model,\n            build_detection_test_loader(\n                self.cfg,\n                self.cfg.DATASETS.TEST[0],\n                DatasetMapper(self.cfg,True)\n            )\n        ))\n        return hooks","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:13:43.137834Z","iopub.execute_input":"2024-05-30T22:13:43.138875Z","iopub.status.idle":"2024-05-30T22:13:43.167548Z","shell.execute_reply.started":"2024-05-30T22:13:43.138839Z","shell.execute_reply":"2024-05-30T22:13:43.166819Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = MyTrainer(cfg)\ntrainer.resume_or_load(resume=False)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:13:43.168540Z","iopub.execute_input":"2024-05-30T22:13:43.168808Z","iopub.status.idle":"2024-05-30T22:34:51.816353Z","shell.execute_reply.started":"2024-05-30T22:13:43.168784Z","shell.execute_reply":"2024-05-30T22:34:51.815177Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"\u001b[32m[05/30 22:13:44 d2.engine.defaults]: \u001b[0mModel:\nRetinaNet(\n  (backbone): FPN(\n    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (top_block): LastLevelP6P7(\n      (p6): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    )\n    (bottom_up): ResNet(\n      (stem): BasicStem(\n        (conv1): Conv2d(\n          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n        )\n      )\n      (res2): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n        )\n      )\n      (res3): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n        (3): BottleneckBlock(\n          (conv1): Conv2d(\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n      )\n      (res4): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (3): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (4): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (5): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (6): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (7): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (8): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (9): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (10): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (11): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (12): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (13): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (14): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (15): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (16): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (17): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (18): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (19): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (20): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (21): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (22): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n      )\n      (res5): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n        )\n      )\n    )\n  )\n  (head): RetinaNetHead(\n    (cls_subnet): Sequential(\n      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (3): ReLU()\n      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (5): ReLU()\n      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (7): ReLU()\n    )\n    (bbox_subnet): Sequential(\n      (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU()\n      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (3): ReLU()\n      (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (5): ReLU()\n      (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (7): ReLU()\n    )\n    (cls_score): Conv2d(256, 720, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (bbox_pred): Conv2d(256, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n  (anchor_generator): DefaultAnchorGenerator(\n    (cell_anchors): BufferList()\n  )\n)\n\u001b[32m[05/30 22:13:44 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 424 images left.\n\u001b[32m[05/30 22:13:44 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n\u001b[36m|  category   | #instances   |   category   | #instances   |  category  | #instances   |\n|:-----------:|:-------------|:------------:|:-------------|:----------:|:-------------|\n| Atelectasis | 98           | Cardiomegaly | 96           |  Effusion  | 99           |\n| Infiltrate  | 102          |  Pneumonia   | 100          |            |              |\n|    total    | 495          |              |              |            |              |\u001b[0m\n\u001b[32m[05/30 22:13:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n\u001b[32m[05/30 22:13:44 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n\u001b[32m[05/30 22:13:44 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:13:44 d2.data.common]: \u001b[0mSerializing 424 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:13:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.10 MiB\n\u001b[32m[05/30 22:13:44 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=8\n\u001b[32m[05/30 22:13:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n\u001b[32m[05/30 22:13:44 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n\u001b[36m|  category   | #instances   |   category   | #instances   |  category  | #instances   |\n|:-----------:|:-------------|:------------:|:-------------|:----------:|:-------------|\n| Atelectasis | 11           | Cardiomegaly | 12           |  Effusion  | 11           |\n| Infiltrate  | 9            |  Pneumonia   | 10           |            |              |\n|    total    | 53           |              |              |            |              |\u001b[0m\n\u001b[32m[05/30 22:13:44 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:13:44 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:13:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:13:44 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/retinanet_R_101_FPN_3x/190397697/model_final_971ab9.pkl ...\n","output_type":"stream"},{"name":"stderr","text":"model_final_971ab9.pkl: 228MB [00:09, 23.5MB/s]                              \n","output_type":"stream"},{"name":"stdout","text":"\u001b[32m[05/30 22:13:54 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3483.)\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[32m[05/30 22:14:19 d2.utils.events]: \u001b[0m eta: 0:17:38  iter: 19  total_loss: 2.093  loss_cls: 1.304  loss_box_reg: 0.7944    time: 1.1510  last_time: 1.1465  data_time: 0.0555  last_data_time: 0.0730   lr: 0.00019981  max_mem: 10364M\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[32m[05/30 22:14:51 d2.utils.events]: \u001b[0m eta: 0:17:17  iter: 39  total_loss: 1.328  loss_cls: 0.767  loss_box_reg: 0.5704    time: 1.0969  last_time: 1.0971  data_time: 0.0394  last_data_time: 0.0245   lr: 0.00039961  max_mem: 10364M\n\u001b[32m[05/30 22:15:02 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:15:02 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:15:02 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:15:02 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:15:02 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 22:15:02 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 22:15:02 d2.evaluation.coco_evaluation]: \u001b[0mTrying to convert 'xray_val' to COCO format ...\n\u001b[32m[05/30 22:15:02 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'xray_val' to COCO format ...)\n\u001b[32m[05/30 22:15:02 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n\u001b[32m[05/30 22:15:02 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 53, #annotations: 53\n\u001b[32m[05/30 22:15:02 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './output/inference/xray_val_coco_format.json' ...\n\u001b[32m[05/30 22:15:02 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:15:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0012 s/iter. Inference: 0.0677 s/iter. Eval: 0.0006 s/iter. Total: 0.0696 s/iter. ETA=0:00:02\n\u001b[32m[05/30 22:15:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.355286 (0.069902 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:15:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.066799 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:15:06 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:15:06 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 22:15:06 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.18s).\nAccumulating evaluation results...\nDONE (t=0.11s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.039\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.082\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.042\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.039\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.122\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.224\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.278\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.284\n\u001b[32m[05/30 22:15:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 3.921 | 8.151  | 4.232  |  nan  | 0.000 | 3.941 |\n\u001b[32m[05/30 22:15:07 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:15:07 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.289 | Cardiomegaly | 17.230 | Effusion   | 0.052 |\n| Infiltrate  | 0.115 | Pneumonia    | 1.917  |            |       |\n\u001b[32m[05/30 22:15:07 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 22:15:07 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 22:15:07 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 22:15:07 d2.evaluation.testing]: \u001b[0mcopypaste: 3.9206,8.1507,4.2324,nan,0.0000,3.9409\n\u001b[32m[05/30 22:15:08 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:03\n\u001b[32m[05/30 22:15:22 d2.utils.events]: \u001b[0m eta: 0:17:03  iter: 59  total_loss: 1.309  loss_cls: 0.7411  loss_box_reg: 0.6026  validation_loss: 0.7331    time: 1.0940  last_time: 1.1050  data_time: 0.0382  last_data_time: 0.0367   lr: 0.00059941  max_mem: 10364M\n\u001b[32m[05/30 22:15:43 d2.utils.events]: \u001b[0m eta: 0:16:41  iter: 79  total_loss: 1.284  loss_cls: 0.7006  loss_box_reg: 0.5561  validation_loss: 0.7331    time: 1.0781  last_time: 0.9539  data_time: 0.0367  last_data_time: 0.0272   lr: 0.00079921  max_mem: 10364M\n\u001b[32m[05/30 22:16:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:16:04 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:16:04 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:16:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:16:04 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 22:16:04 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 22:16:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:16:05 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0012 s/iter. Inference: 0.0651 s/iter. Eval: 0.0004 s/iter. Total: 0.0667 s/iter. ETA=0:00:02\n\u001b[32m[05/30 22:16:08 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.270507 (0.068136 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:16:08 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.064934 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:16:08 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:16:08 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 22:16:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.18s).\nAccumulating evaluation results...\nDONE (t=0.11s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.081\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.169\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.090\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.082\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.199\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.327\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.361\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.371\n\u001b[32m[05/30 22:16:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 8.140 | 16.918 | 8.969  |  nan  | 0.000 | 8.186 |\n\u001b[32m[05/30 22:16:08 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:16:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.467 | Cardiomegaly | 30.607 | Effusion   | 0.128 |\n| Infiltrate  | 4.898 | Pneumonia    | 4.601  |            |       |\n\u001b[32m[05/30 22:16:08 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 22:16:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 22:16:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 22:16:08 d2.evaluation.testing]: \u001b[0mcopypaste: 8.1402,16.9184,8.9694,nan,0.0000,8.1865\n\u001b[32m[05/30 22:16:09 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:02\n\u001b[32m[05/30 22:16:12 d2.utils.events]: \u001b[0m eta: 0:16:19  iter: 99  total_loss: 0.988  loss_cls: 0.5429  loss_box_reg: 0.4581  validation_loss: 0.6296    time: 1.0737  last_time: 1.1030  data_time: 0.0398  last_data_time: 0.0301   lr: 0.00099901  max_mem: 10364M\n\u001b[32m[05/30 22:16:34 d2.utils.events]: \u001b[0m eta: 0:16:00  iter: 119  total_loss: 1.479  loss_cls: 0.7964  loss_box_reg: 0.6808  validation_loss: 0.6296    time: 1.0779  last_time: 1.1007  data_time: 0.0379  last_data_time: 0.0315   lr: 0.0011988  max_mem: 10364M\n\u001b[32m[05/30 22:16:55 d2.utils.events]: \u001b[0m eta: 0:15:37  iter: 139  total_loss: 1.074  loss_cls: 0.59  loss_box_reg: 0.4923  validation_loss: 0.6296    time: 1.0757  last_time: 1.1411  data_time: 0.0351  last_data_time: 0.0704   lr: 0.0013986  max_mem: 10364M\n\u001b[32m[05/30 22:17:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:17:06 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:17:06 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:17:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:17:06 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 22:17:06 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 22:17:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:17:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0011 s/iter. Inference: 0.0651 s/iter. Eval: 0.0004 s/iter. Total: 0.0666 s/iter. ETA=0:00:02\n\u001b[32m[05/30 22:17:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.245914 (0.067623 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:17:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.064726 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:17:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:17:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 22:17:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.19s).\nAccumulating evaluation results...\nDONE (t=0.10s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.105\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.187\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.096\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.105\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.199\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.340\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.365\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.377\n\u001b[32m[05/30 22:17:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n|:------:|:------:|:------:|:-----:|:-----:|:------:|\n| 10.506 | 18.740 | 9.609  |  nan  | 0.000 | 10.537 |\n\u001b[32m[05/30 22:17:10 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:17:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.364 | Cardiomegaly | 39.271 | Effusion   | 0.401 |\n| Infiltrate  | 3.225 | Pneumonia    | 9.270  |            |       |\n\u001b[32m[05/30 22:17:10 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 22:17:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 22:17:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 22:17:10 d2.evaluation.testing]: \u001b[0mcopypaste: 10.5062,18.7397,9.6094,nan,0.0000,10.5366\n\u001b[32m[05/30 22:17:11 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:02\n\u001b[32m[05/30 22:17:25 d2.utils.events]: \u001b[0m eta: 0:15:14  iter: 159  total_loss: 1.214  loss_cls: 0.7058  loss_box_reg: 0.5121  validation_loss: 0.6284    time: 1.0725  last_time: 1.1596  data_time: 0.0444  last_data_time: 0.0753   lr: 0.0015984  max_mem: 10364M\n\u001b[32m[05/30 22:17:46 d2.utils.events]: \u001b[0m eta: 0:14:54  iter: 179  total_loss: 1.084  loss_cls: 0.6153  loss_box_reg: 0.4796  validation_loss: 0.6284    time: 1.0725  last_time: 0.9543  data_time: 0.0418  last_data_time: 0.0307   lr: 0.0017982  max_mem: 10364M\n\u001b[32m[05/30 22:18:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:18:07 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:18:07 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:18:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:18:07 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 22:18:07 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 22:18:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:18:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0012 s/iter. Inference: 0.0650 s/iter. Eval: 0.0004 s/iter. Total: 0.0666 s/iter. ETA=0:00:02\n\u001b[32m[05/30 22:18:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.253031 (0.067771 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:18:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.064875 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:18:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:18:11 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 22:18:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.18s).\nAccumulating evaluation results...\nDONE (t=0.11s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.087\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.164\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.093\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.088\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.172\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.340\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.397\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.033\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.406\n\u001b[32m[05/30 22:18:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 8.730 | 16.443 | 9.264  |  nan  | 0.042 | 8.778 |\n\u001b[32m[05/30 22:18:12 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:18:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.475 | Cardiomegaly | 39.316 | Effusion   | 0.948 |\n| Infiltrate  | 0.751 | Pneumonia    | 2.159  |            |       |\n\u001b[32m[05/30 22:18:12 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 22:18:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 22:18:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 22:18:12 d2.evaluation.testing]: \u001b[0mcopypaste: 8.7297,16.4435,9.2642,nan,0.0416,8.7784\n\u001b[32m[05/30 22:18:13 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:02\n\u001b[32m[05/30 22:18:16 d2.utils.events]: \u001b[0m eta: 0:14:31  iter: 199  total_loss: 0.9732  loss_cls: 0.5395  loss_box_reg: 0.4334  validation_loss: 0.6272    time: 1.0694  last_time: 1.1391  data_time: 0.0435  last_data_time: 0.0748   lr: 0.001998  max_mem: 10364M\n\u001b[32m[05/30 22:18:37 d2.utils.events]: \u001b[0m eta: 0:14:09  iter: 219  total_loss: 1.471  loss_cls: 0.8288  loss_box_reg: 0.6483  validation_loss: 0.6272    time: 1.0686  last_time: 0.9992  data_time: 0.0455  last_data_time: 0.0755   lr: 0.0021978  max_mem: 10364M\n\u001b[32m[05/30 22:18:58 d2.utils.events]: \u001b[0m eta: 0:13:47  iter: 239  total_loss: 0.9339  loss_cls: 0.508  loss_box_reg: 0.417  validation_loss: 0.6272    time: 1.0680  last_time: 1.0840  data_time: 0.0327  last_data_time: 0.0220   lr: 0.0023976  max_mem: 10364M\n\u001b[32m[05/30 22:19:09 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:19:09 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:19:09 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:19:09 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:19:09 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 22:19:09 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 22:19:09 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:19:10 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0013 s/iter. Inference: 0.0648 s/iter. Eval: 0.0004 s/iter. Total: 0.0665 s/iter. ETA=0:00:02\n\u001b[32m[05/30 22:19:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.241344 (0.067528 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:19:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.064610 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:19:13 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:19:13 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 22:19:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.51s).\nAccumulating evaluation results...\nDONE (t=0.12s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.089\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.179\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.103\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.089\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.184\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.322\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.100\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.356\n\u001b[32m[05/30 22:19:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 8.894 | 17.908 | 10.299 |  nan  | 0.130 | 8.932 |\n\u001b[32m[05/30 22:19:13 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:19:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.454 | Cardiomegaly | 38.017 | Effusion   | 0.733 |\n| Infiltrate  | 1.427 | Pneumonia    | 3.841  |            |       |\n\u001b[32m[05/30 22:19:13 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 22:19:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 22:19:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 22:19:13 d2.evaluation.testing]: \u001b[0mcopypaste: 8.8942,17.9080,10.2994,nan,0.1295,8.9324\n\u001b[32m[05/30 22:19:14 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:02\n\u001b[32m[05/30 22:19:28 d2.utils.events]: \u001b[0m eta: 0:13:25  iter: 259  total_loss: 1.18  loss_cls: 0.6345  loss_box_reg: 0.5454  validation_loss: 0.644    time: 1.0674  last_time: 1.1060  data_time: 0.0433  last_data_time: 0.0273   lr: 0.0025974  max_mem: 10364M\n\u001b[32m[05/30 22:19:49 d2.utils.events]: \u001b[0m eta: 0:13:03  iter: 279  total_loss: 1.074  loss_cls: 0.6069  loss_box_reg: 0.4875  validation_loss: 0.644    time: 1.0668  last_time: 1.0051  data_time: 0.0402  last_data_time: 0.0779   lr: 0.0027972  max_mem: 10364M\n\u001b[32m[05/30 22:20:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:20:11 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:20:11 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:20:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:20:11 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 22:20:11 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 22:20:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:20:12 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0010 s/iter. Inference: 0.0650 s/iter. Eval: 0.0004 s/iter. Total: 0.0665 s/iter. ETA=0:00:02\n\u001b[32m[05/30 22:20:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.273760 (0.068203 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:20:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.065297 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:20:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:20:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 22:20:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.17s).\nAccumulating evaluation results...\nDONE (t=0.10s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.112\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.259\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.094\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.112\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.219\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.333\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.390\n\u001b[32m[05/30 22:20:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n|:------:|:------:|:------:|:-----:|:-----:|:------:|\n| 11.172 | 25.941 | 9.446  |  nan  | 0.000 | 11.234 |\n\u001b[32m[05/30 22:20:16 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:20:16 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.819 | Cardiomegaly | 41.967 | Effusion   | 1.839 |\n| Infiltrate  | 2.451 | Pneumonia    | 8.784  |            |       |\n\u001b[32m[05/30 22:20:16 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 22:20:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 22:20:16 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 22:20:16 d2.evaluation.testing]: \u001b[0mcopypaste: 11.1718,25.9408,9.4462,nan,0.0000,11.2338\n\u001b[32m[05/30 22:20:17 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:02\n\u001b[32m[05/30 22:20:20 d2.utils.events]: \u001b[0m eta: 0:12:42  iter: 299  total_loss: 0.8438  loss_cls: 0.4646  loss_box_reg: 0.3936  validation_loss: 0.6007    time: 1.0685  last_time: 1.1357  data_time: 0.0397  last_data_time: 0.0618   lr: 0.002997  max_mem: 10364M\n\u001b[32m[05/30 22:20:42 d2.utils.events]: \u001b[0m eta: 0:12:21  iter: 319  total_loss: 1.484  loss_cls: 0.8021  loss_box_reg: 0.6626  validation_loss: 0.6007    time: 1.0697  last_time: 1.1429  data_time: 0.0417  last_data_time: 0.0724   lr: 0.0031968  max_mem: 10364M\n\u001b[32m[05/30 22:21:03 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 339  total_loss: 0.871  loss_cls: 0.4699  loss_box_reg: 0.3985  validation_loss: 0.6007    time: 1.0698  last_time: 0.9367  data_time: 0.0440  last_data_time: 0.0230   lr: 0.0033966  max_mem: 10364M\n\u001b[32m[05/30 22:21:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:21:14 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:21:14 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:21:14 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:21:14 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 22:21:14 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 22:21:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:21:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0011 s/iter. Inference: 0.0650 s/iter. Eval: 0.0004 s/iter. Total: 0.0666 s/iter. ETA=0:00:02\n\u001b[32m[05/30 22:21:18 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.243202 (0.067567 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:21:18 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.064686 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:21:18 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:21:18 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 22:21:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.18s).\nAccumulating evaluation results...\nDONE (t=0.11s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.109\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.255\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.084\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.045\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.109\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.188\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.358\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.399\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.167\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.405\n\u001b[32m[05/30 22:21:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n|:------:|:------:|:------:|:-----:|:-----:|:------:|\n| 10.909 | 25.456 | 8.372  |  nan  | 4.480 | 10.869 |\n\u001b[32m[05/30 22:21:18 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:21:18 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 1.785 | Cardiomegaly | 37.229 | Effusion   | 3.811 |\n| Infiltrate  | 1.088 | Pneumonia    | 10.632 |            |       |\n\u001b[32m[05/30 22:21:18 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 22:21:18 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 22:21:18 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 22:21:18 d2.evaluation.testing]: \u001b[0mcopypaste: 10.9089,25.4558,8.3724,nan,4.4796,10.8687\n\u001b[32m[05/30 22:21:19 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:02\n\u001b[32m[05/30 22:21:33 d2.utils.events]: \u001b[0m eta: 0:11:38  iter: 359  total_loss: 1.209  loss_cls: 0.7063  loss_box_reg: 0.5115  validation_loss: 0.6081    time: 1.0711  last_time: 1.0904  data_time: 0.0414  last_data_time: 0.0250   lr: 0.0035964  max_mem: 10364M\n\u001b[32m[05/30 22:21:54 d2.utils.events]: \u001b[0m eta: 0:11:16  iter: 379  total_loss: 0.9358  loss_cls: 0.5127  loss_box_reg: 0.4167  validation_loss: 0.6081    time: 1.0699  last_time: 0.9368  data_time: 0.0345  last_data_time: 0.0215   lr: 0.0037962  max_mem: 10364M\n\u001b[32m[05/30 22:22:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:22:16 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:22:16 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:22:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:22:16 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 22:22:16 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 22:22:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:22:17 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0013 s/iter. Inference: 0.0645 s/iter. Eval: 0.0004 s/iter. Total: 0.0662 s/iter. ETA=0:00:02\n\u001b[32m[05/30 22:22:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.229179 (0.067275 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:22:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.064390 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:22:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:22:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 22:22:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.16s).\nAccumulating evaluation results...\nDONE (t=0.10s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.087\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.168\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.077\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.039\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.086\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.191\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.369\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.399\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.200\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.397\n\u001b[32m[05/30 22:22:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 8.657 | 16.809 | 7.656  |  nan  | 3.881 | 8.639 |\n\u001b[32m[05/30 22:22:20 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:22:20 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.459 | Cardiomegaly | 36.401 | Effusion   | 1.491 |\n| Infiltrate  | 1.466 | Pneumonia    | 3.466  |            |       |\n\u001b[32m[05/30 22:22:20 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 22:22:20 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 22:22:20 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 22:22:20 d2.evaluation.testing]: \u001b[0mcopypaste: 8.6567,16.8089,7.6558,nan,3.8812,8.6387\n\u001b[32m[05/30 22:22:21 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:02\n\u001b[32m[05/30 22:22:24 d2.utils.events]: \u001b[0m eta: 0:10:54  iter: 399  total_loss: 0.8206  loss_cls: 0.472  loss_box_reg: 0.3698  validation_loss: 0.6362    time: 1.0702  last_time: 1.0969  data_time: 0.0380  last_data_time: 0.0374   lr: 0.003996  max_mem: 10364M\n\u001b[32m[05/30 22:22:46 d2.utils.events]: \u001b[0m eta: 0:10:32  iter: 419  total_loss: 1.446  loss_cls: 0.8191  loss_box_reg: 0.6254  validation_loss: 0.6362    time: 1.0703  last_time: 0.8549  data_time: 0.0424  last_data_time: 0.0308   lr: 0.0041958  max_mem: 10364M\n\u001b[32m[05/30 22:23:07 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 439  total_loss: 0.8531  loss_cls: 0.4639  loss_box_reg: 0.4007  validation_loss: 0.6362    time: 1.0697  last_time: 1.0010  data_time: 0.0360  last_data_time: 0.0656   lr: 0.0043956  max_mem: 10364M\n\u001b[32m[05/30 22:23:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:23:17 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:23:17 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:23:17 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:23:17 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 22:23:17 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 22:23:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:23:18 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0011 s/iter. Inference: 0.0647 s/iter. Eval: 0.0004 s/iter. Total: 0.0662 s/iter. ETA=0:00:02\n\u001b[32m[05/30 22:23:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.240470 (0.067510 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:23:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.064586 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:23:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:23:21 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 22:23:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.18s).\nAccumulating evaluation results...\nDONE (t=0.10s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.085\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.164\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.078\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.008\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.085\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.169\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.305\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.346\n\u001b[32m[05/30 22:23:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 8.530 | 16.363 | 7.778  |  nan  | 0.842 | 8.540 |\n\u001b[32m[05/30 22:23:22 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:23:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.265 | Cardiomegaly | 34.060 | Effusion   | 0.257 |\n| Infiltrate  | 0.756 | Pneumonia    | 7.312  |            |       |\n\u001b[32m[05/30 22:23:22 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 22:23:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 22:23:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 22:23:22 d2.evaluation.testing]: \u001b[0mcopypaste: 8.5299,16.3629,7.7782,nan,0.8423,8.5402\n\u001b[32m[05/30 22:23:23 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:02\n\u001b[32m[05/30 22:23:37 d2.utils.events]: \u001b[0m eta: 0:09:48  iter: 459  total_loss: 1.031  loss_cls: 0.6053  loss_box_reg: 0.4381  validation_loss: 0.6305    time: 1.0692  last_time: 1.1056  data_time: 0.0433  last_data_time: 0.0305   lr: 0.0045954  max_mem: 10364M\n\u001b[32m[05/30 22:23:58 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 479  total_loss: 1.008  loss_cls: 0.5712  loss_box_reg: 0.4778  validation_loss: 0.6305    time: 1.0691  last_time: 1.0857  data_time: 0.0386  last_data_time: 0.0258   lr: 0.0047952  max_mem: 10364M\n\u001b[32m[05/30 22:24:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:24:19 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:24:19 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:24:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:24:19 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 22:24:19 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 22:24:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:24:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0012 s/iter. Inference: 0.0653 s/iter. Eval: 0.0005 s/iter. Total: 0.0669 s/iter. ETA=0:00:02\n\u001b[32m[05/30 22:24:23 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.254740 (0.067807 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:24:23 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.064904 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:24:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:24:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 22:24:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.20s).\nAccumulating evaluation results...\nDONE (t=0.10s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.114\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.221\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.107\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.042\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.113\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.206\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.370\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.422\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.533\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.407\n\u001b[32m[05/30 22:24:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n|:------:|:------:|:------:|:-----:|:-----:|:------:|\n| 11.366 | 22.149 | 10.740 |  nan  | 4.228 | 11.324 |\n\u001b[32m[05/30 22:24:23 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:24:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.592 | Cardiomegaly | 44.253 | Effusion   | 6.865 |\n| Infiltrate  | 3.811 | Pneumonia    | 1.310  |            |       |\n\u001b[32m[05/30 22:24:23 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 22:24:23 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 22:24:23 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 22:24:23 d2.evaluation.testing]: \u001b[0mcopypaste: 11.3662,22.1486,10.7396,nan,4.2278,11.3242\n\u001b[32m[05/30 22:24:24 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:02\n\u001b[32m[05/30 22:24:28 d2.utils.events]: \u001b[0m eta: 0:09:05  iter: 499  total_loss: 0.8481  loss_cls: 0.455  loss_box_reg: 0.3774  validation_loss: 0.6616    time: 1.0686  last_time: 1.0909  data_time: 0.0448  last_data_time: 0.0313   lr: 0.004995  max_mem: 10364M\n\u001b[32m[05/30 22:24:49 d2.utils.events]: \u001b[0m eta: 0:08:43  iter: 519  total_loss: 1.269  loss_cls: 0.7219  loss_box_reg: 0.5679  validation_loss: 0.6616    time: 1.0684  last_time: 1.1431  data_time: 0.0443  last_data_time: 0.0755   lr: 0.0051948  max_mem: 10364M\n\u001b[32m[05/30 22:25:10 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 539  total_loss: 0.9022  loss_cls: 0.4859  loss_box_reg: 0.3926  validation_loss: 0.6616    time: 1.0680  last_time: 0.9506  data_time: 0.0481  last_data_time: 0.0234   lr: 0.0053946  max_mem: 10364M\n\u001b[32m[05/30 22:25:21 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:25:21 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:25:21 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:25:21 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:25:21 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 22:25:21 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 22:25:21 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:25:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0014 s/iter. Inference: 0.0651 s/iter. Eval: 0.0004 s/iter. Total: 0.0669 s/iter. ETA=0:00:02\n\u001b[32m[05/30 22:25:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.273064 (0.068189 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:25:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.065183 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:25:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:25:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 22:25:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.18s).\nAccumulating evaluation results...\nDONE (t=0.11s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.121\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.227\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.116\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.034\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.121\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.190\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.349\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.412\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.404\n\u001b[32m[05/30 22:25:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n|:------:|:------:|:------:|:-----:|:-----:|:------:|\n| 12.113 | 22.732 | 11.615 |  nan  | 3.371 | 12.086 |\n\u001b[32m[05/30 22:25:25 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:25:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.433 | Cardiomegaly | 49.503 | Effusion   | 1.458 |\n| Infiltrate  | 0.763 | Pneumonia    | 8.407  |            |       |\n\u001b[32m[05/30 22:25:25 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 22:25:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 22:25:25 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 22:25:25 d2.evaluation.testing]: \u001b[0mcopypaste: 12.1129,22.7318,11.6147,nan,3.3708,12.0860\n\u001b[32m[05/30 22:25:26 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:02\n\u001b[32m[05/30 22:25:41 d2.utils.events]: \u001b[0m eta: 0:07:59  iter: 559  total_loss: 1.003  loss_cls: 0.5397  loss_box_reg: 0.4634  validation_loss: 0.6218    time: 1.0686  last_time: 1.0848  data_time: 0.0368  last_data_time: 0.0240   lr: 0.0055944  max_mem: 10364M\n\u001b[32m[05/30 22:26:02 d2.utils.events]: \u001b[0m eta: 0:07:37  iter: 579  total_loss: 0.9977  loss_cls: 0.5555  loss_box_reg: 0.4526  validation_loss: 0.6218    time: 1.0683  last_time: 1.0800  data_time: 0.0401  last_data_time: 0.0227   lr: 0.0057942  max_mem: 10364M\n\u001b[32m[05/30 22:26:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:26:23 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:26:23 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:26:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:26:23 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 22:26:23 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 22:26:23 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:26:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0010 s/iter. Inference: 0.0654 s/iter. Eval: 0.0004 s/iter. Total: 0.0668 s/iter. ETA=0:00:02\n\u001b[32m[05/30 22:26:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.235536 (0.067407 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:26:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.064495 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:26:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:26:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 22:26:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.12s).\nAccumulating evaluation results...\nDONE (t=0.08s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.096\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.212\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.073\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.006\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.097\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.215\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.306\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.067\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.351\n\u001b[32m[05/30 22:26:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 9.620 | 21.239 | 7.350  |  nan  | 0.612 | 9.744 |\n\u001b[32m[05/30 22:26:27 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:26:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 1.253 | Cardiomegaly | 34.897 | Effusion   | 0.354 |\n| Infiltrate  | 7.144 | Pneumonia    | 4.450  |            |       |\n\u001b[32m[05/30 22:26:27 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 22:26:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 22:26:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 22:26:27 d2.evaluation.testing]: \u001b[0mcopypaste: 9.6198,21.2390,7.3497,nan,0.6121,9.7438\n\u001b[32m[05/30 22:26:28 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:02\n\u001b[32m[05/30 22:26:31 d2.utils.events]: \u001b[0m eta: 0:07:15  iter: 599  total_loss: 0.7582  loss_cls: 0.4127  loss_box_reg: 0.3455  validation_loss: 0.6727    time: 1.0676  last_time: 1.0816  data_time: 0.0421  last_data_time: 0.0216   lr: 0.005994  max_mem: 10364M\n\u001b[32m[05/30 22:26:53 d2.utils.events]: \u001b[0m eta: 0:06:53  iter: 619  total_loss: 1.506  loss_cls: 0.9216  loss_box_reg: 0.596  validation_loss: 0.6727    time: 1.0679  last_time: 1.0849  data_time: 0.0383  last_data_time: 0.0236   lr: 0.0061938  max_mem: 10364M\n\u001b[32m[05/30 22:27:14 d2.utils.events]: \u001b[0m eta: 0:06:32  iter: 639  total_loss: 0.9061  loss_cls: 0.5341  loss_box_reg: 0.3964  validation_loss: 0.6727    time: 1.0675  last_time: 1.1049  data_time: 0.0418  last_data_time: 0.0367   lr: 0.0063936  max_mem: 10364M\n\u001b[32m[05/30 22:27:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:27:24 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:27:24 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:27:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:27:24 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 22:27:24 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 22:27:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:27:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0010 s/iter. Inference: 0.0648 s/iter. Eval: 0.0004 s/iter. Total: 0.0662 s/iter. ETA=0:00:02\n\u001b[32m[05/30 22:27:28 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.237936 (0.067457 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:27:28 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.064564 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:27:28 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:27:28 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 22:27:28 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.32s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.19s).\nAccumulating evaluation results...\nDONE (t=0.10s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.103\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.233\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.093\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.030\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.103\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.204\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.308\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.370\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.367\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.357\n\u001b[32m[05/30 22:27:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n|:------:|:------:|:------:|:-----:|:-----:|:------:|\n| 10.325 | 23.253 | 9.302  |  nan  | 3.023 | 10.294 |\n\u001b[32m[05/30 22:27:29 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:27:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.286 | Cardiomegaly | 41.339 | Effusion   | 3.006 |\n| Infiltrate  | 3.508 | Pneumonia    | 3.487  |            |       |\n\u001b[32m[05/30 22:27:29 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 22:27:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 22:27:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 22:27:29 d2.evaluation.testing]: \u001b[0mcopypaste: 10.3252,23.2531,9.3024,nan,3.0226,10.2938\n\u001b[32m[05/30 22:27:30 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:02\n\u001b[32m[05/30 22:27:44 d2.utils.events]: \u001b[0m eta: 0:06:10  iter: 659  total_loss: 1.135  loss_cls: 0.6231  loss_box_reg: 0.4933  validation_loss: 0.6228    time: 1.0670  last_time: 1.1429  data_time: 0.0438  last_data_time: 0.0753   lr: 0.0065934  max_mem: 10364M\n\u001b[32m[05/30 22:28:05 d2.utils.events]: \u001b[0m eta: 0:05:48  iter: 679  total_loss: 1.048  loss_cls: 0.6044  loss_box_reg: 0.4424  validation_loss: 0.6228    time: 1.0663  last_time: 1.1110  data_time: 0.0432  last_data_time: 0.0313   lr: 0.0067932  max_mem: 10364M\n\u001b[32m[05/30 22:28:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:28:26 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:28:26 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:28:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:28:26 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 22:28:26 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 22:28:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:28:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0011 s/iter. Inference: 0.0644 s/iter. Eval: 0.0004 s/iter. Total: 0.0659 s/iter. ETA=0:00:02\n\u001b[32m[05/30 22:28:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.234103 (0.067377 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:28:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.064470 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:28:30 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:28:30 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 22:28:30 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.17s).\nAccumulating evaluation results...\nDONE (t=0.10s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.088\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.223\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.059\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.118\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.087\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.192\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.299\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.332\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.533\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.305\n\u001b[32m[05/30 22:28:31 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n|:-----:|:------:|:------:|:-----:|:------:|:-----:|\n| 8.793 | 22.254 | 5.890  |  nan  | 11.827 | 8.706 |\n\u001b[32m[05/30 22:28:31 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:28:31 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.460 | Cardiomegaly | 31.136 | Effusion   | 1.859 |\n| Infiltrate  | 3.389 | Pneumonia    | 7.121  |            |       |\n\u001b[32m[05/30 22:28:31 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 22:28:31 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 22:28:31 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 22:28:31 d2.evaluation.testing]: \u001b[0mcopypaste: 8.7930,22.2543,5.8896,nan,11.8266,8.7059\n\u001b[32m[05/30 22:28:32 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:02\n\u001b[32m[05/30 22:28:35 d2.utils.events]: \u001b[0m eta: 0:05:26  iter: 699  total_loss: 0.7685  loss_cls: 0.4085  loss_box_reg: 0.3581  validation_loss: 0.6439    time: 1.0668  last_time: 1.1042  data_time: 0.0383  last_data_time: 0.0341   lr: 0.006993  max_mem: 10364M\n\u001b[32m[05/30 22:28:56 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 719  total_loss: 1.27  loss_cls: 0.7373  loss_box_reg: 0.5569  validation_loss: 0.6439    time: 1.0658  last_time: 1.0862  data_time: 0.0409  last_data_time: 0.0237   lr: 0.0071928  max_mem: 10364M\n\u001b[32m[05/30 22:29:18 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 739  total_loss: 0.7934  loss_cls: 0.4548  loss_box_reg: 0.3657  validation_loss: 0.6439    time: 1.0666  last_time: 1.1357  data_time: 0.0486  last_data_time: 0.0654   lr: 0.0073926  max_mem: 10364M\n\u001b[32m[05/30 22:29:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:29:29 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:29:29 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:29:29 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:29:29 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 22:29:29 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 22:29:29 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:29:30 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0012 s/iter. Inference: 0.0649 s/iter. Eval: 0.0004 s/iter. Total: 0.0665 s/iter. ETA=0:00:02\n\u001b[32m[05/30 22:29:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.278318 (0.068298 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:29:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.065408 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:29:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:29:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 22:29:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.17s).\nAccumulating evaluation results...\nDONE (t=0.10s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.127\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.233\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.117\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.040\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.126\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.249\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.361\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.412\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.467\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.397\n\u001b[32m[05/30 22:29:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n|:------:|:------:|:------:|:-----:|:-----:|:------:|\n| 12.653 | 23.306 | 11.663 |  nan  | 3.960 | 12.642 |\n\u001b[32m[05/30 22:29:33 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:29:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.883 | Cardiomegaly | 47.930 | Effusion   | 1.747 |\n| Infiltrate  | 7.502 | Pneumonia    | 5.203  |            |       |\n\u001b[32m[05/30 22:29:33 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 22:29:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 22:29:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 22:29:33 d2.evaluation.testing]: \u001b[0mcopypaste: 12.6527,23.3061,11.6628,nan,3.9600,12.6424\n\u001b[32m[05/30 22:29:34 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:02\n\u001b[32m[05/30 22:29:48 d2.utils.events]: \u001b[0m eta: 0:04:21  iter: 759  total_loss: 1.069  loss_cls: 0.5873  loss_box_reg: 0.4882  validation_loss: 0.6389    time: 1.0673  last_time: 1.1065  data_time: 0.0383  last_data_time: 0.0364   lr: 0.0075924  max_mem: 10364M\n\u001b[32m[05/30 22:30:10 d2.utils.events]: \u001b[0m eta: 0:03:59  iter: 779  total_loss: 0.9271  loss_cls: 0.5407  loss_box_reg: 0.4055  validation_loss: 0.6389    time: 1.0675  last_time: 1.1102  data_time: 0.0394  last_data_time: 0.0303   lr: 0.0077922  max_mem: 10364M\n\u001b[32m[05/30 22:30:31 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:30:31 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:30:31 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:30:31 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:30:31 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 22:30:31 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 22:30:31 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:30:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0010 s/iter. Inference: 0.0648 s/iter. Eval: 0.0005 s/iter. Total: 0.0663 s/iter. ETA=0:00:02\n\u001b[32m[05/30 22:30:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.276360 (0.068258 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:30:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.065367 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:30:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:30:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 22:30:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.18s).\nAccumulating evaluation results...\nDONE (t=0.10s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.087\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.182\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.086\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.187\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.085\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.330\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.382\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.533\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.365\n\u001b[32m[05/30 22:30:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n|:-----:|:------:|:------:|:-----:|:------:|:-----:|\n| 8.689 | 18.237 | 8.621  |  nan  | 18.691 | 8.522 |\n\u001b[32m[05/30 22:30:35 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:30:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 1.214 | Cardiomegaly | 36.673 | Effusion   | 2.966 |\n| Infiltrate  | 1.472 | Pneumonia    | 1.121  |            |       |\n\u001b[32m[05/30 22:30:35 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 22:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 22:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 22:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: 8.6892,18.2369,8.6206,nan,18.6909,8.5221\n\u001b[32m[05/30 22:30:36 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:02\n\u001b[32m[05/30 22:30:40 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 799  total_loss: 0.7384  loss_cls: 0.406  loss_box_reg: 0.338  validation_loss: 0.6603    time: 1.0672  last_time: 0.9740  data_time: 0.0456  last_data_time: 0.0681   lr: 0.007992  max_mem: 10364M\n\u001b[32m[05/30 22:31:01 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 819  total_loss: 1.121  loss_cls: 0.5959  loss_box_reg: 0.5034  validation_loss: 0.6603    time: 1.0676  last_time: 1.1051  data_time: 0.0449  last_data_time: 0.0343   lr: 0.0081918  max_mem: 10364M\n\u001b[32m[05/30 22:31:23 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 839  total_loss: 0.8077  loss_cls: 0.4435  loss_box_reg: 0.3507  validation_loss: 0.6603    time: 1.0682  last_time: 1.1393  data_time: 0.0506  last_data_time: 0.0714   lr: 0.0083916  max_mem: 10364M\n\u001b[32m[05/30 22:31:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:31:34 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:31:34 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:31:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:31:34 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 22:31:34 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 22:31:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:31:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0011 s/iter. Inference: 0.0648 s/iter. Eval: 0.0004 s/iter. Total: 0.0663 s/iter. ETA=0:00:02\n\u001b[32m[05/30 22:31:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.232846 (0.067351 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:31:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.064514 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:31:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:31:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 22:31:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.16s).\nAccumulating evaluation results...\nDONE (t=0.09s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.104\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.223\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.103\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.064\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.104\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.235\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.359\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.419\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.333\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.408\n\u001b[32m[05/30 22:31:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n|:------:|:------:|:------:|:-----:|:-----:|:------:|\n| 10.449 | 22.335 | 10.268 |  nan  | 6.362 | 10.437 |\n\u001b[32m[05/30 22:31:38 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:31:38 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 1.019 | Cardiomegaly | 40.798 | Effusion   | 2.063 |\n| Infiltrate  | 5.804 | Pneumonia    | 2.562  |            |       |\n\u001b[32m[05/30 22:31:38 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 22:31:38 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 22:31:38 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 22:31:38 d2.evaluation.testing]: \u001b[0mcopypaste: 10.4491,22.3351,10.2684,nan,6.3618,10.4368\n\u001b[32m[05/30 22:31:39 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:02\n\u001b[32m[05/30 22:31:53 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 859  total_loss: 1.277  loss_cls: 0.7097  loss_box_reg: 0.4923  validation_loss: 0.6178    time: 1.0682  last_time: 1.1402  data_time: 0.0368  last_data_time: 0.0699   lr: 0.0085914  max_mem: 10364M\n\u001b[32m[05/30 22:32:15 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 879  total_loss: 0.9835  loss_cls: 0.5555  loss_box_reg: 0.398  validation_loss: 0.6178    time: 1.0682  last_time: 1.0999  data_time: 0.0490  last_data_time: 0.0247   lr: 0.0087912  max_mem: 10364M\n\u001b[32m[05/30 22:32:36 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:32:36 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:32:36 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:32:36 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:32:36 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 22:32:36 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 22:32:36 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:32:37 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0011 s/iter. Inference: 0.0650 s/iter. Eval: 0.0004 s/iter. Total: 0.0666 s/iter. ETA=0:00:02\n\u001b[32m[05/30 22:32:40 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.248590 (0.067679 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:32:40 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.064800 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:32:40 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:32:40 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 22:32:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.20s).\nAccumulating evaluation results...\nDONE (t=0.11s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.081\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.198\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.061\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.052\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.080\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.183\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.365\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.567\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.373\n\u001b[32m[05/30 22:32:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 8.054 | 19.768 | 6.110  |  nan  | 5.169 | 8.004 |\n\u001b[32m[05/30 22:32:41 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:32:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.951 | Cardiomegaly | 31.837 | Effusion   | 2.255 |\n| Infiltrate  | 1.669 | Pneumonia    | 3.559  |            |       |\n\u001b[32m[05/30 22:32:41 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 22:32:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 22:32:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 22:32:41 d2.evaluation.testing]: \u001b[0mcopypaste: 8.0541,19.7680,6.1096,nan,5.1685,8.0042\n\u001b[32m[05/30 22:32:42 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:02\n\u001b[32m[05/30 22:32:45 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 899  total_loss: 0.7867  loss_cls: 0.4531  loss_box_reg: 0.3416  validation_loss: 0.6368    time: 1.0684  last_time: 1.0869  data_time: 0.0465  last_data_time: 0.0224   lr: 0.008991  max_mem: 10364M\n\u001b[32m[05/30 22:33:07 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 919  total_loss: 1.181  loss_cls: 0.658  loss_box_reg: 0.5272  validation_loss: 0.6368    time: 1.0688  last_time: 0.9518  data_time: 0.0495  last_data_time: 0.0210   lr: 0.0091908  max_mem: 10364M\n\u001b[32m[05/30 22:33:28 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 939  total_loss: 0.899  loss_cls: 0.481  loss_box_reg: 0.3702  validation_loss: 0.6368    time: 1.0689  last_time: 1.1384  data_time: 0.0467  last_data_time: 0.0739   lr: 0.0093906  max_mem: 10364M\n\u001b[32m[05/30 22:33:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:33:39 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:33:39 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:33:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:33:39 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 22:33:39 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 22:33:39 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:33:40 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0012 s/iter. Inference: 0.0652 s/iter. Eval: 0.0004 s/iter. Total: 0.0669 s/iter. ETA=0:00:02\n\u001b[32m[05/30 22:33:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.253895 (0.067789 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:33:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.064728 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:33:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:33:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 22:33:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.18s).\nAccumulating evaluation results...\nDONE (t=0.10s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.125\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.227\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.140\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.068\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.124\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.235\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.376\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.425\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.367\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.415\n\u001b[32m[05/30 22:33:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n|:------:|:------:|:------:|:-----:|:-----:|:------:|\n| 12.524 | 22.706 | 14.006 |  nan  | 6.751 | 12.448 |\n\u001b[32m[05/30 22:33:44 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:33:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 1.795 | Cardiomegaly | 49.348 | Effusion   | 4.839 |\n| Infiltrate  | 3.129 | Pneumonia    | 3.509  |            |       |\n\u001b[32m[05/30 22:33:44 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 22:33:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 22:33:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 22:33:44 d2.evaluation.testing]: \u001b[0mcopypaste: 12.5239,22.7064,14.0062,nan,6.7511,12.4485\n\u001b[32m[05/30 22:33:45 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:02\n\u001b[32m[05/30 22:33:59 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 959  total_loss: 1.032  loss_cls: 0.5837  loss_box_reg: 0.4372  validation_loss: 0.6129    time: 1.0688  last_time: 0.9755  data_time: 0.0379  last_data_time: 0.0349   lr: 0.0095904  max_mem: 10364M\n\u001b[32m[05/30 22:34:20 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 979  total_loss: 0.9304  loss_cls: 0.5006  loss_box_reg: 0.4222  validation_loss: 0.6129    time: 1.0690  last_time: 0.9417  data_time: 0.0400  last_data_time: 0.0251   lr: 0.0097902  max_mem: 10364M\n\u001b[32m[05/30 22:34:44 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:02\n\u001b[32m[05/30 22:34:47 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 0.7126  loss_cls: 0.3953  loss_box_reg: 0.3155  validation_loss: 0.6561    time: 1.0693  last_time: 1.0976  data_time: 0.0438  last_data_time: 0.0255   lr: 0.00999  max_mem: 10364M\n\u001b[32m[05/30 22:34:47 d2.engine.hooks]: \u001b[0mOverall training speed: 998 iterations in 0:17:47 (1.0694 s / it)\n\u001b[32m[05/30 22:34:47 d2.engine.hooks]: \u001b[0mTotal training time: 0:20:48 (0:03:01 on hooks)\n\u001b[32m[05/30 22:34:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:34:47 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:34:47 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:34:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:34:47 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 22:34:47 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 22:34:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:34:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0010 s/iter. Inference: 0.0648 s/iter. Eval: 0.0004 s/iter. Total: 0.0662 s/iter. ETA=0:00:02\n\u001b[32m[05/30 22:34:51 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.231711 (0.067327 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:34:51 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.064476 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:34:51 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:34:51 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 22:34:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.15s).\nAccumulating evaluation results...\nDONE (t=0.09s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.111\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.209\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.112\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.027\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.111\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.178\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.353\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.133\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.380\n\u001b[32m[05/30 22:34:51 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n|:------:|:------:|:------:|:-----:|:-----:|:------:|\n| 11.139 | 20.883 | 11.208 |  nan  | 2.693 | 11.133 |\n\u001b[32m[05/30 22:34:51 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:34:51 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.460 | Cardiomegaly | 47.883 | Effusion   | 0.831 |\n| Infiltrate  | 3.844 | Pneumonia    | 2.679  |            |       |\n\u001b[32m[05/30 22:34:51 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 22:34:51 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 22:34:51 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 22:34:51 d2.evaluation.testing]: \u001b[0mcopypaste: 11.1394,20.8835,11.2079,nan,2.6931,11.1327\n","output_type":"stream"}]},{"cell_type":"code","source":"# from detectron2.evaluation import COCOEvaluator, inference_on_dataset\nfrom detectron2.data import build_detection_test_loader\n\nevaluator = COCOEvaluator(\"xray_val\", tasks=(\"bbox\",), distributed=False, output_dir=\"./output/\")\ntest_loader = build_detection_test_loader(cfg, \"xray_val\")\nevaluation_results = inference_on_dataset(trainer.model, test_loader, evaluator)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:34:51.818595Z","iopub.execute_input":"2024-05-30T22:34:51.820273Z","iopub.status.idle":"2024-05-30T22:34:56.410008Z","shell.execute_reply.started":"2024-05-30T22:34:51.820229Z","shell.execute_reply":"2024-05-30T22:34:56.409230Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"\u001b[32m[05/30 22:34:51 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[32m[05/30 22:34:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 22:34:51 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 22:34:51 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 22:34:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 22:34:51 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 22:34:53 d2.evaluation.evaluator]: \u001b[0mInference done 23/53. Dataloading: 0.0014 s/iter. Inference: 0.0644 s/iter. Eval: 0.0004 s/iter. Total: 0.0662 s/iter. ETA=0:00:01\n\u001b[32m[05/30 22:34:55 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:03.251270 (0.067735 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:34:55 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.064723 s / iter per device, on 1 devices)\n\u001b[32m[05/30 22:34:55 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 22:34:55 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n\u001b[32m[05/30 22:34:55 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.01s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.51s).\nAccumulating evaluation results...\nDONE (t=0.10s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.111\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.209\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.112\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.027\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.111\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.178\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.353\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.133\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.380\n\u001b[32m[05/30 22:34:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n|:------:|:------:|:------:|:-----:|:-----:|:------:|\n| 11.139 | 20.883 | 11.208 |  nan  | 2.693 | 11.133 |\n\u001b[32m[05/30 22:34:56 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 22:34:56 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.460 | Cardiomegaly | 47.883 | Effusion   | 0.831 |\n| Infiltrate  | 3.844 | Pneumonia    | 2.679  |            |       |\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport matplotlib.pyplot as plt\n\nexperiment_folder = './output'\n\ndef load_json_arr(json_path):\n    lines = []\n    with open(json_path, 'r') as f:\n        for line in f:\n            lines.append(json.loads(line))\n    return lines\n\nexperiment_metrics = load_json_arr(experiment_folder + '/metrics.json')\nexperiment_metrics[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:34:56.411804Z","iopub.execute_input":"2024-05-30T22:34:56.412117Z","iopub.status.idle":"2024-05-30T22:34:56.423380Z","shell.execute_reply.started":"2024-05-30T22:34:56.412090Z","shell.execute_reply":"2024-05-30T22:34:56.422414Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"{'data_time': 0.032306041999959234,\n 'eta_seconds': 1058.6775193400058,\n 'iteration': 19,\n 'loss_box_reg': 0.7944042086601257,\n 'loss_cls': 1.3040509223937988,\n 'lr': 0.00019981,\n 'num_pos_anchors': 32.8125,\n 'rank_data_time': 0.032306041999959234,\n 'time': 1.080283183000006,\n 'timetest': 12.0,\n 'total_loss': 2.0932226479053497}"},"metadata":{}}]},{"cell_type":"code","source":"!mkdir /kaggle/working/imagens","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:34:56.424712Z","iopub.execute_input":"2024-05-30T22:34:56.424990Z","iopub.status.idle":"2024-05-30T22:34:57.427348Z","shell.execute_reply.started":"2024-05-30T22:34:56.424965Z","shell.execute_reply":"2024-05-30T22:34:57.425946Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.0   # set a custom testing threshold\npredictor = DefaultPredictor(cfg)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:34:57.429108Z","iopub.execute_input":"2024-05-30T22:34:57.429449Z","iopub.status.idle":"2024-05-30T22:34:58.749025Z","shell.execute_reply.started":"2024-05-30T22:34:57.429412Z","shell.execute_reply":"2024-05-30T22:34:58.747961Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"\u001b[32m[05/30 22:34:58 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./output/model_final.pth ...\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\n\npredictions = {'image_id': [], 'class': [], 'bbox': [], 'score': []}\n\nfor i in zzz:\n    f = i['file_name']\n    img = cv2.imread(f)\n    outputs = predictor(img)\n    \n    for j in range(len(outputs[\"instances\"].pred_boxes.tensor.cpu().numpy())):\n        predictions['image_id'].append(i['file_name'])\n        predictions['bbox'].append(outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()[j])\n        predictions['class'].append(outputs[\"instances\"].pred_classes.cpu().numpy()[j])\n        predictions['score'].append(outputs[\"instances\"].scores.cpu().numpy()[j])","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:34:58.750644Z","iopub.execute_input":"2024-05-30T22:34:58.750974Z","iopub.status.idle":"2024-05-30T22:35:04.165083Z","shell.execute_reply.started":"2024-05-30T22:34:58.750946Z","shell.execute_reply":"2024-05-30T22:35:04.164239Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"res_df = pd.DataFrame(predictions)\nres_df.to_csv('/kaggle/working/previsoes.csv', index=False)\nres_df","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:35:04.166429Z","iopub.execute_input":"2024-05-30T22:35:04.166822Z","iopub.status.idle":"2024-05-30T22:35:04.636966Z","shell.execute_reply.started":"2024-05-30T22:35:04.166787Z","shell.execute_reply":"2024-05-30T22:35:04.635933Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"                                               image_id  class  \\\n0     /kaggle/input/data/images_001/images/00000583_...      4   \n1     /kaggle/input/data/images_001/images/00000583_...      3   \n2     /kaggle/input/data/images_001/images/00000583_...      2   \n3     /kaggle/input/data/images_001/images/00000583_...      2   \n4     /kaggle/input/data/images_001/images/00000583_...      4   \n...                                                 ...    ...   \n3852  /kaggle/input/data/images_012/images/00029469_...      3   \n3853  /kaggle/input/data/images_012/images/00029469_...      0   \n3854  /kaggle/input/data/images_012/images/00029469_...      0   \n3855  /kaggle/input/data/images_012/images/00029469_...      4   \n3856  /kaggle/input/data/images_012/images/00029469_...      3   \n\n                                              bbox     score  \n0     [698.21576, 396.60086, 893.60266, 730.58325]  0.330655  \n1      [307.27182, 441.8503, 490.30792, 592.28125]  0.274155  \n2         [704.492, 380.0073, 904.45013, 693.5894]  0.269516  \n3        [679.0496, 339.73157, 964.3324, 880.5728]  0.224543  \n4        [258.65695, 451.3853, 528.51013, 818.553]  0.223086  \n...                                            ...       ...  \n3852  [526.58246, 576.97473, 730.34485, 975.18207]  0.051372  \n3853      [209.51956, 555.499, 514.2858, 918.8733]  0.050870  \n3854    [568.2793, 917.2624, 677.29376, 983.86615]  0.050861  \n3855   [125.23434, 685.1721, 262.46155, 889.86285]  0.050663  \n3856    [118.30898, 647.5282, 353.9826, 824.46124]  0.050466  \n\n[3857 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>class</th>\n      <th>bbox</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/data/images_001/images/00000583_...</td>\n      <td>4</td>\n      <td>[698.21576, 396.60086, 893.60266, 730.58325]</td>\n      <td>0.330655</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/data/images_001/images/00000583_...</td>\n      <td>3</td>\n      <td>[307.27182, 441.8503, 490.30792, 592.28125]</td>\n      <td>0.274155</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/data/images_001/images/00000583_...</td>\n      <td>2</td>\n      <td>[704.492, 380.0073, 904.45013, 693.5894]</td>\n      <td>0.269516</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/data/images_001/images/00000583_...</td>\n      <td>2</td>\n      <td>[679.0496, 339.73157, 964.3324, 880.5728]</td>\n      <td>0.224543</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/data/images_001/images/00000583_...</td>\n      <td>4</td>\n      <td>[258.65695, 451.3853, 528.51013, 818.553]</td>\n      <td>0.223086</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3852</th>\n      <td>/kaggle/input/data/images_012/images/00029469_...</td>\n      <td>3</td>\n      <td>[526.58246, 576.97473, 730.34485, 975.18207]</td>\n      <td>0.051372</td>\n    </tr>\n    <tr>\n      <th>3853</th>\n      <td>/kaggle/input/data/images_012/images/00029469_...</td>\n      <td>0</td>\n      <td>[209.51956, 555.499, 514.2858, 918.8733]</td>\n      <td>0.050870</td>\n    </tr>\n    <tr>\n      <th>3854</th>\n      <td>/kaggle/input/data/images_012/images/00029469_...</td>\n      <td>0</td>\n      <td>[568.2793, 917.2624, 677.29376, 983.86615]</td>\n      <td>0.050861</td>\n    </tr>\n    <tr>\n      <th>3855</th>\n      <td>/kaggle/input/data/images_012/images/00029469_...</td>\n      <td>4</td>\n      <td>[125.23434, 685.1721, 262.46155, 889.86285]</td>\n      <td>0.050663</td>\n    </tr>\n    <tr>\n      <th>3856</th>\n      <td>/kaggle/input/data/images_012/images/00029469_...</td>\n      <td>3</td>\n      <td>[118.30898, 647.5282, 353.9826, 824.46124]</td>\n      <td>0.050466</td>\n    </tr>\n  </tbody>\n</table>\n<p>3857 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!zip -r /kaggle/working/retinanet_35000.zip /kaggle/working/output","metadata":{"execution":{"iopub.status.busy":"2024-05-30T22:35:04.638215Z","iopub.execute_input":"2024-05-30T22:35:04.638548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Detectron2 Faster R-CNN","metadata":{}},{"cell_type":"code","source":"from detectron2.engine.hooks import HookBase\nfrom detectron2.evaluation import inference_context\nfrom detectron2.utils.logger import log_every_n_seconds\nfrom detectron2.data import DatasetMapper, build_detection_test_loader\nimport detectron2.utils.comm as comm\nimport torch\nimport time\nimport datetime\nimport logging\n\nclass LossEvalHook(HookBase):\n    def __init__(self, eval_period, model, data_loader):\n        self._model = model\n        self._period = eval_period\n        self._data_loader = data_loader\n    \n    def _do_loss_eval(self):\n        # Copying inference_on_dataset from evaluator.py\n        total = len(self._data_loader)\n        num_warmup = min(5, total - 1)\n            \n        start_time = time.perf_counter()\n        total_compute_time = 0\n        losses = []\n        for idx, inputs in enumerate(self._data_loader):            \n            if idx == num_warmup:\n                start_time = time.perf_counter()\n                total_compute_time = 0\n            start_compute_time = time.perf_counter()\n            if torch.cuda.is_available():\n                torch.cuda.synchronize()\n            total_compute_time += time.perf_counter() - start_compute_time\n            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n            seconds_per_img = total_compute_time / iters_after_start\n            if idx >= num_warmup * 2 or seconds_per_img > 5:\n                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n                log_every_n_seconds(\n                    logging.INFO,\n                    \"Loss on Validation  done {}/{}. {:.4f} s / img. ETA={}\".format(\n                        idx + 1, total, seconds_per_img, str(eta)\n                    ),\n                    n=5,\n                )\n            loss_batch = self._get_loss(inputs)\n            losses.append(loss_batch)\n        mean_loss = np.mean(losses)\n        self.trainer.storage.put_scalar('validation_loss', mean_loss)\n        comm.synchronize()\n\n        return losses\n            \n    def _get_loss(self, data):\n        # How loss is calculated on train_loop \n        metrics_dict = self._model(data)\n        metrics_dict = {\n            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n            for k, v in metrics_dict.items()\n        }\n        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n        return total_losses_reduced\n        \n        \n    def after_step(self):\n        next_iter = self.trainer.iter + 1\n        is_final = next_iter == self.trainer.max_iter\n        if is_final or (self._period > 0 and next_iter % self._period == 0):\n            self._do_loss_eval()\n        self.trainer.storage.put_scalars(timetest=12)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:01:43.701185Z","iopub.execute_input":"2024-05-30T13:01:43.701477Z","iopub.status.idle":"2024-05-30T13:01:43.716154Z","shell.execute_reply.started":"2024-05-30T13:01:43.701451Z","shell.execute_reply":"2024-05-30T13:01:43.715324Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"from detectron2.engine import HookBase\nfrom detectron2.data import build_detection_train_loader\nimport detectron2.utils.comm as comm\nfrom detectron2.data import DatasetMapper, build_detection_test_loader\nfrom detectron2.engine import DefaultTrainer\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\n\n\ncfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\ncfg.DATASETS.TRAIN = (\"xray_train\",)\ncfg.DATASETS.VAL = (\"xray_val\",)\ncfg.DATASETS.TEST = (\"xray_val\",)\ncfg.TEST.EVAL_PERIOD = 50\n#cfg.DATALOADER.NUM_WORKERS = 2\n#cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False  # PARA INCLUIR OS EXEMPLOS NEGATIVOS\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\ncfg.SOLVER.IMS_PER_BATCH = 8  # This is the real \"batch size\" commonly known to deep learning people\n#cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\ncfg.SOLVER.MAX_ITER = 1000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\ncfg.SOLVER.STEPS = []        # do not decay learning rate\n# cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = len(categorys)  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n\nclass MyTrainer(DefaultTrainer):\n    @classmethod\n    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n        if output_folder is None:\n            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n                     \n    def build_hooks(self):\n        hooks = super().build_hooks()\n        hooks.insert(-1,LossEvalHook(\n            cfg.TEST.EVAL_PERIOD,\n            self.model,\n            build_detection_test_loader(\n                self.cfg,\n                self.cfg.DATASETS.TEST[0],\n                DatasetMapper(self.cfg,True)\n            )\n        ))\n        return hooks","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:01:43.717331Z","iopub.execute_input":"2024-05-30T13:01:43.717597Z","iopub.status.idle":"2024-05-30T13:01:43.748123Z","shell.execute_reply.started":"2024-05-30T13:01:43.717575Z","shell.execute_reply":"2024-05-30T13:01:43.747285Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\ntrainer = MyTrainer(cfg)\ntrainer.resume_or_load(resume=False)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:01:43.749060Z","iopub.execute_input":"2024-05-30T13:01:43.749308Z","iopub.status.idle":"2024-05-30T13:18:10.109270Z","shell.execute_reply.started":"2024-05-30T13:01:43.749286Z","shell.execute_reply":"2024-05-30T13:18:10.108193Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"\u001b[32m[05/30 13:01:44 d2.engine.defaults]: \u001b[0mModel:\nGeneralizedRCNN(\n  (backbone): FPN(\n    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (top_block): LastLevelMaxPool()\n    (bottom_up): ResNet(\n      (stem): BasicStem(\n        (conv1): Conv2d(\n          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n        )\n      )\n      (res2): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n        )\n      )\n      (res3): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n        (3): BottleneckBlock(\n          (conv1): Conv2d(\n            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n        )\n      )\n      (res4): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (3): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (4): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n        (5): BottleneckBlock(\n          (conv1): Conv2d(\n            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n          )\n        )\n      )\n      (res5): Sequential(\n        (0): BottleneckBlock(\n          (shortcut): Conv2d(\n            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n          (conv1): Conv2d(\n            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n        )\n        (1): BottleneckBlock(\n          (conv1): Conv2d(\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n        )\n        (2): BottleneckBlock(\n          (conv1): Conv2d(\n            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv2): Conv2d(\n            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n          )\n          (conv3): Conv2d(\n            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n          )\n        )\n      )\n    )\n  )\n  (proposal_generator): RPN(\n    (rpn_head): StandardRPNHead(\n      (conv): Conv2d(\n        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n        (activation): ReLU()\n      )\n      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (anchor_generator): DefaultAnchorGenerator(\n      (cell_anchors): BufferList()\n    )\n  )\n  (roi_heads): StandardROIHeads(\n    (box_pooler): ROIPooler(\n      (level_poolers): ModuleList(\n        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n      )\n    )\n    (box_head): FastRCNNConvFCHead(\n      (flatten): Flatten(start_dim=1, end_dim=-1)\n      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n      (fc_relu1): ReLU()\n      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n      (fc_relu2): ReLU()\n    )\n    (box_predictor): FastRCNNOutputLayers(\n      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n    )\n  )\n)\n\u001b[32m[05/30 13:01:44 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 424 images left.\n\u001b[32m[05/30 13:01:44 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n\u001b[36m|  category   | #instances   |   category   | #instances   |  category  | #instances   |\n|:-----------:|:-------------|:------------:|:-------------|:----------:|:-------------|\n| Atelectasis | 98           | Cardiomegaly | 96           |  Effusion  | 99           |\n| Infiltrate  | 102          |  Pneumonia   | 100          |            |              |\n|    total    | 495          |              |              |            |              |\u001b[0m\n\u001b[32m[05/30 13:01:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n\u001b[32m[05/30 13:01:44 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n\u001b[32m[05/30 13:01:44 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:01:44 d2.data.common]: \u001b[0mSerializing 424 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:01:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.10 MiB\n\u001b[32m[05/30 13:01:44 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=8\n\u001b[32m[05/30 13:01:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n\u001b[32m[05/30 13:01:44 d2.data.build]: \u001b[0mDistribution of instances among all 5 categories:\n\u001b[36m|  category   | #instances   |   category   | #instances   |  category  | #instances   |\n|:-----------:|:-------------|:------------:|:-------------|:----------:|:-------------|\n| Atelectasis | 11           | Cardiomegaly | 12           |  Effusion  | 11           |\n| Infiltrate  | 9            |  Pneumonia   | 10           |            |              |\n|    total    | 53           |              |              |            |              |\u001b[0m\n\u001b[32m[05/30 13:01:44 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:01:44 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:01:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:01:44 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n","output_type":"stream"},{"name":"stderr","text":"model_final_280758.pkl: 167MB [00:02, 70.8MB/s]                            \n","output_type":"stream"},{"name":"stdout","text":"\u001b[32m[05/30 13:01:47 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3483.)\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","output_type":"stream"},{"name":"stdout","text":"\u001b[32m[05/30 13:02:06 d2.utils.events]: \u001b[0m eta: 0:13:41  iter: 19  total_loss: 1.007  loss_cls: 0.8557  loss_box_reg: 0.07008  loss_rpn_cls: 0.07377  loss_rpn_loc: 0.01201    time: 0.8395  last_time: 0.8849  data_time: 0.0510  last_data_time: 0.0672   lr: 0.00039962  max_mem: 5721M\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"\u001b[32m[05/30 13:02:34 d2.utils.events]: \u001b[0m eta: 0:13:23  iter: 39  total_loss: 0.3153  loss_cls: 0.1671  loss_box_reg: 0.088  loss_rpn_cls: 0.04223  loss_rpn_loc: 0.009274    time: 0.8315  last_time: 0.7496  data_time: 0.0373  last_data_time: 0.0306   lr: 0.00079922  max_mem: 5721M\n\u001b[32m[05/30 13:02:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:02:42 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:02:42 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:02:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:02:42 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 13:02:42 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 13:02:42 d2.evaluation.coco_evaluation]: \u001b[0mTrying to convert 'xray_val' to COCO format ...\n\u001b[32m[05/30 13:02:42 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'xray_val' to COCO format ...)\n\u001b[32m[05/30 13:02:42 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n\u001b[32m[05/30 13:02:42 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 53, #annotations: 53\n\u001b[32m[05/30 13:02:42 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at './output/inference/xray_val_coco_format.json' ...\n\u001b[32m[05/30 13:02:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:02:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0014 s/iter. Inference: 0.0481 s/iter. Eval: 0.0001 s/iter. Total: 0.0495 s/iter. ETA=0:00:02\n\u001b[32m[05/30 13:02:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.422135 (0.050461 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:02:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.048033 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:02:45 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:02:45 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 13:02:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.01s).\nAccumulating evaluation results...\nDONE (t=0.02s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.010\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.034\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.010\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.013\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.013\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.013\n\u001b[32m[05/30 13:02:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 1.030 | 3.366  | 0.891  |  nan  | 0.000 | 1.030 |\n\u001b[32m[05/30 13:02:45 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:02:45 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP    | category   | AP    |\n|:------------|:------|:-------------|:------|:-----------|:------|\n| Atelectasis | 0.000 | Cardiomegaly | 5.149 | Effusion   | 0.000 |\n| Infiltrate  | 0.000 | Pneumonia    | 0.000 |            |       |\n\u001b[32m[05/30 13:02:45 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 13:02:45 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 13:02:45 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 13:02:45 d2.evaluation.testing]: \u001b[0mcopypaste: 1.0297,3.3663,0.8911,nan,0.0000,1.0297\n\u001b[32m[05/30 13:02:46 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:01\n\u001b[32m[05/30 13:02:57 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 59  total_loss: 0.2811  loss_cls: 0.1403  loss_box_reg: 0.08994  loss_rpn_cls: 0.03584  loss_rpn_loc: 0.009038  validation_loss: 0.2899    time: 0.8282  last_time: 0.8842  data_time: 0.0474  last_data_time: 0.0746   lr: 0.0011988  max_mem: 5721M\n\u001b[32m[05/30 13:03:13 d2.utils.events]: \u001b[0m eta: 0:12:46  iter: 79  total_loss: 0.2964  loss_cls: 0.1492  loss_box_reg: 0.1112  loss_rpn_cls: 0.02315  loss_rpn_loc: 0.008669  validation_loss: 0.2899    time: 0.8285  last_time: 0.8282  data_time: 0.0459  last_data_time: 0.0296   lr: 0.0015984  max_mem: 5721M\n\u001b[32m[05/30 13:03:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:03:30 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:03:30 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:03:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:03:30 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 13:03:30 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 13:03:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:03:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0014 s/iter. Inference: 0.0485 s/iter. Eval: 0.0002 s/iter. Total: 0.0502 s/iter. ETA=0:00:02\n\u001b[32m[05/30 13:03:33 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.460295 (0.051256 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:03:33 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.048624 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:03:33 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:03:33 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 13:03:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.03s).\nAccumulating evaluation results...\nDONE (t=0.03s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.023\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.071\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.022\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.023\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.047\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.054\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.054\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.054\n\u001b[32m[05/30 13:03:33 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 2.285 | 7.129  | 2.171  |  nan  | 0.000 | 2.285 |\n\u001b[32m[05/30 13:03:33 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:03:33 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.000 | Cardiomegaly | 11.315 | Effusion   | 0.000 |\n| Infiltrate  | 0.000 | Pneumonia    | 0.109  |            |       |\n\u001b[32m[05/30 13:03:33 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 13:03:33 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 13:03:33 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 13:03:33 d2.evaluation.testing]: \u001b[0mcopypaste: 2.2848,7.1293,2.1711,nan,0.0000,2.2848\n\u001b[32m[05/30 13:03:34 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:01\n\u001b[32m[05/30 13:03:36 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 99  total_loss: 0.3055  loss_cls: 0.1568  loss_box_reg: 0.1147  loss_rpn_cls: 0.02203  loss_rpn_loc: 0.007537  validation_loss: 0.2868    time: 0.8312  last_time: 0.8720  data_time: 0.0552  last_data_time: 0.0689   lr: 0.001998  max_mem: 5721M\n\u001b[32m[05/30 13:03:53 d2.utils.events]: \u001b[0m eta: 0:12:13  iter: 119  total_loss: 0.306  loss_cls: 0.1578  loss_box_reg: 0.1174  loss_rpn_cls: 0.01961  loss_rpn_loc: 0.007774  validation_loss: 0.2868    time: 0.8326  last_time: 0.8196  data_time: 0.0482  last_data_time: 0.0218   lr: 0.0023976  max_mem: 5721M\n\u001b[32m[05/30 13:04:10 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 139  total_loss: 0.3105  loss_cls: 0.1605  loss_box_reg: 0.1263  loss_rpn_cls: 0.02279  loss_rpn_loc: 0.008793  validation_loss: 0.2868    time: 0.8358  last_time: 0.8753  data_time: 0.0505  last_data_time: 0.0644   lr: 0.0027972  max_mem: 5721M\n\u001b[32m[05/30 13:04:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:04:19 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:04:19 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:04:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:04:19 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 13:04:19 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 13:04:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:04:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0011 s/iter. Inference: 0.0488 s/iter. Eval: 0.0003 s/iter. Total: 0.0501 s/iter. ETA=0:00:02\n\u001b[32m[05/30 13:04:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.451590 (0.051075 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:04:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.048502 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:04:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:04:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 13:04:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.04s).\nAccumulating evaluation results...\nDONE (t=0.03s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.023\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.064\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.006\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.023\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.081\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.098\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.098\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.098\n\u001b[32m[05/30 13:04:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 2.323 | 6.379  | 0.644  |  nan  | 0.000 | 2.323 |\n\u001b[32m[05/30 13:04:22 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:04:22 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.000 | Cardiomegaly | 11.026 | Effusion   | 0.000 |\n| Infiltrate  | 0.171 | Pneumonia    | 0.419  |            |       |\n\u001b[32m[05/30 13:04:22 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 13:04:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 13:04:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 13:04:22 d2.evaluation.testing]: \u001b[0mcopypaste: 2.3233,6.3788,0.6445,nan,0.0000,2.3233\n\u001b[32m[05/30 13:04:23 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:01\n\u001b[32m[05/30 13:04:33 d2.utils.events]: \u001b[0m eta: 0:11:43  iter: 159  total_loss: 0.325  loss_cls: 0.1648  loss_box_reg: 0.1359  loss_rpn_cls: 0.01929  loss_rpn_loc: 0.006972  validation_loss: 0.2905    time: 0.8366  last_time: 0.7640  data_time: 0.0524  last_data_time: 0.0241   lr: 0.0031968  max_mem: 5721M\n\u001b[32m[05/30 13:04:50 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 179  total_loss: 0.314  loss_cls: 0.1535  loss_box_reg: 0.1322  loss_rpn_cls: 0.01552  loss_rpn_loc: 0.00775  validation_loss: 0.2905    time: 0.8370  last_time: 0.8739  data_time: 0.0500  last_data_time: 0.0631   lr: 0.0035964  max_mem: 5721M\n\u001b[32m[05/30 13:05:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:05:07 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:05:07 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:05:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:05:07 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 13:05:07 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 13:05:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:05:08 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0013 s/iter. Inference: 0.0485 s/iter. Eval: 0.0003 s/iter. Total: 0.0501 s/iter. ETA=0:00:02\n\u001b[32m[05/30 13:05:10 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.475056 (0.051564 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:05:10 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.048864 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:05:10 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:05:10 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 13:05:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.07s).\nAccumulating evaluation results...\nDONE (t=0.05s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.055\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.127\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.043\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.055\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.127\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.177\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.177\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.177\n\u001b[32m[05/30 13:05:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 5.537 | 12.679 | 4.273  |  nan  | 0.000 | 5.537 |\n\u001b[32m[05/30 13:05:10 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:05:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.000 | Cardiomegaly | 23.659 | Effusion   | 0.180 |\n| Infiltrate  | 0.691 | Pneumonia    | 3.156  |            |       |\n\u001b[32m[05/30 13:05:10 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 13:05:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 13:05:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 13:05:10 d2.evaluation.testing]: \u001b[0mcopypaste: 5.5371,12.6794,4.2728,nan,0.0000,5.5371\n\u001b[32m[05/30 13:05:11 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:01\n\u001b[32m[05/30 13:05:13 d2.utils.events]: \u001b[0m eta: 0:11:11  iter: 199  total_loss: 0.3263  loss_cls: 0.1612  loss_box_reg: 0.1374  loss_rpn_cls: 0.01609  loss_rpn_loc: 0.007093  validation_loss: 0.3003    time: 0.8381  last_time: 0.8429  data_time: 0.0461  last_data_time: 0.0273   lr: 0.003996  max_mem: 5721M\n\u001b[32m[05/30 13:05:30 d2.utils.events]: \u001b[0m eta: 0:10:54  iter: 219  total_loss: 0.2911  loss_cls: 0.1551  loss_box_reg: 0.1216  loss_rpn_cls: 0.01452  loss_rpn_loc: 0.006712  validation_loss: 0.3003    time: 0.8394  last_time: 0.8879  data_time: 0.0500  last_data_time: 0.0768   lr: 0.0043956  max_mem: 5721M\n\u001b[32m[05/30 13:05:47 d2.utils.events]: \u001b[0m eta: 0:10:38  iter: 239  total_loss: 0.2899  loss_cls: 0.1391  loss_box_reg: 0.1238  loss_rpn_cls: 0.01437  loss_rpn_loc: 0.007299  validation_loss: 0.3003    time: 0.8402  last_time: 0.8819  data_time: 0.0430  last_data_time: 0.0677   lr: 0.0047952  max_mem: 5721M\n\u001b[32m[05/30 13:05:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:05:56 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:05:56 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:05:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:05:56 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 13:05:56 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 13:05:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:05:57 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0013 s/iter. Inference: 0.0516 s/iter. Eval: 0.0004 s/iter. Total: 0.0533 s/iter. ETA=0:00:02\n\u001b[32m[05/30 13:05:59 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.643763 (0.055078 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:05:59 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.051943 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:05:59 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:05:59 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 13:05:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.07s).\nAccumulating evaluation results...\nDONE (t=0.04s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.048\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.118\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.033\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.048\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.143\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.177\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.177\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.177\n\u001b[32m[05/30 13:05:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 4.769 | 11.848 | 3.307  |  nan  | 0.000 | 4.769 |\n\u001b[32m[05/30 13:05:59 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:05:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.000 | Cardiomegaly | 20.197 | Effusion   | 0.272 |\n| Infiltrate  | 1.118 | Pneumonia    | 2.256  |            |       |\n\u001b[32m[05/30 13:05:59 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 13:05:59 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 13:05:59 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 13:05:59 d2.evaluation.testing]: \u001b[0mcopypaste: 4.7686,11.8477,3.3073,nan,0.0000,4.7686\n\u001b[32m[05/30 13:06:00 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:01\n\u001b[32m[05/30 13:06:11 d2.utils.events]: \u001b[0m eta: 0:10:22  iter: 259  total_loss: 0.2704  loss_cls: 0.1393  loss_box_reg: 0.1085  loss_rpn_cls: 0.01466  loss_rpn_loc: 0.006853  validation_loss: 0.2657    time: 0.8416  last_time: 0.8859  data_time: 0.0506  last_data_time: 0.0661   lr: 0.0051948  max_mem: 5721M\n\u001b[32m[05/30 13:06:28 d2.utils.events]: \u001b[0m eta: 0:10:05  iter: 279  total_loss: 0.2525  loss_cls: 0.1317  loss_box_reg: 0.1084  loss_rpn_cls: 0.01298  loss_rpn_loc: 0.007146  validation_loss: 0.2657    time: 0.8415  last_time: 0.8715  data_time: 0.0481  last_data_time: 0.0697   lr: 0.0055944  max_mem: 5721M\n\u001b[32m[05/30 13:06:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:06:44 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:06:44 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:06:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:06:44 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 13:06:44 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 13:06:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:06:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0012 s/iter. Inference: 0.0494 s/iter. Eval: 0.0003 s/iter. Total: 0.0509 s/iter. ETA=0:00:02\n\u001b[32m[05/30 13:06:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.515745 (0.052411 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:06:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.049551 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:06:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:06:47 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 13:06:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.05s).\nAccumulating evaluation results...\nDONE (t=0.04s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.068\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.153\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.071\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.068\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.171\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.219\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.219\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.219\n\u001b[32m[05/30 13:06:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 6.765 | 15.271 | 7.065  |  nan  | 0.000 | 6.765 |\n\u001b[32m[05/30 13:06:48 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:06:48 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.000 | Cardiomegaly | 27.631 | Effusion   | 1.391 |\n| Infiltrate  | 1.079 | Pneumonia    | 3.726  |            |       |\n\u001b[32m[05/30 13:06:48 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 13:06:48 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 13:06:48 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 13:06:48 d2.evaluation.testing]: \u001b[0mcopypaste: 6.7655,15.2710,7.0646,nan,0.0000,6.7655\n\u001b[32m[05/30 13:06:48 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:01\n\u001b[32m[05/30 13:06:51 d2.utils.events]: \u001b[0m eta: 0:09:48  iter: 299  total_loss: 0.2648  loss_cls: 0.1404  loss_box_reg: 0.105  loss_rpn_cls: 0.01255  loss_rpn_loc: 0.007247  validation_loss: 0.2498    time: 0.8407  last_time: 0.8273  data_time: 0.0351  last_data_time: 0.0226   lr: 0.005994  max_mem: 5721M\n\u001b[32m[05/30 13:07:08 d2.utils.events]: \u001b[0m eta: 0:09:31  iter: 319  total_loss: 0.2702  loss_cls: 0.1476  loss_box_reg: 0.1103  loss_rpn_cls: 0.01491  loss_rpn_loc: 0.007409  validation_loss: 0.2498    time: 0.8410  last_time: 0.8293  data_time: 0.0470  last_data_time: 0.0257   lr: 0.0063936  max_mem: 5721M\n\u001b[32m[05/30 13:07:24 d2.utils.events]: \u001b[0m eta: 0:09:14  iter: 339  total_loss: 0.2818  loss_cls: 0.1482  loss_box_reg: 0.1142  loss_rpn_cls: 0.01185  loss_rpn_loc: 0.007254  validation_loss: 0.2498    time: 0.8408  last_time: 0.8499  data_time: 0.0415  last_data_time: 0.0351   lr: 0.0067932  max_mem: 5721M\n\u001b[32m[05/30 13:07:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:07:33 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:07:33 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:07:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:07:33 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 13:07:33 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 13:07:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:07:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0014 s/iter. Inference: 0.0554 s/iter. Eval: 0.0003 s/iter. Total: 0.0571 s/iter. ETA=0:00:02\n\u001b[32m[05/30 13:07:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.590109 (0.053961 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:07:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.051192 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:07:36 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:07:36 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 13:07:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.08s).\nAccumulating evaluation results...\nDONE (t=0.05s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.091\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.199\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.085\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.091\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.192\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.274\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.276\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.279\n\u001b[32m[05/30 13:07:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 9.110 | 19.875 | 8.488  |  nan  | 0.000 | 9.118 |\n\u001b[32m[05/30 13:07:36 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:07:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP     |\n|:------------|:------|:-------------|:-------|:-----------|:-------|\n| Atelectasis | 0.092 | Cardiomegaly | 29.948 | Effusion   | 10.483 |\n| Infiltrate  | 2.134 | Pneumonia    | 2.894  |            |        |\n\u001b[32m[05/30 13:07:36 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 13:07:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 13:07:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 13:07:36 d2.evaluation.testing]: \u001b[0mcopypaste: 9.1104,19.8748,8.4883,nan,0.0000,9.1183\n\u001b[32m[05/30 13:07:37 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:01\n\u001b[32m[05/30 13:07:48 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 359  total_loss: 0.2622  loss_cls: 0.1359  loss_box_reg: 0.1058  loss_rpn_cls: 0.01223  loss_rpn_loc: 0.00724  validation_loss: 0.2387    time: 0.8408  last_time: 0.8365  data_time: 0.0435  last_data_time: 0.0306   lr: 0.0071928  max_mem: 5721M\n\u001b[32m[05/30 13:08:05 d2.utils.events]: \u001b[0m eta: 0:08:41  iter: 379  total_loss: 0.2791  loss_cls: 0.1434  loss_box_reg: 0.09675  loss_rpn_cls: 0.01261  loss_rpn_loc: 0.007406  validation_loss: 0.2387    time: 0.8407  last_time: 0.8735  data_time: 0.0459  last_data_time: 0.0676   lr: 0.0075924  max_mem: 5721M\n\u001b[32m[05/30 13:08:22 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:08:22 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:08:22 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:08:22 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:08:22 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 13:08:22 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 13:08:22 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:08:23 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0013 s/iter. Inference: 0.0491 s/iter. Eval: 0.0003 s/iter. Total: 0.0506 s/iter. ETA=0:00:02\n\u001b[32m[05/30 13:08:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.477681 (0.051618 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:08:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.048898 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:08:25 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:08:25 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 13:08:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.06s).\nAccumulating evaluation results...\nDONE (t=0.04s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.068\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.191\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.027\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.034\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.068\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.134\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.215\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.215\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.200\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.207\n\u001b[32m[05/30 13:08:25 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 6.789 | 19.127 | 2.681  |  nan  | 3.366 | 6.752 |\n\u001b[32m[05/30 13:08:25 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:08:25 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.373 | Cardiomegaly | 22.640 | Effusion   | 6.264 |\n| Infiltrate  | 0.710 | Pneumonia    | 3.961  |            |       |\n\u001b[32m[05/30 13:08:25 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 13:08:25 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 13:08:25 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 13:08:25 d2.evaluation.testing]: \u001b[0mcopypaste: 6.7894,19.1269,2.6814,nan,3.3663,6.7518\n\u001b[32m[05/30 13:08:26 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:01\n\u001b[32m[05/30 13:08:28 d2.utils.events]: \u001b[0m eta: 0:08:24  iter: 399  total_loss: 0.2586  loss_cls: 0.1374  loss_box_reg: 0.1023  loss_rpn_cls: 0.0109  loss_rpn_loc: 0.006094  validation_loss: 0.249    time: 0.8417  last_time: 0.8601  data_time: 0.0524  last_data_time: 0.0318   lr: 0.007992  max_mem: 5721M\n\u001b[32m[05/30 13:08:45 d2.utils.events]: \u001b[0m eta: 0:08:08  iter: 419  total_loss: 0.2715  loss_cls: 0.1451  loss_box_reg: 0.1104  loss_rpn_cls: 0.01351  loss_rpn_loc: 0.007239  validation_loss: 0.249    time: 0.8426  last_time: 0.8612  data_time: 0.0472  last_data_time: 0.0356   lr: 0.0083916  max_mem: 5721M\n\u001b[32m[05/30 13:09:02 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 439  total_loss: 0.2427  loss_cls: 0.1247  loss_box_reg: 0.0917  loss_rpn_cls: 0.01104  loss_rpn_loc: 0.00755  validation_loss: 0.249    time: 0.8420  last_time: 0.7715  data_time: 0.0427  last_data_time: 0.0319   lr: 0.0087912  max_mem: 5721M\n\u001b[32m[05/30 13:09:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:09:10 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:09:10 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:09:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:09:10 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 13:09:10 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 13:09:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:09:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0012 s/iter. Inference: 0.0488 s/iter. Eval: 0.0003 s/iter. Total: 0.0503 s/iter. ETA=0:00:02\n\u001b[32m[05/30 13:09:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.473777 (0.051537 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:09:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.048816 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:09:13 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:09:13 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 13:09:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.06s).\nAccumulating evaluation results...\nDONE (t=0.04s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.094\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.204\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.085\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.095\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.217\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.289\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.289\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.294\n\u001b[32m[05/30 13:09:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 9.360 | 20.404 | 8.519  |  nan  | 0.000 | 9.480 |\n\u001b[32m[05/30 13:09:13 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:09:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 1.758 | Cardiomegaly | 33.884 | Effusion   | 7.137 |\n| Infiltrate  | 1.054 | Pneumonia    | 2.964  |            |       |\n\u001b[32m[05/30 13:09:13 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 13:09:13 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 13:09:13 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 13:09:13 d2.evaluation.testing]: \u001b[0mcopypaste: 9.3595,20.4038,8.5188,nan,0.0000,9.4798\n\u001b[32m[05/30 13:09:14 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:01\n\u001b[32m[05/30 13:09:25 d2.utils.events]: \u001b[0m eta: 0:07:35  iter: 459  total_loss: 0.2484  loss_cls: 0.1248  loss_box_reg: 0.1056  loss_rpn_cls: 0.01285  loss_rpn_loc: 0.007296  validation_loss: 0.2486    time: 0.8425  last_time: 0.8619  data_time: 0.0501  last_data_time: 0.0391   lr: 0.0091908  max_mem: 5721M\n\u001b[32m[05/30 13:09:42 d2.utils.events]: \u001b[0m eta: 0:07:17  iter: 479  total_loss: 0.2626  loss_cls: 0.1448  loss_box_reg: 0.1085  loss_rpn_cls: 0.01103  loss_rpn_loc: 0.008498  validation_loss: 0.2486    time: 0.8422  last_time: 0.8878  data_time: 0.0411  last_data_time: 0.0773   lr: 0.0095904  max_mem: 5721M\n\u001b[32m[05/30 13:09:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:09:58 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:09:58 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:09:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:09:58 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 13:09:58 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 13:09:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:09:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0013 s/iter. Inference: 0.0496 s/iter. Eval: 0.0003 s/iter. Total: 0.0512 s/iter. ETA=0:00:02\n\u001b[32m[05/30 13:10:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.484096 (0.051752 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:10:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.049081 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:10:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:10:02 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 13:10:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.06s).\nAccumulating evaluation results...\nDONE (t=0.04s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.097\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.207\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.097\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.097\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.171\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.246\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.248\n\u001b[32m[05/30 13:10:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 9.652 | 20.690 | 9.700  |  nan  | 0.000 | 9.701 |\n\u001b[32m[05/30 13:10:02 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:10:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.778 | Cardiomegaly | 35.729 | Effusion   | 9.001 |\n| Infiltrate  | 0.900 | Pneumonia    | 1.851  |            |       |\n\u001b[32m[05/30 13:10:02 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 13:10:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 13:10:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 13:10:02 d2.evaluation.testing]: \u001b[0mcopypaste: 9.6518,20.6899,9.7002,nan,0.0000,9.7009\n\u001b[32m[05/30 13:10:02 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:01\n\u001b[32m[05/30 13:10:05 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 499  total_loss: 0.2498  loss_cls: 0.131  loss_box_reg: 0.09917  loss_rpn_cls: 0.009426  loss_rpn_loc: 0.007432  validation_loss: 0.2404    time: 0.8419  last_time: 0.7652  data_time: 0.0371  last_data_time: 0.0214   lr: 0.00999  max_mem: 5721M\n\u001b[32m[05/30 13:10:21 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 519  total_loss: 0.2669  loss_cls: 0.1384  loss_box_reg: 0.1101  loss_rpn_cls: 0.0106  loss_rpn_loc: 0.006245  validation_loss: 0.2404    time: 0.8414  last_time: 0.7321  data_time: 0.0389  last_data_time: 0.0222   lr: 0.01039  max_mem: 5721M\n\u001b[32m[05/30 13:10:38 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 539  total_loss: 0.2235  loss_cls: 0.1134  loss_box_reg: 0.09064  loss_rpn_cls: 0.008707  loss_rpn_loc: 0.005092  validation_loss: 0.2404    time: 0.8416  last_time: 0.8769  data_time: 0.0500  last_data_time: 0.0775   lr: 0.010789  max_mem: 5721M\n\u001b[32m[05/30 13:10:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:10:47 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:10:47 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:10:47 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:10:47 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 13:10:47 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 13:10:47 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:10:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0011 s/iter. Inference: 0.0492 s/iter. Eval: 0.0003 s/iter. Total: 0.0506 s/iter. ETA=0:00:02\n\u001b[32m[05/30 13:10:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.485011 (0.051771 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:10:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.049047 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:10:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:10:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 13:10:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.08s).\nAccumulating evaluation results...\nDONE (t=0.05s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.096\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.206\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.101\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.018\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.099\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.302\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.302\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.167\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.308\n\u001b[32m[05/30 13:10:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 9.646 | 20.639 | 10.134 |  nan  | 1.811 | 9.884 |\n\u001b[32m[05/30 13:10:50 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:10:50 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 4.436 | Cardiomegaly | 33.026 | Effusion   | 7.049 |\n| Infiltrate  | 2.290 | Pneumonia    | 1.429  |            |       |\n\u001b[32m[05/30 13:10:50 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 13:10:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 13:10:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 13:10:50 d2.evaluation.testing]: \u001b[0mcopypaste: 9.6460,20.6387,10.1341,nan,1.8108,9.8838\n\u001b[32m[05/30 13:10:51 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:02\n\u001b[32m[05/30 13:11:02 d2.utils.events]: \u001b[0m eta: 0:06:10  iter: 559  total_loss: 0.2381  loss_cls: 0.1245  loss_box_reg: 0.09618  loss_rpn_cls: 0.006822  loss_rpn_loc: 0.006594  validation_loss: 0.2412    time: 0.8421  last_time: 0.8370  data_time: 0.0564  last_data_time: 0.0270   lr: 0.011189  max_mem: 5721M\n\u001b[32m[05/30 13:11:18 d2.utils.events]: \u001b[0m eta: 0:05:53  iter: 579  total_loss: 0.265  loss_cls: 0.1395  loss_box_reg: 0.1105  loss_rpn_cls: 0.01055  loss_rpn_loc: 0.006386  validation_loss: 0.2412    time: 0.8420  last_time: 0.8826  data_time: 0.0526  last_data_time: 0.0737   lr: 0.011588  max_mem: 5721M\n\u001b[32m[05/30 13:11:35 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:11:35 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:11:35 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:11:35 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:11:35 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 13:11:35 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 13:11:35 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:11:36 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0011 s/iter. Inference: 0.0498 s/iter. Eval: 0.0004 s/iter. Total: 0.0512 s/iter. ETA=0:00:02\n\u001b[32m[05/30 13:11:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.562282 (0.053381 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:11:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.050484 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:11:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:11:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 13:11:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.07s).\nAccumulating evaluation results...\nDONE (t=0.05s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.086\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.177\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.078\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.087\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.176\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.254\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.254\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.256\n\u001b[32m[05/30 13:11:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 8.610 | 17.720 | 7.752  |  nan  | 0.000 | 8.669 |\n\u001b[32m[05/30 13:11:39 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:11:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.990 | Cardiomegaly | 32.468 | Effusion   | 3.777 |\n| Infiltrate  | 0.133 | Pneumonia    | 5.683  |            |       |\n\u001b[32m[05/30 13:11:39 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 13:11:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 13:11:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 13:11:39 d2.evaluation.testing]: \u001b[0mcopypaste: 8.6101,17.7204,7.7523,nan,0.0000,8.6695\n\u001b[32m[05/30 13:11:39 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:01\n\u001b[32m[05/30 13:11:42 d2.utils.events]: \u001b[0m eta: 0:05:37  iter: 599  total_loss: 0.2466  loss_cls: 0.1321  loss_box_reg: 0.09977  loss_rpn_cls: 0.009207  loss_rpn_loc: 0.007316  validation_loss: 0.2686    time: 0.8421  last_time: 0.8871  data_time: 0.0441  last_data_time: 0.0696   lr: 0.011988  max_mem: 5721M\n\u001b[32m[05/30 13:11:58 d2.utils.events]: \u001b[0m eta: 0:05:20  iter: 619  total_loss: 0.245  loss_cls: 0.1263  loss_box_reg: 0.1014  loss_rpn_cls: 0.008252  loss_rpn_loc: 0.005797  validation_loss: 0.2686    time: 0.8420  last_time: 0.8547  data_time: 0.0417  last_data_time: 0.0364   lr: 0.012388  max_mem: 5721M\n\u001b[32m[05/30 13:12:15 d2.utils.events]: \u001b[0m eta: 0:05:03  iter: 639  total_loss: 0.2638  loss_cls: 0.1362  loss_box_reg: 0.1102  loss_rpn_cls: 0.01034  loss_rpn_loc: 0.005847  validation_loss: 0.2686    time: 0.8419  last_time: 0.8812  data_time: 0.0369  last_data_time: 0.0675   lr: 0.012787  max_mem: 5721M\n\u001b[32m[05/30 13:12:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:12:24 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:12:24 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:12:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:12:24 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 13:12:24 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 13:12:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:12:24 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0011 s/iter. Inference: 0.0503 s/iter. Eval: 0.0003 s/iter. Total: 0.0517 s/iter. ETA=0:00:02\n\u001b[32m[05/30 13:12:27 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.512554 (0.052345 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:12:27 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.049407 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:12:27 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:12:27 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 13:12:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.08s).\nAccumulating evaluation results...\nDONE (t=0.05s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.103\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.222\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.089\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.042\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.103\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.231\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.314\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.314\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.233\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.310\n\u001b[32m[05/30 13:12:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n|:------:|:------:|:------:|:-----:|:-----:|:------:|\n| 10.329 | 22.221 | 8.899  |  nan  | 4.183 | 10.314 |\n\u001b[32m[05/30 13:12:27 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:12:27 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 3.260 | Cardiomegaly | 33.398 | Effusion   | 7.803 |\n| Infiltrate  | 1.222 | Pneumonia    | 5.961  |            |       |\n\u001b[32m[05/30 13:12:27 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 13:12:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 13:12:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 13:12:27 d2.evaluation.testing]: \u001b[0mcopypaste: 10.3288,22.2206,8.8987,nan,4.1832,10.3140\n\u001b[32m[05/30 13:12:28 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:01\n\u001b[32m[05/30 13:12:38 d2.utils.events]: \u001b[0m eta: 0:04:46  iter: 659  total_loss: 0.2485  loss_cls: 0.1231  loss_box_reg: 0.1076  loss_rpn_cls: 0.008263  loss_rpn_loc: 0.00573  validation_loss: 0.2423    time: 0.8417  last_time: 0.8304  data_time: 0.0453  last_data_time: 0.0242   lr: 0.013187  max_mem: 5721M\n\u001b[32m[05/30 13:12:55 d2.utils.events]: \u001b[0m eta: 0:04:29  iter: 679  total_loss: 0.2501  loss_cls: 0.1267  loss_box_reg: 0.1048  loss_rpn_cls: 0.007759  loss_rpn_loc: 0.006241  validation_loss: 0.2423    time: 0.8418  last_time: 0.8293  data_time: 0.0434  last_data_time: 0.0214   lr: 0.013586  max_mem: 5721M\n\u001b[32m[05/30 13:13:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:13:12 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:13:12 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:13:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:13:12 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 13:13:12 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 13:13:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:13:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0012 s/iter. Inference: 0.0494 s/iter. Eval: 0.0003 s/iter. Total: 0.0509 s/iter. ETA=0:00:02\n\u001b[32m[05/30 13:13:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.484416 (0.051759 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:13:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.049020 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:13:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:13:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 13:13:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.07s).\nAccumulating evaluation results...\nDONE (t=0.04s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.100\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.193\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.107\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.034\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.100\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.258\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.258\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.067\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.261\n\u001b[32m[05/30 13:13:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 9.965 | 19.309 | 10.736 |  nan  | 3.366 | 9.972 |\n\u001b[32m[05/30 13:13:15 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:13:15 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 1.485 | Cardiomegaly | 40.101 | Effusion   | 4.531 |\n| Infiltrate  | 0.466 | Pneumonia    | 3.243  |            |       |\n\u001b[32m[05/30 13:13:15 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 13:13:15 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 13:13:15 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 13:13:15 d2.evaluation.testing]: \u001b[0mcopypaste: 9.9653,19.3087,10.7359,nan,3.3663,9.9723\n\u001b[32m[05/30 13:13:16 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:01\n\u001b[32m[05/30 13:13:18 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 699  total_loss: 0.2321  loss_cls: 0.1217  loss_box_reg: 0.09389  loss_rpn_cls: 0.008805  loss_rpn_loc: 0.00696  validation_loss: 0.2527    time: 0.8419  last_time: 0.8413  data_time: 0.0452  last_data_time: 0.0300   lr: 0.013986  max_mem: 5721M\n\u001b[32m[05/30 13:13:35 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 719  total_loss: 0.2442  loss_cls: 0.1287  loss_box_reg: 0.1048  loss_rpn_cls: 0.007944  loss_rpn_loc: 0.006505  validation_loss: 0.2527    time: 0.8420  last_time: 0.8922  data_time: 0.0538  last_data_time: 0.0742   lr: 0.014386  max_mem: 5721M\n\u001b[32m[05/30 13:13:52 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 739  total_loss: 0.2359  loss_cls: 0.1241  loss_box_reg: 0.09637  loss_rpn_cls: 0.007392  loss_rpn_loc: 0.00677  validation_loss: 0.2527    time: 0.8421  last_time: 0.8319  data_time: 0.0446  last_data_time: 0.0191   lr: 0.014785  max_mem: 5721M\n\u001b[32m[05/30 13:14:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:14:01 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:14:01 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:14:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:14:01 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 13:14:01 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 13:14:01 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:14:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0010 s/iter. Inference: 0.0497 s/iter. Eval: 0.0003 s/iter. Total: 0.0511 s/iter. ETA=0:00:02\n\u001b[32m[05/30 13:14:04 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.499941 (0.052082 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:14:04 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.049300 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:14:04 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:14:04 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 13:14:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.05s).\nAccumulating evaluation results...\nDONE (t=0.04s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.086\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.223\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.033\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.168\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.085\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.186\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.241\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.241\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.167\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.238\n\u001b[32m[05/30 13:14:04 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n|:-----:|:------:|:------:|:-----:|:------:|:-----:|\n| 8.568 | 22.287 | 3.289  |  nan  | 16.832 | 8.507 |\n\u001b[32m[05/30 13:14:04 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:14:04 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP     |\n|:------------|:------|:-------------|:-------|:-----------|:-------|\n| Atelectasis | 0.765 | Cardiomegaly | 28.745 | Effusion   | 10.287 |\n| Infiltrate  | 0.570 | Pneumonia    | 2.474  |            |        |\n\u001b[32m[05/30 13:14:04 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 13:14:04 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 13:14:04 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 13:14:04 d2.evaluation.testing]: \u001b[0mcopypaste: 8.5681,22.2866,3.2894,nan,16.8317,8.5069\n\u001b[32m[05/30 13:14:05 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:01\n\u001b[32m[05/30 13:14:15 d2.utils.events]: \u001b[0m eta: 0:03:22  iter: 759  total_loss: 0.2345  loss_cls: 0.1188  loss_box_reg: 0.09902  loss_rpn_cls: 0.006936  loss_rpn_loc: 0.005893  validation_loss: 0.2595    time: 0.8421  last_time: 0.8822  data_time: 0.0442  last_data_time: 0.0667   lr: 0.015185  max_mem: 5721M\n\u001b[32m[05/30 13:14:32 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 779  total_loss: 0.2408  loss_cls: 0.1289  loss_box_reg: 0.1045  loss_rpn_cls: 0.00713  loss_rpn_loc: 0.006557  validation_loss: 0.2595    time: 0.8419  last_time: 0.8098  data_time: 0.0459  last_data_time: 0.0695   lr: 0.015584  max_mem: 5721M\n\u001b[32m[05/30 13:14:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:14:49 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:14:49 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:14:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:14:49 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 13:14:49 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 13:14:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:14:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0011 s/iter. Inference: 0.0491 s/iter. Eval: 0.0003 s/iter. Total: 0.0504 s/iter. ETA=0:00:02\n\u001b[32m[05/30 13:14:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.558854 (0.053309 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:14:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.050430 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:14:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:14:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 13:14:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.07s).\nAccumulating evaluation results...\nDONE (t=0.05s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.094\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.179\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.094\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.024\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.094\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.174\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.262\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.167\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.262\n\u001b[32m[05/30 13:14:52 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 9.371 | 17.863 | 9.388  |  nan  | 2.441 | 9.402 |\n\u001b[32m[05/30 13:14:52 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:14:52 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 1.350 | Cardiomegaly | 40.690 | Effusion   | 0.809 |\n| Infiltrate  | 3.124 | Pneumonia    | 0.884  |            |       |\n\u001b[32m[05/30 13:14:52 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 13:14:52 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 13:14:52 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 13:14:53 d2.evaluation.testing]: \u001b[0mcopypaste: 9.3714,17.8626,9.3880,nan,2.4406,9.4020\n\u001b[32m[05/30 13:14:53 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:01\n\u001b[32m[05/30 13:14:56 d2.utils.events]: \u001b[0m eta: 0:02:48  iter: 799  total_loss: 0.2331  loss_cls: 0.1212  loss_box_reg: 0.09233  loss_rpn_cls: 0.008205  loss_rpn_loc: 0.006516  validation_loss: 0.2599    time: 0.8421  last_time: 0.8328  data_time: 0.0535  last_data_time: 0.0261   lr: 0.015984  max_mem: 5721M\n\u001b[32m[05/30 13:15:12 d2.utils.events]: \u001b[0m eta: 0:02:31  iter: 819  total_loss: 0.2229  loss_cls: 0.1233  loss_box_reg: 0.09082  loss_rpn_cls: 0.005985  loss_rpn_loc: 0.00527  validation_loss: 0.2599    time: 0.8420  last_time: 0.8354  data_time: 0.0447  last_data_time: 0.0272   lr: 0.016384  max_mem: 5721M\n\u001b[32m[05/30 13:15:29 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 839  total_loss: 0.2264  loss_cls: 0.1125  loss_box_reg: 0.09685  loss_rpn_cls: 0.008515  loss_rpn_loc: 0.005941  validation_loss: 0.2599    time: 0.8422  last_time: 0.9005  data_time: 0.0457  last_data_time: 0.0772   lr: 0.016783  max_mem: 5721M\n\u001b[32m[05/30 13:15:38 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:15:38 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:15:38 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:15:38 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:15:38 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 13:15:38 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 13:15:38 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:15:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0015 s/iter. Inference: 0.0493 s/iter. Eval: 0.0003 s/iter. Total: 0.0511 s/iter. ETA=0:00:02\n\u001b[32m[05/30 13:15:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.488130 (0.051836 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:15:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.049127 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:15:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:15:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 13:15:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.05s).\nAccumulating evaluation results...\nDONE (t=0.04s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.103\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.249\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.086\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.106\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.201\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.259\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.259\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.269\n\u001b[32m[05/30 13:15:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n|:------:|:------:|:------:|:-----:|:-----:|:------:|\n| 10.268 | 24.873 | 8.625  |  nan  | 0.000 | 10.604 |\n\u001b[32m[05/30 13:15:41 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:15:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 4.247 | Cardiomegaly | 36.421 | Effusion   | 3.224 |\n| Infiltrate  | 1.610 | Pneumonia    | 5.838  |            |       |\n\u001b[32m[05/30 13:15:41 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 13:15:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 13:15:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 13:15:41 d2.evaluation.testing]: \u001b[0mcopypaste: 10.2678,24.8734,8.6250,nan,0.0000,10.6036\n\u001b[32m[05/30 13:15:41 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:01\n\u001b[32m[05/30 13:15:52 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 859  total_loss: 0.215  loss_cls: 0.1103  loss_box_reg: 0.08883  loss_rpn_cls: 0.006981  loss_rpn_loc: 0.005051  validation_loss: 0.2437    time: 0.8420  last_time: 0.8900  data_time: 0.0441  last_data_time: 0.0726   lr: 0.017183  max_mem: 5721M\n\u001b[32m[05/30 13:16:09 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 879  total_loss: 0.1998  loss_cls: 0.09805  loss_box_reg: 0.0887  loss_rpn_cls: 0.005283  loss_rpn_loc: 0.005378  validation_loss: 0.2437    time: 0.8421  last_time: 0.8773  data_time: 0.0397  last_data_time: 0.0714   lr: 0.017582  max_mem: 5721M\n\u001b[32m[05/30 13:16:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:16:26 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:16:26 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:16:26 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:16:26 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 13:16:26 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 13:16:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:16:27 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0016 s/iter. Inference: 0.0538 s/iter. Eval: 0.0004 s/iter. Total: 0.0558 s/iter. ETA=0:00:02\n\u001b[32m[05/30 13:16:29 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.571653 (0.053576 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:16:29 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.050725 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:16:29 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:16:29 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 13:16:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.06s).\nAccumulating evaluation results...\nDONE (t=0.04s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.098\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.234\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.058\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.099\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.213\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.273\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.273\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.275\n\u001b[32m[05/30 13:16:29 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n| 9.835 | 23.364 | 5.839  |  nan  | 0.000 | 9.925 |\n\u001b[32m[05/30 13:16:29 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:16:29 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 1.485 | Cardiomegaly | 35.871 | Effusion   | 6.599 |\n| Infiltrate  | 1.013 | Pneumonia    | 4.206  |            |       |\n\u001b[32m[05/30 13:16:29 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 13:16:29 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 13:16:29 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 13:16:29 d2.evaluation.testing]: \u001b[0mcopypaste: 9.8349,23.3640,5.8395,nan,0.0000,9.9245\n\u001b[32m[05/30 13:16:30 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:01\n\u001b[32m[05/30 13:16:32 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 899  total_loss: 0.2206  loss_cls: 0.1069  loss_box_reg: 0.09773  loss_rpn_cls: 0.005226  loss_rpn_loc: 0.005414  validation_loss: 0.2548    time: 0.8420  last_time: 0.8444  data_time: 0.0434  last_data_time: 0.0279   lr: 0.017982  max_mem: 5721M\n\u001b[32m[05/30 13:16:49 d2.utils.events]: \u001b[0m eta: 0:01:07  iter: 919  total_loss: 0.2128  loss_cls: 0.1077  loss_box_reg: 0.09312  loss_rpn_cls: 0.008154  loss_rpn_loc: 0.006741  validation_loss: 0.2548    time: 0.8417  last_time: 0.8305  data_time: 0.0552  last_data_time: 0.0204   lr: 0.018382  max_mem: 5721M\n\u001b[32m[05/30 13:17:06 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 939  total_loss: 0.2289  loss_cls: 0.1212  loss_box_reg: 0.1028  loss_rpn_cls: 0.008325  loss_rpn_loc: 0.00718  validation_loss: 0.2548    time: 0.8416  last_time: 0.8563  data_time: 0.0410  last_data_time: 0.0404   lr: 0.018781  max_mem: 5721M\n\u001b[32m[05/30 13:17:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:17:14 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:17:14 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:17:14 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:17:14 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 13:17:14 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 13:17:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:17:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0010 s/iter. Inference: 0.0493 s/iter. Eval: 0.0003 s/iter. Total: 0.0506 s/iter. ETA=0:00:02\n\u001b[32m[05/30 13:17:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.511502 (0.052323 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:17:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.049414 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:17:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:17:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 13:17:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.07s).\nAccumulating evaluation results...\nDONE (t=0.05s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.120\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.257\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.119\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.120\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.206\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.323\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.323\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.326\n\u001b[32m[05/30 13:17:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n|:------:|:------:|:------:|:-----:|:-----:|:------:|\n| 11.992 | 25.749 | 11.853 |  nan  | 0.000 | 12.042 |\n\u001b[32m[05/30 13:17:17 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:17:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.162 | Cardiomegaly | 45.169 | Effusion   | 5.403 |\n| Infiltrate  | 2.367 | Pneumonia    | 6.860  |            |       |\n\u001b[32m[05/30 13:17:17 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 13:17:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 13:17:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 13:17:17 d2.evaluation.testing]: \u001b[0mcopypaste: 11.9924,25.7491,11.8535,nan,0.0000,12.0422\n\u001b[32m[05/30 13:17:18 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:01\n\u001b[32m[05/30 13:17:29 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 959  total_loss: 0.2071  loss_cls: 0.1063  loss_box_reg: 0.09196  loss_rpn_cls: 0.006664  loss_rpn_loc: 0.00578  validation_loss: 0.2392    time: 0.8417  last_time: 0.8770  data_time: 0.0403  last_data_time: 0.0708   lr: 0.019181  max_mem: 5721M\n\u001b[32m[05/30 13:17:46 d2.utils.events]: \u001b[0m eta: 0:00:16  iter: 979  total_loss: 0.1966  loss_cls: 0.1035  loss_box_reg: 0.08894  loss_rpn_cls: 0.006411  loss_rpn_loc: 0.006654  validation_loss: 0.2392    time: 0.8418  last_time: 0.8950  data_time: 0.0501  last_data_time: 0.0831   lr: 0.01958  max_mem: 5721M\n\u001b[32m[05/30 13:18:04 detectron2]: \u001b[0mLoss on Validation  done 11/53. 0.0001 s / img. ETA=0:00:01\n\u001b[32m[05/30 13:18:06 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 0.217  loss_cls: 0.1078  loss_box_reg: 0.08761  loss_rpn_cls: 0.007377  loss_rpn_loc: 0.005731  validation_loss: 0.2413    time: 0.8417  last_time: 0.8733  data_time: 0.0429  last_data_time: 0.0661   lr: 0.01998  max_mem: 5721M\n\u001b[32m[05/30 13:18:06 d2.engine.hooks]: \u001b[0mOverall training speed: 998 iterations in 0:14:00 (0.8417 s / it)\n\u001b[32m[05/30 13:18:06 d2.engine.hooks]: \u001b[0mTotal training time: 0:16:15 (0:02:15 on hooks)\n\u001b[32m[05/30 13:18:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:18:06 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:18:06 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:18:06 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:18:06 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[05/30 13:18:06 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n\u001b[32m[05/30 13:18:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:18:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/53. Dataloading: 0.0013 s/iter. Inference: 0.0516 s/iter. Eval: 0.0004 s/iter. Total: 0.0533 s/iter. ETA=0:00:02\n\u001b[32m[05/30 13:18:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.642545 (0.055053 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:18:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.051841 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:18:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:18:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/inference/coco_instances_results.json\n\u001b[32m[05/30 13:18:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.06s).\nAccumulating evaluation results...\nDONE (t=0.04s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.109\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.201\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.112\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.109\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.258\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.310\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317\n\u001b[32m[05/30 13:18:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n|:------:|:------:|:------:|:-----:|:-----:|:------:|\n| 10.876 | 20.117 | 11.158 |  nan  | 0.000 | 10.922 |\n\u001b[32m[05/30 13:18:10 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:18:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.511 | Cardiomegaly | 45.118 | Effusion   | 4.316 |\n| Infiltrate  | 0.770 | Pneumonia    | 3.663  |            |       |\n\u001b[32m[05/30 13:18:10 d2.engine.defaults]: \u001b[0mEvaluation results for xray_val in csv format:\n\u001b[32m[05/30 13:18:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n\u001b[32m[05/30 13:18:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n\u001b[32m[05/30 13:18:10 d2.evaluation.testing]: \u001b[0mcopypaste: 10.8757,20.1171,11.1581,nan,0.0000,10.9216\n","output_type":"stream"}]},{"cell_type":"code","source":"# from detectron2.evaluation import COCOEvaluator, inference_on_dataset\nfrom detectron2.data import build_detection_test_loader\n\nevaluator = COCOEvaluator(\"xray_val\", tasks=(\"bbox\",), distributed=False, output_dir=\"./output/\")\ntest_loader = build_detection_test_loader(cfg, \"xray_val\")\nevaluation_results = inference_on_dataset(trainer.model, test_loader, evaluator)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:18:10.110979Z","iopub.execute_input":"2024-05-30T13:18:10.112020Z","iopub.status.idle":"2024-05-30T13:18:13.322499Z","shell.execute_reply.started":"2024-05-30T13:18:10.111983Z","shell.execute_reply":"2024-05-30T13:18:13.321502Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"\u001b[32m[05/30 13:18:10 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n\u001b[32m[05/30 13:18:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n\u001b[32m[05/30 13:18:10 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n\u001b[32m[05/30 13:18:10 d2.data.common]: \u001b[0mSerializing 53 elements to byte tensors and concatenating them all ...\n\u001b[32m[05/30 13:18:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.01 MiB\n\u001b[32m[05/30 13:18:10 d2.evaluation.evaluator]: \u001b[0mStart inference on 53 batches\n\u001b[32m[05/30 13:18:12 d2.evaluation.evaluator]: \u001b[0mInference done 43/53. Dataloading: 0.0015 s/iter. Inference: 0.0502 s/iter. Eval: 0.0004 s/iter. Total: 0.0521 s/iter. ETA=0:00:00\n\u001b[32m[05/30 13:18:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:02.525569 (0.052616 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:18:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.049826 s / iter per device, on 1 devices)\n\u001b[32m[05/30 13:18:13 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n\u001b[32m[05/30 13:18:13 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n\u001b[32m[05/30 13:18:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\nLoading and preparing results...\nDONE (t=0.00s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *bbox*\nDONE (t=0.06s).\nAccumulating evaluation results...\nDONE (t=0.04s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.109\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.201\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.112\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.109\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.258\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.310\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.310\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.317\n\u001b[32m[05/30 13:18:13 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n|:------:|:------:|:------:|:-----:|:-----:|:------:|\n| 10.876 | 20.117 | 11.158 |  nan  | 0.000 | 10.922 |\n\u001b[32m[05/30 13:18:13 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n\u001b[32m[05/30 13:18:13 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n| category    | AP    | category     | AP     | category   | AP    |\n|:------------|:------|:-------------|:-------|:-----------|:------|\n| Atelectasis | 0.511 | Cardiomegaly | 45.118 | Effusion   | 4.316 |\n| Infiltrate  | 0.770 | Pneumonia    | 3.663  |            |       |\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport matplotlib.pyplot as plt\n\nexperiment_folder = './output'\n\ndef load_json_arr(json_path):\n    lines = []\n    with open(json_path, 'r') as f:\n        for line in f:\n            lines.append(json.loads(line))\n    return lines\n\nexperiment_metrics = load_json_arr(experiment_folder + '/metrics.json')\nexperiment_metrics[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:18:13.324067Z","iopub.execute_input":"2024-05-30T13:18:13.324360Z","iopub.status.idle":"2024-05-30T13:18:13.334747Z","shell.execute_reply.started":"2024-05-30T13:18:13.324331Z","shell.execute_reply":"2024-05-30T13:18:13.333822Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"{'data_time': 0.032772231999985024,\n 'eta_seconds': 821.8608025599701,\n 'fast_rcnn/cls_accuracy': 0.9752197265625,\n 'fast_rcnn/false_negative': 1.0,\n 'fast_rcnn/fg_cls_accuracy': 0.0,\n 'iteration': 19,\n 'loss_box_reg': 0.07008441537618637,\n 'loss_cls': 0.8557019233703613,\n 'loss_rpn_cls': 0.07377208024263382,\n 'loss_rpn_loc': 0.012013777624815702,\n 'lr': 0.00039962,\n 'rank_data_time': 0.032772231999985024,\n 'roi_head/num_bg_samples': 502.25,\n 'roi_head/num_fg_samples': 9.75,\n 'rpn/num_neg_anchors': 251.625,\n 'rpn/num_pos_anchors': 4.375,\n 'time': 0.8386334719999695,\n 'timetest': 12.0,\n 'total_loss': 1.0074606924317777}"},"metadata":{}}]},{"cell_type":"code","source":"!mkdir /kaggle/working/imagens","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:18:13.336016Z","iopub.execute_input":"2024-05-30T13:18:13.336782Z","iopub.status.idle":"2024-05-30T13:18:14.300740Z","shell.execute_reply.started":"2024-05-30T13:18:13.336756Z","shell.execute_reply":"2024-05-30T13:18:14.299444Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.0   # set a custom testing threshold\npredictor = DefaultPredictor(cfg)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:18:14.302374Z","iopub.execute_input":"2024-05-30T13:18:14.302700Z","iopub.status.idle":"2024-05-30T13:18:15.233364Z","shell.execute_reply.started":"2024-05-30T13:18:14.302674Z","shell.execute_reply":"2024-05-30T13:18:15.232384Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"\u001b[32m[05/30 13:18:14 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./output/model_final.pth ...\n","output_type":"stream"}]},{"cell_type":"code","source":"import cv2\n\npredictions = {'image_id': [], 'class': [], 'bbox': [], 'score': []}\n\nfor i in zzz:\n    f = i['file_name']\n    img = cv2.imread(f)\n    outputs = predictor(img)\n    \n    for j in range(len(outputs[\"instances\"].pred_boxes.tensor.cpu().numpy())):\n        predictions['image_id'].append(i['file_name'])\n        predictions['bbox'].append(outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()[j])\n        predictions['class'].append(outputs[\"instances\"].pred_classes.cpu().numpy()[j])\n        predictions['score'].append(outputs[\"instances\"].scores.cpu().numpy()[j])","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:18:15.234695Z","iopub.execute_input":"2024-05-30T13:18:15.235038Z","iopub.status.idle":"2024-05-30T13:18:19.940878Z","shell.execute_reply.started":"2024-05-30T13:18:15.235012Z","shell.execute_reply":"2024-05-30T13:18:19.940105Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"res_df = pd.DataFrame(predictions)\nres_df.to_csv('/kaggle/working/previsoes.csv', index=False)\nres_df","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:18:19.942016Z","iopub.execute_input":"2024-05-30T13:18:19.942318Z","iopub.status.idle":"2024-05-30T13:18:20.577875Z","shell.execute_reply.started":"2024-05-30T13:18:19.942286Z","shell.execute_reply":"2024-05-30T13:18:20.576965Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"                                               image_id  class  \\\n0     /kaggle/input/data/images_001/images/00000583_...      4   \n1     /kaggle/input/data/images_001/images/00000583_...      1   \n2     /kaggle/input/data/images_001/images/00000583_...      4   \n3     /kaggle/input/data/images_001/images/00000583_...      3   \n4     /kaggle/input/data/images_001/images/00000583_...      4   \n...                                                 ...    ...   \n5195  /kaggle/input/data/images_012/images/00029469_...      0   \n5196  /kaggle/input/data/images_012/images/00029469_...      2   \n5197  /kaggle/input/data/images_012/images/00029469_...      0   \n5198  /kaggle/input/data/images_012/images/00029469_...      0   \n5199  /kaggle/input/data/images_012/images/00029469_...      3   \n\n                                              bbox     score  \n0      [302.18878, 475.11124, 504.17377, 584.5674]  0.412086  \n1       [19.583632, 406.08847, 343.14447, 858.065]  0.328861  \n2      [630.07245, 423.26047, 793.25415, 642.1592]  0.298709  \n3      [310.0705, 466.74442, 514.48456, 582.84906]  0.289200  \n4          [616.7471, 433.6759, 836.698, 563.1049]  0.155486  \n...                                            ...       ...  \n5195  [146.21764, 165.53203, 393.09268, 512.79535]  0.002686  \n5196    [736.83014, 509.7092, 858.3712, 895.20044]  0.002686  \n5197    [551.67035, 481.1781, 728.6158, 752.97766]  0.002631  \n5198    [101.41779, 701.8034, 354.35437, 980.7334]  0.002525  \n5199  [161.62267, 88.150665, 731.38226, 836.97327]  0.002517  \n\n[5200 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>class</th>\n      <th>bbox</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/data/images_001/images/00000583_...</td>\n      <td>4</td>\n      <td>[302.18878, 475.11124, 504.17377, 584.5674]</td>\n      <td>0.412086</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/data/images_001/images/00000583_...</td>\n      <td>1</td>\n      <td>[19.583632, 406.08847, 343.14447, 858.065]</td>\n      <td>0.328861</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/data/images_001/images/00000583_...</td>\n      <td>4</td>\n      <td>[630.07245, 423.26047, 793.25415, 642.1592]</td>\n      <td>0.298709</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/data/images_001/images/00000583_...</td>\n      <td>3</td>\n      <td>[310.0705, 466.74442, 514.48456, 582.84906]</td>\n      <td>0.289200</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/data/images_001/images/00000583_...</td>\n      <td>4</td>\n      <td>[616.7471, 433.6759, 836.698, 563.1049]</td>\n      <td>0.155486</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5195</th>\n      <td>/kaggle/input/data/images_012/images/00029469_...</td>\n      <td>0</td>\n      <td>[146.21764, 165.53203, 393.09268, 512.79535]</td>\n      <td>0.002686</td>\n    </tr>\n    <tr>\n      <th>5196</th>\n      <td>/kaggle/input/data/images_012/images/00029469_...</td>\n      <td>2</td>\n      <td>[736.83014, 509.7092, 858.3712, 895.20044]</td>\n      <td>0.002686</td>\n    </tr>\n    <tr>\n      <th>5197</th>\n      <td>/kaggle/input/data/images_012/images/00029469_...</td>\n      <td>0</td>\n      <td>[551.67035, 481.1781, 728.6158, 752.97766]</td>\n      <td>0.002631</td>\n    </tr>\n    <tr>\n      <th>5198</th>\n      <td>/kaggle/input/data/images_012/images/00029469_...</td>\n      <td>0</td>\n      <td>[101.41779, 701.8034, 354.35437, 980.7334]</td>\n      <td>0.002525</td>\n    </tr>\n    <tr>\n      <th>5199</th>\n      <td>/kaggle/input/data/images_012/images/00029469_...</td>\n      <td>3</td>\n      <td>[161.62267, 88.150665, 731.38226, 836.97327]</td>\n      <td>0.002517</td>\n    </tr>\n  </tbody>\n</table>\n<p>5200 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!zip -r /kaggle/working/fastercnn_35000.zip /kaggle/working/output","metadata":{"execution":{"iopub.status.busy":"2024-05-30T13:18:20.579075Z","iopub.execute_input":"2024-05-30T13:18:20.579359Z","iopub.status.idle":"2024-05-30T13:18:38.169869Z","shell.execute_reply.started":"2024-05-30T13:18:20.579334Z","shell.execute_reply":"2024-05-30T13:18:38.168686Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/output/ (stored 0%)\n  adding: kaggle/working/output/inference/ (stored 0%)\n  adding: kaggle/working/output/inference/xray_val_coco_format.json (deflated 81%)\n  adding: kaggle/working/output/inference/coco_instances_results.json (deflated 72%)\n  adding: kaggle/working/output/inference/instances_predictions.pth (deflated 58%)\n  adding: kaggle/working/output/inference/xray_val_coco_format.json.lock (stored 0%)\n  adding: kaggle/working/output/events.out.tfevents.1717074137.c63cc3b49623.27.0 (deflated 71%)\n  adding: kaggle/working/output/last_checkpoint (stored 0%)\n  adding: kaggle/working/output/model_final.pth (deflated 7%)\n  adding: kaggle/working/output/coco_instances_results.json (deflated 72%)\n  adding: kaggle/working/output/instances_predictions.pth (deflated 58%)\n  adding: kaggle/working/output/metrics.json (deflated 77%)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# COMEÇO YOLO","metadata":{}},{"cell_type":"code","source":"# install dependencies: \n!python -m pip install pyyaml==5.1\nimport torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())\n!gcc --version\n# opencv is pre-installed on colab","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys, os, distutils.core\n# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n!git clone 'https://github.com/facebookresearch/detectron2'\ndist = distutils.core.run_setup(\"./detectron2/setup.py\")\n!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\nsys.path.insert(0, os.path.abspath('./detectron2'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch, detectron2\n!nvcc --version\nTORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\nCUDA_VERSION = torch.__version__.split(\"+\")[-1]\nprint(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\nprint(\"detectron2:\", detectron2.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Some basic setup:\n# Setup detectron2 logger\nimport detectron2\nfrom detectron2.utils.logger import setup_logger\nsetup_logger()\n\n# import some common libraries\nimport pandas as pd\nimport numpy as np\nimport os, json, cv2, random\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom glob import glob\n\n# import some common detectron2 utilities\nfrom detectron2 import model_zoo\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.config import get_cfg\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.data import MetadataCatalog, DatasetCatalog","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os, json, cv2, random\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom glob import glob","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_xray_df = pd.read_csv('/kaggle/input/data/Data_Entry_2017.csv')\nall_image_paths = {os.path.basename(x): x for x in \n                   glob(os.path.join('/kaggle/input/data', 'images*', '*', '*.png'))}\nprint('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\nall_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\nall_xray_df['Patient Age'] = all_xray_df['Patient Age'].map(lambda x: int(x))\nall_xray_df.sample(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = all_xray_df[all_xray_df['Image Index'] == '00013118_008.png']['path'].item()\nprint(a)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(all_image_paths.items())[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Antes de tudo precisamos reescrever a BBOX no formato json","metadata":{}},{"cell_type":"code","source":"bbox_csv = pd.read_csv('/kaggle/input/data/BBox_List_2017.csv')\nbbox_csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorys = bbox_csv['Finding Label'].unique()\ncategory_ids = {k: v for v, k in enumerate(categorys)}\ncategory_ids","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"{k: bbox_csv['Finding Label'].value_counts()[k] - bbox_csv['Finding Label'].value_counts().min() for k in categorys}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bbox_csv['Finding Label'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bbox_csv_copy = bbox_csv.copy(deep=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#bbox_csv = bbox_csv[~bbox_csv['Finding Label'].isin(['Atelectasis', 'Nodule', 'Mass', 'Pneumothorax'])]\nbbox_csv = bbox_csv[~bbox_csv['Finding Label'].isin(['Nodule', 'Mass', 'Pneumothorax'])]\nbbox_csv['Finding Label'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorys = bbox_csv['Finding Label'].unique()\ncategory_ids = {k: v for v, k in enumerate(categorys)}\ncategory_ids","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_exc = []\ncats_exc = {k: bbox_csv['Finding Label'].value_counts()[k] - bbox_csv['Finding Label'].value_counts().min() for k in categorys}\n\nfor cat in categorys:\n    count = 0\n    df_catx = bbox_csv[bbox_csv['Finding Label'] == cat]\n    for i, r in df_catx.iterrows():\n        if len(bbox_csv[bbox_csv['Image Index'] == r['Image Index']]['Image Index'].to_list()) == 1 and count < cats_exc[cat]:\n            list_exc.append(r['Image Index'])\n            count += 1\n\ndf_new = bbox_csv[~bbox_csv['Image Index'].isin(list_exc)]\ndf_new","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_new['Finding Label'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bbox_csv = df_new.copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#bbox_csv = bbox_csv_copy.copy(deep=True)\nbbox_csv[bbox_csv['Image Index'] == '00008814_010.png']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bbox1 = bbox_csv.iloc[0] \nbbox1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataentry = pd.read_csv('/kaggle/input/data/Data_Entry_2017.csv')\ndataentry","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataentry[dataentry['Finding Labels'] == 'Effusion|Emphysema|Infiltration|Nodule|Pneumothorax']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_val_list_txt = pd.read_csv('/kaggle/input/data/train_val_list.txt', sep=' ', header=None)\ntrain_val_list_txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\naa = dataentry[dataentry['Finding Labels'] == 'No Finding'].head(79)\na = np.empty(79)\na[:] = np.nan\n\ndict_df = {\n    'Image Index': aa['Image Index'].to_list(),\n    'Finding Label': aa['Finding Labels'].to_list(),\n    'Bbox [x': a,\n    'y': a,\n    'w': a,\n    'h]': a,\n    'Unnamed: 6': a,\n    'Unnamed: 7': a,\n    'Unnamed: 8': a\n}\ndict_df = pd.DataFrame(dict_df)\nbbox_csv = pd.concat([bbox_csv, dict_df])\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorys = bbox_csv['Finding Label'].unique()\ncategory_ids = {k: v for v, k in enumerate(categorys)}\ncategory_ids","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = dataentry.loc[dataentry['Image Index'] == '00003423_005.png', ['Height]']]\na.values[0][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bbox_csv['image_id'] = bbox_csv.apply(lambda x: x['Image Index'].split('.')[0], axis = 1)\nbbox_csv['category_id'] = bbox_csv.apply(lambda x: category_ids[x['Finding Label']], axis = 1)\nbbox_csv['height'] = None\nbbox_csv['width'] = None\n\nfor i in bbox_csv['Image Index']:\n    if i in dataentry['Image Index'].values:\n        bbox_csv.loc[bbox_csv['Image Index'] == i, ['height']] = dataentry.loc[dataentry['Image Index'] == i, ['Height]']].values[0][0]\n        bbox_csv.loc[bbox_csv['Image Index'] == i, ['width']] = dataentry.loc[dataentry['Image Index'] == i, ['OriginalImage[Width']].values[0][0]\n\nbbox_csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_annotation(rowbbox):\n    if rowbbox['category_id'] == 8: # PARA OS CASOS QUE NÃO POSSUEM DETECÇÕES\n        dict_return = {\n            'file_name': str(rowbbox['Image Index']),\n            'image_id': str(rowbbox['image_id']),\n            'height': rowbbox['height'],\n            'width': rowbbox['width'],\n            'annotations': []\n        }\n        return dict_return\n    \n    dict_return = {\n        'file_name': str(rowbbox['Image Index']),\n        'image_id': str(rowbbox['image_id']),\n        'height': rowbbox['height'],\n        'width': rowbbox['width'],\n        'annotations': [\n            {\n                'bbox': [rowbbox['Bbox [x'], rowbbox['y'], rowbbox['w'], rowbbox['h]']],\n                'bbox_mode': 1,\n                'category_id': rowbbox['category_id']\n            }\n        ]\n    }\n    return dict_return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_json = []\nfor index, row in bbox_csv.iterrows():\n    presente = False\n    indice = 0\n    for i in range(len(list_json)):\n        if str(row['Image Index']) == list_json[i]['file_name']:\n            presente = True\n            indice = i\n            break\n    \n    if presente:\n        list_json[i]['annotations'].append(\n            {\n                'bbox': [row['Bbox [x'], row['y'], row['w'], row['h]']],\n                'bbox_mode': 1,\n                'category_id': row['category_id']\n            }\n        )\n    else:\n        list_json.append(to_annotation(row))\n\nlen(list_json)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in list_json:\n    if i['file_name'] == '00008814_010.png':\n        print(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(list_json)):\n    for key, value in all_image_paths.items():\n        if list_json[i]['file_name'] in key:\n            list_json[i]['file_name'] = value\nlist_json[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To ensure bbox always remap to original image size\nfor i in range(len(list_json)):\n    image = cv2.imread(list_json[i]['file_name'])\n    list_json[i][\"width\"] = image.shape[1]\n    list_json[i][\"height\"] = image.shape[0]\n\nl = None\nfor i in list_json:\n    if i['image_id'] == '00008814_010':\n        l = i\nl","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"listststs = {}\ntrain_data = {}\nval_data = {}\ntest_data = {}\n\nfor i in category_ids.values():\n    listststs[i] = []\n    for j in list_json:\n        try:\n            if j['annotations'][0]['category_id'] == i:\n                listststs[i].append(j)\n        except:\n            if i == 8:\n                listststs[i].append(j)\n\nfor i, x in listststs.items():\n    train_data[i] = x[:int((len(x)+1)*.80)] #80% to training set\n    val_data[i] = x[int((len(x)+1)*.80):int((len(x)+1)*.90)] #10% to val set\n    test_data[i] = x[int((len(x)+1)*.90):] #10% to val set\n\nyyy = []\nxxx = []\nzzz = []\n\nfor i, x in train_data.items():\n    for y in x:\n        yyy.append(y)\n\nfor i, x in val_data.items():\n    for y in x:\n        xxx.append(y)\n        \nfor i, x in test_data.items():\n    for y in x:\n        zzz.append(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(xxx), len(yyy), len(zzz)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nwith open('/kaggle/working/treino.json', 'w', encoding='utf-8') as f:\n    json.dump(yyy, f, ensure_ascii=False, indent=4)\nwith open('/kaggle/working/val.json', 'w', encoding='utf-8') as f:\n    json.dump(xxx, f, ensure_ascii=False, indent=4)\nwith open('/kaggle/working/test.json', 'w', encoding='utf-8') as f:\n    json.dump(zzz, f, ensure_ascii=False, indent=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''xray_metadata = {}\n\ndef registrar(d):\n    if d == 'train':\n        return yyy\n    if d == 'val':\n        return xxx\n    return zzz\n\nfor d in [\"train\", \"val\", \"test\"]:\n    DatasetCatalog.register(\"xray_\" + d, lambda d=d: registrar(d))\n    MetadataCatalog.get(\"xray_\" + d).set(thing_classes=list(categorys))\nxray_metadata['train'] = MetadataCatalog.get(\"xray_train\")\nxray_metadata['val'] = MetadataCatalog.get(\"xray_val\")\nxray_metadata['test'] = MetadataCatalog.get(\"xray_test\")'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''for d in random.sample(yyy, 3):\n    img = cv2.imread(d[\"file_name\"])\n    visualizer = Visualizer(img[:, :, ::-1], metadata=xray_metadata['train'], scale=0.5)\n    out = visualizer.draw_dataset_dict(d)\n    plt.imshow(cv2.cvtColor(out.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB)) # converting BGR to RGB for using matplotlib\n    plt.title(d['file_name'])\n    plt.axis('off')'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FORMATANDO PARA YOLO","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport ast\nimport torch\nimport PIL\nfrom tqdm.auto import tqdm\nimport shutil as sh\nfrom pathlib import Path\nimport random\n\nfrom IPython.display import Image, clear_output\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom IPython import display\ndisplay.clear_output()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"DATA_DIR = Path('../input/data')\nimg_list = [x for x in glob(os.path.join('/kaggle/input/data', 'images*', '*', '*.png'))]\npickone = random.choice(img_list)\ndisplay.Image(pickone)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Found {len(img_list)} images files in {DATA_DIR}\")\n\nimg = PIL.Image.open(pickone)\nIMAGE_HEIGHT, IMAGE_WIDTH = img.size\nnum_channels = len(img.mode)\nprint(\"Image size: {}\".format((IMAGE_HEIGHT, IMAGE_WIDTH)))\nprint(\"Num channels: {}\".format(num_channels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    bbox_csv.drop(bbox_csv.iloc[:, 6:9], axis=1, inplace=True)\n    bbox_csv.drop(bbox_csv.iloc[:, 6:9], axis=1, inplace=True)\n    bbox_csv.drop(bbox_csv.iloc[:, 6:9], axis=1, inplace=True)\nexcept: \n    pass\nbbox_csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_json = pd.DataFrame(yyy)\nval_json = pd.DataFrame(xxx)\ntest_json = pd.DataFrame(zzz)\ntrain_json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MUDANÇA","metadata":{}},{"cell_type":"code","source":"import random\nimport cv2\nfrom matplotlib import pyplot as plt\nimport albumentations as A\n# import some common libraries\nimport pandas as pd\nimport numpy as np\nimport os, json, cv2, random, itertools\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom glob import glob\nfrom random import sample\nfrom PIL import Image as im\nfrom matplotlib.image import imread\npd.set_option('display.max_columns', None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BOX_COLOR = (255, 0, 0) # Red\nTEXT_COLOR = (255, 255, 255) # White\n\n\ndef visualize_bbox(img, bbox, class_name, color=BOX_COLOR, thickness=2):\n    \"\"\"Visualizes a single bounding box on the image\"\"\"\n    x_min, y_min, w, h = bbox\n    x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n\n    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=color, thickness=thickness)\n\n    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)\n    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n    cv2.putText(\n        img,\n        text=class_name,\n        org=(x_min, y_min - int(0.3 * text_height)),\n        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n        fontScale=0.35,\n        color=TEXT_COLOR,\n        lineType=cv2.LINE_AA,\n    )\n    return img\n\n\ndef visualize(image, bboxes, category_ids, category_id_to_name):\n    img = image.copy()\n    for bbox, category_id in zip(bboxes, category_ids):\n        class_name = category_id_to_name[category_id]\n        img = visualize_bbox(img, bbox, class_name)\n    plt.figure(figsize=(8, 8))\n    plt.axis('off')\n    plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def to_annotation(rowbbox):\n    dict_return = {\n        'file_name': str(rowbbox['Image Index']),\n        'image_id': str(rowbbox['image_id']),\n        'height': rowbbox['height'],\n        'width': rowbbox['width'],\n        'annotations': [\n            {\n                'bbox': [rowbbox['Bbox [x'], rowbbox['y'], rowbbox['w'], rowbbox['h]']],\n                'bbox_mode': 1,\n                'category_id': rowbbox['category_id']\n            }\n        ]\n    }\n    return dict_return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir novas_imagens","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = A.Compose(\n    [A.Resize(640, 640)],\n    bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']),\n)\n\n\nkey_list = list(category_ids.keys())\nval_list = list(category_ids.values())\nnew_list = []\nbox_list = []\n\nfor j, i in train_json.iterrows():\n    image = cv2.imread(i['file_name'])\n    bboxes = [a['bbox'] for a in i['annotations']]\n    cat_ids = [a['category_id'] for a in i['annotations']]\n    cat_names = [key_list[val_list.index(a)] for a in cat_ids]\n\n    novo_item = {'Image Index': 0, 'Finding Label': 0, 'x': 0, 'y': 0, 'w': 0, 'h':0, 'path': 0}\n    novo_item['Image Index'] = i['image_id'] + '_new.png'\n    novo_item['path'] = f'/kaggle/working/novas_imagens/{i[\"image_id\"]}_new.png'\n\n    new_image_id = i['image_id'] + '_new'\n    diretorio = f\"/kaggle/working/novas_imagens/{new_image_id}.png\"\n\n    random.seed(7)\n    transformed = transform(image=image, bboxes=bboxes, category_ids=cat_ids)\n\n    data = im.fromarray(transformed['image'])\n    data.save(diretorio)\n\n    for c in range(len(cat_ids)):\n        if c == 0:\n            row = {'Image Index': diretorio, 'Finding Label': cat_names[c],\n               'Bbox [x': transformed['bboxes'][c][0], 'y': transformed['bboxes'][c][1],\n               'w': transformed['bboxes'][c][2], 'h]': transformed['bboxes'][c][3],\n               'image_id': new_image_id, 'category_id': cat_ids[c],\n               'height': 640, 'width': 640}\n            novo_item['Finding Label'] = (list(category_ids.keys())[list(category_ids.values()).index(cat_ids[c])])\n            novo_item['x'] = transformed['bboxes'][c][0]\n            novo_item['y'] = transformed['bboxes'][c][1]\n            novo_item['w'] = transformed['bboxes'][c][2]\n            novo_item['h'] = transformed['bboxes'][c][3]\n            box_list.append(novo_item)\n            new_list.append(to_annotation(row))\n        else:\n            novo_item['Finding Label'] = (list(category_ids.keys())[list(category_ids.values()).index(cat_ids[c])])\n            novo_item['x'] = transformed['bboxes'][c][0]\n            novo_item['y'] = transformed['bboxes'][c][1]\n            novo_item['w'] = transformed['bboxes'][c][2]\n            novo_item['h'] = transformed['bboxes'][c][3]\n            box_list.append(novo_item)\n            new_list[-1]['annotations'].append(\n                {\n                    'bbox': [transformed['bboxes'][c][0], transformed['bboxes'][c][1], transformed['bboxes'][c][2], transformed['bboxes'][c][3]],\n                    'bbox_mode': 1,\n                    'category_id': cat_ids[c]\n                }\n            )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_json = pd.DataFrame(new_list)\ntrain_json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bbox_csv = pd.DataFrame(box_list)\nbbox_csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = A.Compose(\n    [A.Resize(640, 640)],\n    bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']),\n)\n\n\nkey_list = list(category_ids.keys())\nval_list = list(category_ids.values())\nnew_list = []\nbox_list = []\n\nfor j, i in val_json.iterrows():\n    image = cv2.imread(i['file_name'])\n    bboxes = [a['bbox'] for a in i['annotations']]\n    cat_ids = [a['category_id'] for a in i['annotations']]\n    cat_names = [key_list[val_list.index(a)] for a in cat_ids]\n\n    novo_item = {'Image Index': 0, 'Finding Label': 0, 'x': 0, 'y': 0, 'w': 0, 'h':0, 'path': 0}\n    novo_item['Image Index'] = i['image_id'] + '_new.png'\n    novo_item['path'] = f'/kaggle/working/novas_imagens/{i[\"image_id\"]}_new.png'\n\n    new_image_id = i['image_id'] + '_new'\n    diretorio = f\"/kaggle/working/novas_imagens/{new_image_id}.png\"\n\n    random.seed(7)\n    transformed = transform(image=image, bboxes=bboxes, category_ids=cat_ids)\n\n    data = im.fromarray(transformed['image'])\n    data.save(diretorio)\n\n    for c in range(len(cat_ids)):\n        if c == 0:\n            row = {'Image Index': diretorio, 'Finding Label': cat_names[c],\n               'Bbox [x': transformed['bboxes'][c][0], 'y': transformed['bboxes'][c][1],\n               'w': transformed['bboxes'][c][2], 'h]': transformed['bboxes'][c][3],\n               'image_id': new_image_id, 'category_id': cat_ids[c],\n               'height': 640, 'width': 640}\n            novo_item['Finding Label'] = (list(category_ids.keys())[list(category_ids.values()).index(cat_ids[c])])\n            novo_item['x'] = transformed['bboxes'][c][0]\n            novo_item['y'] = transformed['bboxes'][c][1]\n            novo_item['w'] = transformed['bboxes'][c][2]\n            novo_item['h'] = transformed['bboxes'][c][3]\n            box_list.append(novo_item)\n            new_list.append(to_annotation(row))\n        else:\n            novo_item['Finding Label'] = (list(category_ids.keys())[list(category_ids.values()).index(cat_ids[c])])\n            novo_item['x'] = transformed['bboxes'][c][0]\n            novo_item['y'] = transformed['bboxes'][c][1]\n            novo_item['w'] = transformed['bboxes'][c][2]\n            novo_item['h'] = transformed['bboxes'][c][3]\n            box_list.append(novo_item)\n            new_list[-1]['annotations'].append(\n                {\n                    'bbox': [transformed['bboxes'][c][0], transformed['bboxes'][c][1], transformed['bboxes'][c][2], transformed['bboxes'][c][3]],\n                    'bbox_mode': 1,\n                    'category_id': cat_ids[c]\n                }\n            )\nval_json = pd.DataFrame(new_list)\nl = pd.DataFrame(box_list)\nbbox_csv = pd.concat([bbox_csv, l], axis=0)\nval_json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = A.Compose(\n    [A.Resize(640, 640)],\n    bbox_params=A.BboxParams(format='coco', label_fields=['category_ids']),\n)\n\n\nkey_list = list(category_ids.keys())\nval_list = list(category_ids.values())\nnew_list = []\nbox_list = []\n\nfor j, i in test_json.iterrows():\n    image = cv2.imread(i['file_name'])\n    bboxes = [a['bbox'] for a in i['annotations']]\n    cat_ids = [a['category_id'] for a in i['annotations']]\n    cat_names = [key_list[val_list.index(a)] for a in cat_ids]\n\n    novo_item = {'Image Index': 0, 'Finding Label': 0, 'x': 0, 'y': 0, 'w': 0, 'h':0, 'path': 0}\n    novo_item['Image Index'] = i['image_id'] + '_new.png'\n    novo_item['path'] = f'/kaggle/working/novas_imagens/{i[\"image_id\"]}_new.png'\n\n    new_image_id = i['image_id'] + '_new'\n    diretorio = f\"/kaggle/working/novas_imagens/{new_image_id}.png\"\n\n    random.seed(7)\n    transformed = transform(image=image, bboxes=bboxes, category_ids=cat_ids)\n\n    data = im.fromarray(transformed['image'])\n    data.save(diretorio)\n\n    for c in range(len(cat_ids)):\n        if c == 0:\n            row = {'Image Index': diretorio, 'Finding Label': cat_names[c],\n               'Bbox [x': transformed['bboxes'][c][0], 'y': transformed['bboxes'][c][1],\n               'w': transformed['bboxes'][c][2], 'h]': transformed['bboxes'][c][3],\n               'image_id': new_image_id, 'category_id': cat_ids[c],\n               'height': 640, 'width': 640}\n            novo_item['Finding Label'] = (list(category_ids.keys())[list(category_ids.values()).index(cat_ids[c])])\n            novo_item['x'] = transformed['bboxes'][c][0]\n            novo_item['y'] = transformed['bboxes'][c][1]\n            novo_item['w'] = transformed['bboxes'][c][2]\n            novo_item['h'] = transformed['bboxes'][c][3]\n            box_list.append(novo_item)\n            new_list.append(to_annotation(row))\n        else:\n            novo_item['Finding Label'] = (list(category_ids.keys())[list(category_ids.values()).index(cat_ids[c])])\n            novo_item['x'] = transformed['bboxes'][c][0]\n            novo_item['y'] = transformed['bboxes'][c][1]\n            novo_item['w'] = transformed['bboxes'][c][2]\n            novo_item['h'] = transformed['bboxes'][c][3]\n            box_list.append(novo_item)\n            new_list[-1]['annotations'].append(\n                {\n                    'bbox': [transformed['bboxes'][c][0], transformed['bboxes'][c][1], transformed['bboxes'][c][2], transformed['bboxes'][c][3]],\n                    'bbox_mode': 1,\n                    'category_id': cat_ids[c]\n                }\n            )\ntest_json = pd.DataFrame(new_list)\nl = pd.DataFrame(box_list)\nbbox_csv = pd.concat([bbox_csv, l], axis=0)\ntest_json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bbox_csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FIM","metadata":{}},{"cell_type":"code","source":"bbox_csv = bbox_csv.rename (columns = {'Bbox [x': 'x', 'h]': 'h'})\nbbox_csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convertendo COCO para YOLO (class_id, center_x, center_y, width, height) (normalizados)\nbbox_csv = bbox_csv.rename (columns = {'Bbox [x': 'x', 'h]': 'h'})\nbbox_csv['x'] = (bbox_csv['x'] + bbox_csv['w']/2) / 640\nbbox_csv['y'] = (bbox_csv['y'] + bbox_csv['h']/2) / 640\nbbox_csv['w'] = bbox_csv['w'] / 640\nbbox_csv['h'] = bbox_csv['h'] / 640\nbbox_csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_image_paths = {os.path.basename(x): x for x in \n                   glob(os.path.join('//kaggle/working/novas_imagens', '*.png'))}\nbbox_csv['path'] = bbox_csv['Image Index'].map(all_image_paths.get)\nbbox_csv['class_id'] = bbox_csv.apply(lambda x: category_ids[x['Finding Label']], axis=1)\nbbox_csv['boxes'] = bbox_csv.apply(lambda row: [row.class_id, row.x, row.y, row.w, row.h], axis=1)\nbbox_csv.drop(['Image Index', 'Finding Label', 'x', 'y', 'w', 'h', 'class_id'], axis=1, inplace=True)\nbbox_csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(yyy), len(xxx), len(zzz)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_files = []\ntrain_files = []\nteste_files = []\nbbox_csv = bbox_csv[['path', 'boxes']]\nfor i in bbox_csv['path'].tolist():\n    l = '_'.join(i.split('/')[-1].split('_')[0:2])\n    if l in [yyy[i]['image_id'] for i in range(len(yyy))]:\n        train_files.append(i)\n    elif l in [xxx[i]['image_id'] for i in range(len(xxx))]:\n        valid_files.append(i)\n    elif l in [zzz[i]['image_id'] for i in range(len(zzz))]:\n        teste_files.append(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('/kaggle/working/labels', exist_ok = True)\nfor i in range(len(bbox_csv)):\n    fname = os.path.basename(bbox_csv.iloc [i, 0]).replace('png', 'txt')\n    with open(f'labels/{fname}', 'a') as f:\n        for j in range(5):\n            f.write(str(bbox_csv.iloc[i, 1][j]) + ' ')\n        f.write('\\n')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nwith open('/kaggle/working/treino.json', 'w', encoding='utf-8') as f:\n    json.dump(train_files, f, ensure_ascii=False, indent=4)\nwith open('/kaggle/working/val.json', 'w', encoding='utf-8') as f:\n    json.dump(valid_files, f, ensure_ascii=False, indent=4)\nwith open('/kaggle/working/test.json', 'w', encoding='utf-8') as f:\n    json.dump(teste_files, f, ensure_ascii=False, indent=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xray_metadata = {}\n\ndef registrar(d):\n    if d == 'train':\n        return train_files\n    if d == 'val':\n        return valid_files\n    return teste_files\n\nfor d in [\"train\", \"val\", \"test\"]:\n    DatasetCatalog.register(\"xray_\" + d, lambda d=d: registrar(d))\n    MetadataCatalog.get(\"xray_\" + d).set(thing_classes=list(categorys))\nxray_metadata['train'] = MetadataCatalog.get(\"xray_train\")\nxray_metadata['val'] = MetadataCatalog.get(\"xray_val\")\nxray_metadata['test'] = MetadataCatalog.get(\"xray_test\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for d in random.sample(yyy, 3):\n    img = cv2.imread(d[\"file_name\"])\n    visualizer = Visualizer(img[:, :, ::-1], metadata=xray_metadata['train'], scale=0.5)\n    out = visualizer.draw_dataset_dict(d)\n    plt.imshow(cv2.cvtColor(out.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB)) # converting BGR to RGB for using matplotlib\n    plt.title(d['file_name'])\n    plt.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\nimport pandas as pd\nfrom glob import glob\nfrom tqdm.notebook import tqdm\n\nos.makedirs('/kaggle/working/NIH/train/images', exist_ok = True)\nos.makedirs('/kaggle/working/NIH/train/labels', exist_ok = True)\nos.makedirs('/kaggle/working/NIH/valid/images', exist_ok = True)\nos.makedirs('/kaggle/working/NIH/valid/labels', exist_ok = True)\nos.makedirs('/kaggle/working/NIH/teste/images', exist_ok = True)\nos.makedirs('/kaggle/working/NIH/teste/labels', exist_ok = True)\n\nfor files in [train_files, valid_files, teste_files]:\n    for file in tqdm (files):\n        fname = file.split ('/')[-1].split ('.')[0]\n        if files == train_files:\n            shutil.copy (file, '/kaggle/working/NIH/train/images/' + fname + '.png')\n            shutil.copy (os.path.join ('labels', fname + '.txt'), '/kaggle/working/NIH/train/labels/' + fname + '.txt')\n        elif files == valid_files:\n            shutil.copy (file, '/kaggle/working/NIH/valid/images/' + fname + '.png')\n            shutil.copy (os.path.join ('labels', fname + '.txt'), '/kaggle/working/NIH/valid/labels/' + fname + '.txt')\n        elif files == teste_files:\n            shutil.copy (file, '/kaggle/working/NIH/teste/images/' + fname + '.png')\n            shutil.copy (os.path.join ('labels', fname + '.txt'), '/kaggle/working/NIH/teste/labels/' + fname + '.txt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''CONFIG = \"\"\"\n# train and val datasets (image directory or *.txt file with image paths)\ntrain: /kaggle/working/NIH/train/\nval: /kaggle/working/NIH/valid/\n\n# number of classes\nnc: 8\n\n# class names\nnames: [\"Atelectasia\", \"Cardiomegalia\", \"Efusão\", \"Infiltração\", \"Massa\", \"Nódulo\", \"Pneumonia\", \"Pneumotórax\"]\n\"\"\"\n\nwith open(\"nih.yaml\", \"w\") as f:\n    f.write(CONFIG)'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CONFIG = \"\"\"\n# train and val datasets (image directory or *.txt file with image paths)\ntrain: /kaggle/working/NIH/train/\nval: /kaggle/working/NIH/valid/\n\n# number of classes\nnc: 4\n\n# class names\nnames: [\"Cardiomegalia\", \"Efusão\", \"Infiltração\", \"Pneumonia\"]\n\"\"\"\n\nwith open(\"nih.yaml\", \"w\") as f:\n    f.write(CONFIG)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T18:26:06.879102Z","iopub.execute_input":"2024-02-25T18:26:06.879528Z","iopub.status.idle":"2024-02-25T18:26:06.885661Z","shell.execute_reply.started":"2024-02-25T18:26:06.879475Z","shell.execute_reply":"2024-02-25T18:26:06.884517Z"}}},{"cell_type":"code","source":"CONFIG = \"\"\"\n# train and val datasets (image directory or *.txt file with image paths)\ntrain: /kaggle/working/NIH/train/\nval: /kaggle/working/NIH/valid/\n\n# number of classes\nnc: 5\n\n# class names\nnames: [\"Atelectasia\", \"Cardiomegalia\", \"Efusão\", \"Infiltração\", \"Pneumonia\"]\n\"\"\"\n\nwith open(\"nih.yaml\", \"w\") as f:\n    f.write(CONFIG)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r /kaggle/working/novas_imagens.zip /kaggle/working/novas_imagens","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# YOLOv5","metadata":{}},{"cell_type":"code","source":"# To check the number of GPUs with their names\n!nvidia-smi -L","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To get the CPU information\n!lscpu |grep 'Model name'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/ultralytics/yolov5  # clone repo\n%cd yolov5\n%pip install -qr requirements.txt  # install\n\nimport torch\nimport utils\ndisplay = utils.notebook_init()  # checks","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hyperparameters = '''\n# YOLOv5 🚀 by Ultralytics, AGPL-3.0 license\n# Hyperparameters for low-augmentation COCO training from scratch\n# python train.py --batch 64 --cfg yolov5n6.yaml --weights '' --data coco.yaml --img 640 --epochs 300 --linear\n# See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials\n\nlr0: 0.001 # initial learning rate (SGD=1E-2, Adam=1E-3)\nlrf: 0.1 # final OneCycleLR learning rate (lr0 * lrf)\nmomentum: 0.937 # SGD momentum/Adam beta1\nweight_decay: 0.0005 # optimizer weight decay 5e-4\nwarmup_epochs: 3.0 # warmup epochs (fractions ok)\nwarmup_momentum: 0.8 # warmup initial momentum\nwarmup_bias_lr: 0.1 # warmup initial bias lr\nbox: 0.05 # box loss gain\ncls: 0.5 # cls loss gain\ncls_pw: 1.0 # cls BCELoss positive_weight\nobj: 1.0 # obj loss gain (scale with pixels)\nobj_pw: 1.0 # obj BCELoss positive_weight\niou_t: 0.20 # IoU training threshold\nanchor_t: 4.0 # anchor-multiple threshold\n# anchors: 3  # anchors per output layer (0 to ignore)\nfl_gamma: 0.0 # focal loss gamma (efficientDet default gamma=1.5)\nhsv_h: 0.015 # image HSV-Hue augmentation (fraction)\nhsv_s: 0.7 # image HSV-Saturation augmentation (fraction)\nhsv_v: 0.4 # image HSV-Value augmentation (fraction)\ndegrees: 0.0 # image rotation (+/- deg)\ntranslate: 0.1 # image translation (+/- fraction)\nscale: 0.5 # image scale (+/- gain)\nshear: 0.0 # image shear (+/- deg)\nperspective: 0.0 # image perspective (+/- fraction), range 0-0.001\nflipud: 0.0 # image flip up-down (probability)\nfliplr: 0.5 # image flip left-right (probability)\nmosaic: 1.0 # image mosaic (probability)\nmixup: 0.0 # image mixup (probability)\ncopy_paste: 0.0 # segment copy-paste (probability)\n'''\n\nwith open(\"/kaggle/working/hyp.yaml\", \"w\") as f:\n    f.write(hyperparameters)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python train.py --img 1024 --cfg yolov5n6.yaml --hyp /kaggle/working/hyp.yaml --batch 16 --epochs 500 --data /kaggle/working/nih.yaml --weights '' --name yolo_nih --patience 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python train.py --img 1024 --cfg yolov5n6.yaml --hyp /kaggle/working/hyp.yaml --batch 16 --epochs 500 --data /kaggle/working/nih.yaml --weights yolov5n6.pt --name yolo_nih --patience 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python train.py --img 640 --cfg yolov5n.yaml --hyp hyp.scratch-low.yaml --batch 16 --epochs 3500 --data /kaggle/working/nih.yaml --weights yolov5n.pt --workers 24 --name yolo_nih --patience 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''import shutil\nshutil.rmtree(\"/kaggle/working/yolov5/runs/train/yolo_nih\")'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python detect.py  --img 640 --source /kaggle/working/NIH/teste/images/ --weights /kaggle/working/yolov5/runs/train/yolo_nih/weights/best.pt --iou 0.0 --conf 0.0 --name yolo_nih --save-csv --save-txt --save-conf --exist-ok ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\nfrom pathlib import Path\nimport pandas as df\n\nmy_dir_path = \"/kaggle/working/yolov5/runs/detect/yolo_nih/labels\"\n\nresults = defaultdict(list)\nfor file in Path(my_dir_path).iterdir():\n    with open(file, \"r\") as file_open:\n        results[\"file_name\"].append(file.name)\n        results[\"text\"].append(file_open.read())\ndf_valid = pd.DataFrame(results)\ndf_valid.to_csv('/kaggle/working/yolov5n6_1000_teste_lr001_lf0.1_comweights.csv', index=False, sep=';')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r /kaggle/working/yolov5n6_1000_teste_lr001_lf0.1_comweights.zip /kaggle/working/yolov5/runs/train/yolo_nih","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# YOLOv8","metadata":{}},{"cell_type":"code","source":"# Pip install (recommended)\n!pip install ultralytics\n\nfrom IPython import display\ndisplay.clear_output()\n!yolo checks","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install albumentations==1.0.3\ndisplay.clear_output()\n!pip show albumentations","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HOME = \"/kaggle/working/\"\n!wandb disabled  # ou os.environ['WANDB_DISABLED'] = 'true'\n#!yolo task=detect mode=train model=yolov8n.pt data={HOME}/nih.yaml epochs=1000 batch=32 imgsz=1024 patience=0 iou=0.5\n!yolo task=detect mode=train model=yolov8n.pt data={HOME}/nih.yaml epochs=3500 batch=16 imgsz=640 patience=0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/working/runs/detect/train/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display.Image(filename=f'{HOME}/runs/detect/train/F1_curve.png', width=600)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\nimport pandas as pd\n\ndf = pd.read_csv(\"/kaggle/working/runs/detect/train/results.csv\")\nfig = px.line(df, x='                  epoch', y='       metrics/mAP50(B)', title='mAP50')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display.Image(filename=f'{HOME}/runs/detect/train/val_batch0_pred.jpg', width=1000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!yolo task=detect mode=val model={HOME}/runs/detect/train/weights/best.pt data={HOME}/nih.yaml","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ultralytics import YOLO\nmodel = YOLO(f\"{HOME}/runs/detect/train/weights/best.pt\")\nresults = model.predict(source='/kaggle/working/NIH/teste/images', save_conf=True, save=True, save_txt=True, conf=0.0, iou=0.0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import defaultdict\nfrom pathlib import Path\nimport pandas as df\n\nmy_dir_path = \"/kaggle/working/runs/detect/predict/labels\"\n\nresults = defaultdict(list)\nfor file in Path(my_dir_path).iterdir():\n    with open(file, \"r\") as file_open:\n        results[\"file_name\"].append(file.name)\n        results[\"text\"].append(file_open.read())\ndf_valid = pd.DataFrame(results)\ndf_valid.to_csv('/kaggle/working/yolov8n_3500_teste16.csv', index=False, sep=';')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r /kaggle/working/filev8n16b_3500.zip /kaggle/working/runs/detect/train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}